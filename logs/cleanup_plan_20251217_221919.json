{
  "generated_at": "2025-12-17T22:19:19+00:00",
  "repo_root": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite",
  "dry_run": true,
  "inventory": [
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_exports",
      "kind": "directory",
      "size_bytes": 193,
      "modified_at": "2025-12-17T20:41:01+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_exports_final",
      "kind": "directory",
      "size_bytes": 155,
      "modified_at": "2025-12-17T22:06:26+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_exports_stage",
      "kind": "directory",
      "size_bytes": 126,
      "modified_at": "2025-12-17T22:11:21+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_inputs",
      "kind": "directory",
      "size_bytes": 193,
      "modified_at": "2025-12-17T20:41:01+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_inputs_final",
      "kind": "directory",
      "size_bytes": 163,
      "modified_at": "2025-12-17T22:06:21+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_inputs_stage",
      "kind": "directory",
      "size_bytes": 84,
      "modified_at": "2025-12-17T22:11:11+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work",
      "kind": "directory",
      "size_bytes": 1660279772,
      "modified_at": "2025-12-17T20:41:01+00:00",
      "classification": "deprecated"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\data",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\exports",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\inputs",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\outputs",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\runs",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tmp",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    },
    {
      "path": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\work",
      "kind": "directory",
      "size_bytes": 0,
      "modified_at": null,
      "classification": "missing"
    }
  ],
  "references": [
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\.pytest_cache\\README.md",
      "line": 3,
      "context": "This directory contains data from the pytest's cache plugin,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\asr_env.ps1",
      "line": 12,
      "context": "[string]$workspaceRoot = Resolve-SingleValue (Split-Path -Parent $repoRoot)",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\asr_env.ps1",
      "line": 39,
      "context": "\"$workspaceRoot\\.venv\\Lib\\site-packages\\nvidia\\cudnn\\bin\",",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\asr_env.ps1",
      "line": 40,
      "context": "\"$workspaceRoot\\.venv\\Lib\\site-packages\\torch\\lib\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 36,
      "context": "echo \"-> grep dans le filesystem (exclut .git/.venv/work/exports/models/cache)\" | tee -a \"$REPORT\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 39,
      "context": "--exclude-dir=\"work\" --exclude-dir=\"exports\" \\",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 45,
      "context": "if git rev-parse --is-inside-work-tree >/dev/null 2>&1; then",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 58,
      "context": "if git rev-parse --is-inside-work-tree >/dev/null 2>&1; then",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 59,
      "context": "for p in \"work/\" \"exports/\" \"models/\" \".venv/\" \".cache/\"; do",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 72,
      "context": "-not -path \"./.git/*\" -not -path \"./work/*\" -not -path \"./exports/*\" \\",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 82,
      "context": "-not -path \"./.venv/*\" -not -path \"./work/*\" -not -path \"./exports/*\" \\",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 90,
      "context": "-not -path \"./.venv/*\" -not -path \"./work/*\" -not -path \"./exports/*\" \\",
      "scope": "scripts"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\audit_before_commit.sh",
      "line": 145,
      "context": "if ! NO_TK=1 CT2_USE_MPS=1 bin/run.sh dry-run --input \"/tmp/placeholder.wav\" 2>&1 | tee -a \"$REPORT\"; then",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\env_check.py",
      "line": 75,
      "context": "from importlib import metadata",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\env_check.py",
      "line": 77,
      "context": "return metadata.version(package)",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 6,
      "context": "set \"PIPELINE_ROOT=\\\\bricesodini\\Savoirs\\03_data_pipeline\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 90,
      "context": "call :ResolveWorkDir \"%BASE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 91,
      "context": "if not defined WORK_DIR (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 92,
      "context": "echo [ERROR] work/%BASE% introuvable.",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 98,
      "context": "echo [ERROR] Exports introuvables pour %BASE%.",
      "scope": "scripts"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 102,
      "context": "call :StageOutputs \"%SAFE_BASE%\" \"%BASE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 129,
      "context": ":ResolveWorkDir",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 131,
      "context": "set \"WORK_DIR=%REPO_ROOT%\\work\\%TARGET%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 132,
      "context": "if exist \"%WORK_DIR%\" (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 135,
      "context": "for /d %%W in (\"%REPO_ROOT%\\work\\*\") do (",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 137,
      "context": "set \"WORK_DIR=%%~fW\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 141,
      "context": "set \"WORK_DIR=\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 147,
      "context": "set \"MANIFEST_PATH=%REPO_ROOT%\\work\\%BASE_NAME%\\logs\\run_manifest.json\"",
      "scope": "scripts"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 160,
      "context": ":StageOutputs",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 164,
      "context": "set \"TARGET_WORK=%DOC_STAGE%\\work\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 167,
      "context": "call :EnsureDir \"%TARGET_WORK%\" || exit /b 1",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_asr_batch.bat",
      "line": 168,
      "context": "robocopy \"%WORK_DIR%\" \"%TARGET_WORK%\\%DOC_NAME%\" /MIR /NFL /NDL /NJH /NJS >nul",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 9,
      "context": "set \"PIPELINE_ROOT=\\\\bricesodini\\Savoirs\\03_data_pipeline\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 209,
      "context": "set \"WORK_DIR=\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 211,
      "context": "call :ResolveWorkDir \"%DOC_STAGE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 213,
      "context": "if not defined WORK_DIR (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 215,
      "context": "echo [WARN] Work introuvable pour %DOC_STAGE%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 229,
      "context": "echo Work : %WORK_DIR%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 231,
      "context": "set \"VALIDATED=%WORK_DIR%\\rag.glossary.yaml\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 233,
      "context": "set \"STAMP_PATH=%WORK_DIR%\\.lexicon_ok.json\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 239,
      "context": "call :SelectSourceFile \"%WORK_DIR%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 285,
      "context": "call \"%RUN_BAT%\" rag lexicon scan --input \"%WORK_DIR%\" %LEXICON_EXTRA%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 295,
      "context": "call \"%RUN_BAT%\" rag lexicon apply --input \"%WORK_DIR%\" %LEXICON_EXTRA%",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 321,
      "context": ":ResolveWorkDir",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 325,
      "context": "set \"WORK_PARENT=%DOC_ROOT%\\work\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 327,
      "context": "if not exist \"%WORK_PARENT%\" exit /b 1",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 329,
      "context": "set \"DOC_SPECIFIC=%WORK_PARENT%\\%DOC_STAGE_NAME%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 333,
      "context": "set \"WORK_DIR=%DOC_SPECIFIC%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 339,
      "context": "set /a WORK_COUNT=0",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 341,
      "context": "set \"WORK_TMP=\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 343,
      "context": "for /d %%W in (\"%WORK_PARENT%\\*\") do (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 345,
      "context": "set \"WORK_TMP=%%~fW\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 347,
      "context": "set /a WORK_COUNT+=1",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 351,
      "context": "if %WORK_COUNT% EQU 1 (",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_lexicon_batch.bat",
      "line": 353,
      "context": "set \"WORK_DIR=%WORK_TMP%\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 6,
      "context": "set \"PIPELINE_ROOT=\\\\bricesodini\\Savoirs\\03_data_pipeline\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 17,
      "context": "set \"DATA_PIPELINE_ROOT=%PIPELINE_ROOT%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 78,
      "context": "set \"WORK_PARENT=%DOC_STAGE%\\work\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 79,
      "context": "if not exist \"%WORK_PARENT%\" (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 80,
      "context": "echo [WARN] Aucun dossier work pour %DOC_STAGE%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 83,
      "context": "set \"WORK_DIR=\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 84,
      "context": "for /d %%W in (\"%WORK_PARENT%\\*\") do (",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 85,
      "context": "if not defined WORK_DIR set \"WORK_DIR=%%~fW\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 87,
      "context": "if not defined WORK_DIR (",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 88,
      "context": "echo [WARN] Aucun sous-dossier dans %WORK_PARENT%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 114,
      "context": "echo === rag-export pour %WORK_DIR% ===",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 116,
      "context": "call \"%RUN_BAT%\" rag lexicon scan --input \"%WORK_DIR%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 118,
      "context": "echo [WARN] Lexicon scan a échoué pour %WORK_DIR%",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 121,
      "context": "call \"%RUN_BAT%\" rag --input \"%WORK_DIR%\" %RUN_ARGS% --force",
      "scope": "scripts"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\pipeline_rag_batch.bat",
      "line": 123,
      "context": "echo [ERROR] rag-export a échoué pour %WORK_DIR%",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\post_env.sh",
      "line": 2,
      "context": "# Prépare les variables CPU pour les étapes post-ASR (align, diar, exports).",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\run.bat",
      "line": 12,
      "context": "for %%I in (\"%REPO_ROOT%\\..\") do set \"WORKSPACE_ROOT=%%~fI\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\run.bat",
      "line": 17,
      "context": "set \"VENV_ROOT=%WORKSPACE_ROOT%\\.venv\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 11,
      "context": "set \"PIPELINE_ROOT=%DATA_PIPELINE_ROOT%\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 12,
      "context": "if not defined PIPELINE_ROOT set \"PIPELINE_ROOT=\\\\bricesodini\\Savoirs\\03_data_pipeline\"",
      "scope": "scripts"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 22,
      "context": "set \"NET_IN=%ROOT%\\inputs\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 23,
      "context": "set \"NET_OUT=%ROOT%\\exports\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 75,
      "context": "--asr-workers 2 ^",
      "scope": "scripts"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 81,
      "context": "--polish-outputs ^",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 93,
      "context": "set \"MANIFEST_PATH=%ROOT%\\work\\%BASE%\\logs\\run_manifest.json\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 117,
      "context": "echo ERROR: dossier exports introuvable \"%EXPORT_DIR%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 123,
      "context": "set \"FINAL_EXPORTS=%FINAL_ROOT%\\TRANSCRIPT - %BASE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 131,
      "context": "REM --- MOVE EXPORTS (ROBUST SMB) -------------------------------------",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 132,
      "context": "if exist \"%FINAL_EXPORTS%\" rd /s /q \"%FINAL_EXPORTS%\" >nul 2>&1",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 133,
      "context": "call :MoveDirRobust \"%EXPORT_DIR%\" \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 135,
      "context": "echo ERROR: impossible de déplacer les exports",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 138,
      "context": "echo [OK] Exports déplacés vers \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_mono.bat",
      "line": 141,
      "context": "set \"SOURCE_LOGS=%ROOT%\\work\\%BASE%\\logs\"",
      "scope": "scripts"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 64,
      "context": "--polish-outputs ^",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 75,
      "context": "set \"MANIFEST_PATH=%ROOT%\\work\\%BASE%\\logs\\run_manifest.json\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 97,
      "context": "echo ERROR: dossier exports introuvable \"%EXPORT_DIR%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 103,
      "context": "set \"FINAL_EXPORTS=%FINAL_ROOT%\\TRANSCRIPT - %BASE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 111,
      "context": "if exist \"%FINAL_EXPORTS%\" rd /s /q \"%FINAL_EXPORTS%\" >nul 2>&1",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 112,
      "context": "call :MoveDirRobust \"%EXPORT_DIR%\" \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 114,
      "context": "echo ERROR: impossible de déplacer les exports",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 117,
      "context": "echo [OK] Exports déplacés vers \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_multi.bat",
      "line": 119,
      "context": "set \"SOURCE_LOGS=%ROOT%\\work\\%BASE%\\logs\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 71,
      "context": "set \"MANIFEST_PATH=%ROOT%\\work\\%BASE%\\logs\\run_manifest.json\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 93,
      "context": "echo ERROR: dossier exports introuvable \"%EXPORT_DIR%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 99,
      "context": "set \"FINAL_EXPORTS=%FINAL_ROOT%\\TRANSCRIPT - %BASE%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 107,
      "context": "if exist \"%FINAL_EXPORTS%\" rd /s /q \"%FINAL_EXPORTS%\" >nul 2>&1",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 108,
      "context": "call :MoveDirRobust \"%EXPORT_DIR%\" \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 110,
      "context": "echo ERROR: impossible de déplacer les exports",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 113,
      "context": "echo [OK] Exports déplacés vers \"%FINAL_EXPORTS%\"",
      "scope": "scripts"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\bin\\transcribe_share.bat",
      "line": 115,
      "context": "set \"SOURCE_LOGS=%ROOT%\\work\\%BASE%\\logs\"",
      "scope": "scripts"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 2,
      "context": "inputs_dir: inputs",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 3,
      "context": "work_dir: work",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 4,
      "context": "exports_dir: exports",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 6,
      "context": "cache_dir: work/cache",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 54,
      "context": "workers: auto",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\config\\config.yaml",
      "line": 62,
      "context": "workers: 4",
      "scope": "source"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\configs\\base_stable.yaml",
      "line": 2,
      "context": "inputs_dir: inputs",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\configs\\base_stable.yaml",
      "line": 3,
      "context": "work_dir: work",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\configs\\base_stable.yaml",
      "line": 4,
      "context": "exports_dir: exports",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\configs\\base_stable.yaml",
      "line": 17,
      "context": "outputs:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\configs\\base_stable.yaml",
      "line": 58,
      "context": "workers: auto",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_LEXICON_WORKFLOW.md",
      "line": 7,
      "context": "1. **Scanner** les textes issus d’ASR (`work/<doc>`) pour proposer un fichier `rag.glossary.suggested.yaml`.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_LEXICON_WORKFLOW.md",
      "line": 17,
      "context": "# 2) Dans work\\<doc>, ouvrir rag.glossary.suggested.yaml, conserver seulement les règles souhaitées",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_LEXICON_WORKFLOW.md",
      "line": 50,
      "context": "3. Pour chaque doc : ouvrir `work\\<doc>\\rag.glossary.suggested.yaml`, corriger/compléter les entrées, supprimer les règles inutiles.",
      "scope": "docs"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_LEXICON_WORKFLOW.md",
      "line": 51,
      "context": "4. `pipeline_lexicon_batch.bat --apply` → copie les règles validées dans `rag.glossary.yaml` + écrit `.lexicon_ok.json` (horodatage, SHA, rules_count).",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_LEXICON_WORKFLOW.md",
      "line": 60,
      "context": "- Si vous validez manuellement sans repasser par le batch, exécutez `bin\\run.bat rag lexicon apply --input \"work\\<doc>\"` pour mettre à jour le stamp.",
      "scope": "docs"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 3,
      "context": "This note outlines how to extend `rag-export` to PDF inputs while preserving deterministic, versioned artefacts.",
      "scope": "docs"
    },
    {
      "pattern": "runs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 7,
      "context": "- Produce the same artefacts as for video/audio runs: `document.json`, `segments.jsonl`, `chunks.jsonl`, `chunks_for_llm.jsonl`, `quality.json`, `lexical.sqlite`, `README_RAG.md`.",
      "scope": "docs"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 11,
      "context": "## Inputs and resolver",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 13,
      "context": "1. `rag-export --input \"docs/MyReport.pdf\"` points to either the PDF itself or a prepared `work/<doc>` folder.",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 35,
      "context": "- Video/audio exports keep their current timestamps; `locator` simply mirrors them (`type=time`, `unit=seconds`).",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 36,
      "context": "- PDF exports reuse the same fields but `type=page`, `unit=page`, and `start`/`end` hold page numbers (allowing decimals for intra-page offsets).",
      "scope": "docs"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 48,
      "context": "- `quality.json` keeps the coverage metric; on PDF inputs the timeline corresponds to page span (coverage = (last_page - first_page) / total_pages).",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 49,
      "context": "- `lexical.sqlite` is identical; FTS queries ignore the locator type so `rag query` works for both media and PDF.",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 53,
      "context": "- `locator` is optional for older exports; once PDF support lands, video exports will also include it to ease migrations.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 54,
      "context": "- Existing consumers that only read `start`/`end` continue to work because those fields stay populated.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_PDF_DESIGN.md",
      "line": 61,
      "context": "4. Document the PDF workflow in the README and add fixtures + pytest coverage for a minimal PDF sample.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 7,
      "context": "- Copied the sample work dir to `work\\Démo NAS Éléphant` (contains spaces + accent).",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 8,
      "context": "- Invoked the CLI with the Win32 long-path prefix: `\\\\?\\D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\work\\Démo NAS Éléphant`.",
      "scope": "docs"
    },
    {
      "pattern": "runs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 9,
      "context": "- Forced output into a dedicated tag (`--version-tag windows_nas`) to avoid clashing with local runs.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 15,
      "context": "python -m rag_export.cli --input \"\\\\?\\D:\\...\\work\\Démo NAS Éléphant\" --config config/rag.yaml --version-tag windows_nas --force",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 38,
      "context": "| UNC share rights | The `\\\\?\\` prefix works for local disks; real NAS shares (`\\\\server\\share`) still rely on Windows credentials. | Documented in README: run `bin\\run.bat rag ...` from a session that already has access to the share. |",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 40,
      "context": "| SQLite locks | Running `rag query` while a share is read-only works because the command only opens the DB in read mode. | No change required; just avoid opening the DB in other apps with write locks. |",
      "scope": "docs"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\RAG_WINDOWS_VALIDATION.md",
      "line": 42,
      "context": "Outputs were deleted after the test; rerun the commands above to reproduce.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 24,
      "context": "- ASR: Faster-Whisper `large-v3`, `beam_size=1`, `best_of=1`, `temperature={0.0,0.2}`, `no_speech_threshold=0.6`, `workers=auto` (2 sur CUDA, 3 si VRAM ≥ 20 GB, sinon `≈cpu/2`), `device=auto`.",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 27,
      "context": "- Exports stricts: `.md`, `.json`, `.vtt` + `.low_confidence.csv`.",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 39,
      "context": "| `--allow-partial-export` | Déverrouille la protection contre les exports partiels (déconseillé). |",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 53,
      "context": "- `work/<video>/logs/metrics.json` (entrées `asr` + `pipeline`).",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 54,
      "context": "- `work/<video>/logs/run_manifest.json` avec :",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 57,
      "context": "- stats ASR (processed / skipped / retries / workers)",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 61,
      "context": "- `work/<video>/` doit contenir `audio_16k.wav`, `manifest.csv`, `02_merged_raw.json`, `03_aligned_whisperx.json`, `04_cleaned.json`, `05_polished.json`.",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 72,
      "context": "1. Inspecter `work/<video>/logs/run_manifest.json` pour identifier l’étape en erreur.",
      "scope": "docs"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 88,
      "context": "--input \"/data/podcasts/episode.mp4\"",
      "scope": "docs"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 93,
      "context": "--input \"/data/podcasts/episode.mp4\"",
      "scope": "docs"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 98,
      "context": "--input \"/data/podcasts/episode.mp4\" \\",
      "scope": "docs"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\docs\\STABLE_BASE.md",
      "line": 100,
      "context": "--low-confidence-out exports/episode.qa.csv",
      "scope": "docs"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 32,
      "context": "self.max_workers = max(1, int(self.cfg.get(\"workers\", 4) or 4))",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 53,
      "context": "align_model, metadata = whisperx.load_align_model(",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 58,
      "context": "self._cache[lang] = (align_model, metadata)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 59,
      "context": "return align_model, metadata",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 84,
      "context": "work_dir: Path,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 89,
      "context": "aligned_path = work_dir / \"03_aligned_whisperx.json\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 100,
      "context": "align_model, metadata = self._load_align_model(language)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 108,
      "context": "if self.max_workers:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 109,
      "context": "requested_kwargs[\"num_workers\"] = self.max_workers",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 119,
      "context": "aligned = self._invoke_align(segments_for_align, align_model, metadata, audio_path, align_kwargs)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 159,
      "context": "log_path = work_dir / \"logs\" / \"align.log\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 221,
      "context": "def _invoke_align(self, segments, align_model, metadata, audio_path, kwargs):",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\align.py",
      "line": 226,
      "context": "metadata,",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 7,
      "context": "from dataclasses import dataclass, field",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 23,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 34,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 35,
      "context": "class WorkerPlan:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 44,
      "context": "_WORKER_MODEL: Optional[WhisperModel] = None",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 45,
      "context": "_WORKER_MODEL_OPTIONS: Dict[str, Any] = {}",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 46,
      "context": "_WORKER_LOG_PATH: Optional[Path] = None",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 49,
      "context": "def _worker_bootstrap(env: Dict[str, str], log_dir: str, model_opts: Dict[str, Any]) -> None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 56,
      "context": "global _WORKER_LOG_PATH, _WORKER_MODEL_OPTIONS",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 57,
      "context": "_WORKER_MODEL_OPTIONS = model_opts or {}",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 58,
      "context": "_WORKER_LOG_PATH = log_dir_path / f\"asr_worker_{os.getpid()}.log\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 61,
      "context": "def _worker_log(message: str) -> None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 62,
      "context": "if _WORKER_LOG_PATH is None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 65,
      "context": "_WORKER_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 66,
      "context": "with _WORKER_LOG_PATH.open(\"a\", encoding=\"utf-8\") as handle:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 72,
      "context": "def _ensure_worker_model() -> WhisperModel:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 73,
      "context": "global _WORKER_MODEL",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 74,
      "context": "if _WORKER_MODEL is not None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 75,
      "context": "return _WORKER_MODEL",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 78,
      "context": "model_name = _WORKER_MODEL_OPTIONS.get(\"model_name\", \"large-v3\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 79,
      "context": "requested_device = _WORKER_MODEL_OPTIONS.get(\"device\", \"auto\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 80,
      "context": "device = resolve_runtime_device(requested_device, logger=None, label=\"ASR worker\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 81,
      "context": "compute_type = _WORKER_MODEL_OPTIONS.get(\"compute_type\", \"auto\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 82,
      "context": "_WORKER_MODEL = WhisperModel(model_name, device=device, compute_type=compute_type)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 83,
      "context": "return _WORKER_MODEL",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 87,
      "context": "model = _ensure_worker_model()",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 160,
      "context": "_worker_log(f\"Segment {job['index']:05d} ➜ {output_path.name} ({len(chunks)} chunks)\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 195,
      "context": "def estimate_worker_count(self) -> int:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 196,
      "context": "return self._resolve_worker_count().count",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 201,
      "context": "work_dir: Path,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 211,
      "context": "jsonl_dir = work_dir / \"01_asr_jsonl\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 213,
      "context": "logs_dir = work_dir / \"logs\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 215,
      "context": "state_path = work_dir / \"manifest_state.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 217,
      "context": "jobs = self._read_manifest(manifest_path, work_dir, jsonl_dir)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 225,
      "context": "idle_plan = self._resolve_worker_count(len(jobs))",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 227,
      "context": "work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 234,
      "context": "\"worker_count\": idle_plan.count,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 250,
      "context": "worker_plan = self._resolve_worker_count(len(pending))",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 251,
      "context": "worker_count = worker_plan.count",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 253,
      "context": "worker_env = self._blas_env()",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 265,
      "context": "plan_suffix = self._format_worker_plan(worker_plan)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 267,
      "context": "\"ASR parallèle: segments=%d, device=%s, workers=%d%s\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 270,
      "context": "worker_count,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 278,
      "context": "max_workers=worker_count,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 279,
      "context": "initializer=_worker_bootstrap,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 280,
      "context": "initargs=(worker_env, str(logs_dir), model_opts),",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 284,
      "context": "while queue and len(inflight) < worker_count:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 332,
      "context": "work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 339,
      "context": "\"worker_count\": worker_count,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 357,
      "context": "def _read_manifest(self, manifest_path: Path, work_dir: Path, jsonl_dir: Path) -> List[SegmentJob]:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 380,
      "context": "data = json.load(handle)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 383,
      "context": "data.setdefault(\"segments\", {})",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 384,
      "context": "return data",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 461,
      "context": "def _resolve_worker_count(self, segment_count: int = 0) -> WorkerPlan:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 463,
      "context": "requested, source = self._requested_worker_setting()",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 466,
      "context": "requested, note = self._auto_worker_target(segments)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 474,
      "context": "resolved = self._clamp_workers(resolved, segments, f\"segments={segments}\", clamp_notes)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 476,
      "context": "resolved = self._clamp_workers(resolved, env_limit, f\"env={env_limit}\", clamp_notes)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 478,
      "context": "resolved = self._clamp_workers(resolved, core_limit, f\"cores={core_limit}\", clamp_notes)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 479,
      "context": "return WorkerPlan(",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 508,
      "context": "def _requested_worker_setting(self) -> Tuple[Optional[int], str]:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 509,
      "context": "if \"_workers_source\" in self.asr_cfg:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 510,
      "context": "source = self.asr_cfg.get(\"_workers_source\", \"cli\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 513,
      "context": "raw_value = self.asr_cfg.get(\"workers\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 515,
      "context": "raw_value = self.asr_cfg.get(\"max_workers\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 526,
      "context": "raise PipelineError(f\"Valeur asr.workers invalide: {raw_value}\") from exc",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 530,
      "context": "raise PipelineError(f\"Valeur asr.workers invalide: {raw_value}\") from exc",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 532,
      "context": "raise PipelineError(\"asr.workers doit être >= 1\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 535,
      "context": "def _auto_worker_target(self, segments: int) -> Tuple[int, str]:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 543,
      "context": "workers = max(1, min(cap, segments))",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 544,
      "context": "return workers, note",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 547,
      "context": "workers = max(1, min(cpu_cap, segments))",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 548,
      "context": "return workers, \"cpu auto\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 564,
      "context": "def _clamp_workers(self, current: int, limit: Optional[int], label: str, notes: List[str]) -> int:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 572,
      "context": "def _format_worker_plan(self, plan: WorkerPlan) -> str:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 579,
      "context": "parts.append(\"legacy max_workers\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 622,
      "context": "def _write_metrics(self, work_dir: Path, metrics: Dict[str, Any]) -> Dict[str, Any]:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\asr.py",
      "line": 623,
      "context": "metrics_path = work_dir / \"logs\" / \"metrics.json\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\audit.py",
      "line": 84,
      "context": "avg_sentences = sum(sec.get(\"metadata\", {}).get(\"sentence_count\", 0) for sec in sections) / len(sections)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\clean.py",
      "line": 2,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\clean.py",
      "line": 142,
      "context": "cleaned = unicodedata.normalize(\"NFC\", text or \"\").strip()",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\export.py",
      "line": 6,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\export.py",
      "line": 19,
      "context": "normalized = unicodedata.normalize(\"NFC\", text)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\export.py",
      "line": 155,
      "context": "max_workers = self._parallel_workers(len(jobs))",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\export.py",
      "line": 156,
      "context": "with ThreadPoolExecutor(max_workers=max_workers) as pool:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\export.py",
      "line": 189,
      "context": "def _parallel_workers(self, task_count: int) -> int:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\glossary.py",
      "line": 2,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\glossary.py",
      "line": 31,
      "context": "normalized = unicodedata.normalize(\"NFC\", value or \"\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\merger.py",
      "line": 22,
      "context": "work_dir: Path,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\merger.py",
      "line": 28,
      "context": "output_path = work_dir / \"02_merged_raw.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\merger.py",
      "line": 62,
      "context": "merge_log = work_dir / \"logs\" / \"merge.log\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 11,
      "context": "from importlib import metadata",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 54,
      "context": "from update_arte_outputs import refresh_arte_outputs as outputs_polisher",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 56,
      "context": "outputs_polisher = None",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 75,
      "context": "\"--allow-local-exports\",",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 77,
      "context": "help=\"Autorise temporairement paths.exports_dir à pointer dans le dépôt (dev).\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 89,
      "context": "parser.add_argument(\"--no-partial-export\", dest=\"no_partial_export\", action=\"store_true\", help=\"Interdit les exports si une étape échoue\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 90,
      "context": "parser.add_argument(\"--allow-partial-export\", dest=\"no_partial_export\", action=\"store_false\", help=\"Autorise des exports partiels\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 102,
      "context": "\"--asr-workers\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 103,
      "context": "dest=\"asr_workers\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 109,
      "context": "dest=\"asr_workers\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 111,
      "context": "help=\"Alias de --asr-workers\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 116,
      "context": "parser.add_argument(\"--align-workers\", dest=\"align_workers\", type=int, help=\"Workers WhisperX align (num_workers)\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 126,
      "context": "parser.add_argument(\"--export-parallel\", dest=\"export_parallel\", action=\"store_true\", help=\"Exports finaux en parallèle\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 127,
      "context": "parser.add_argument(\"--export-serial\", dest=\"export_parallel\", action=\"store_false\", help=\"Exports finaux en série\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 132,
      "context": "\"--polish-outputs\",",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 133,
      "context": "dest=\"polish_outputs\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 135,
      "context": "help=\"Applique le polish final sur les exports (confiances, JSONL enrichis, txt/md nettoyés).\",",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 139,
      "context": "parser.set_defaults(polish_outputs=False)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 175,
      "context": "self.allowed_exports = {\"md\", \"json\", \"vtt\"}",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 179,
      "context": "self.allow_local_exports = bool(getattr(args, \"allow_local_exports\", False))",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 183,
      "context": "allow_local_exports=self.allow_local_exports,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 186,
      "context": "self.work_root = self.paths[\"work_dir\"]",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 187,
      "context": "self.work_dir = self.work_root / self.media_path.stem",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 188,
      "context": "self.work_dir.mkdir(parents=True, exist_ok=True)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 190,
      "context": "(self.work_dir / sub).mkdir(parents=True, exist_ok=True)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 191,
      "context": "self.audio_path = self.work_dir / \"audio_16k.wav\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 193,
      "context": "self.manifest_path = self.work_dir / manifest_name",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 194,
      "context": "self.state_path = self.work_dir / \"manifest_state.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 200,
      "context": "self.global_log_dir = self.paths.get(\"logs_dir\", self.work_dir / \"logs\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 202,
      "context": "self.local_log_dir = self.work_dir / \"logs\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 219,
      "context": "invalid = [fmt for fmt in self.export_formats if fmt not in self.allowed_exports]",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 223,
      "context": "self.export_formats = sorted(self.allowed_exports)",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 238,
      "context": "self.outputs_cfg = config.get(\"outputs\", {})",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 243,
      "context": "self.post_state_path = self.work_dir / \"post_state.json\"",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 244,
      "context": "self.polish_outputs_enabled = bool(getattr(args, \"polish_outputs\", False))",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 247,
      "context": "\"outputs\": self.outputs_cfg,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 339,
      "context": "if args.asr_workers is not None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 340,
      "context": "if args.asr_workers <= 0:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 341,
      "context": "raise PipelineError(\"--asr-workers doit être >= 1\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 342,
      "context": "asr_cfg[\"workers\"] = int(args.asr_workers)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 343,
      "context": "asr_cfg[\"_workers_source\"] = \"cli\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 352,
      "context": "if args.align_workers is not None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 353,
      "context": "align_cfg[\"workers\"] = max(1, int(args.align_workers))",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 376,
      "context": "\"paths\": [\"work_dir\", \"exports_dir\", \"logs_dir\"],",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 396,
      "context": "if not any(key in asr_cfg for key in (\"workers\", \"max_workers\")):",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 397,
      "context": "raise PipelineError(\"Configuration stricte: 'asr.workers' (ou legacy max_workers) manquant\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 402,
      "context": "if set(formats) != self.allowed_exports:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 421,
      "context": "self.audio_path = self.preproc.run(self.media_path, self.work_dir, force=self.force)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 429,
      "context": "self.seg_info = self.segmenter.run(audio_path, self.work_dir, force=self.force)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 448,
      "context": "work_dir=self.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 478,
      "context": "work_dir=self.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 503,
      "context": "self.diarization_result = self.diarizer.run(audio_path, self.work_dir, speech_segments=speech_segments)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 523,
      "context": "self.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 538,
      "context": "segments_for_clean = self.refiner.run(audio_path, segments_for_clean, align_result[\"language\"], self.work_dir)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 544,
      "context": "structure_data = self._ensure_structure_stage(polished_segments, language, doc_id)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 545,
      "context": "chunks = self._ensure_chunk_stage(structure_data, language, doc_id)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 546,
      "context": "self._annotate_sentences_with_chunks(structure_data, chunks)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 547,
      "context": "sentences = self._flatten_sentences(structure_data)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 550,
      "context": "chunk_artifacts = self._write_chunk_artifacts(structure_data, chunks, doc_id, language)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 551,
      "context": "low_conf_entries = self._collect_low_conf_spans(structure_data, chunks, language)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 559,
      "context": "structure_data,",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 571,
      "context": "structure=structure_data,",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 587,
      "context": "\"structure\": structure_data,",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 598,
      "context": "self._maybe_polish_outputs()",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 608,
      "context": "with stage_timer(self.logger, \"Exports finaux\"):",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 623,
      "context": "# ---- helpers for cached data ----",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 625,
      "context": "polished_path = self.work_dir / \"05_polished.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 626,
      "context": "structure_path = self.work_dir / \"structure.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 627,
      "context": "cleaned_path = self.work_dir / \"04_cleaned.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 628,
      "context": "chunks_cache = self.work_dir / \"chunks.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 655,
      "context": "aligned_path = self.work_dir / \"03_aligned_whisperx.json\"",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 666,
      "context": "def _maybe_polish_outputs(self) -> None:",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 667,
      "context": "if not self.polish_outputs_enabled:",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 669,
      "context": "if outputs_polisher is None:",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 670,
      "context": "self.logger.warning(\"Option --polish-outputs ignorée (module indisponible).\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 673,
      "context": "self.logger.info(\"Option --polish-outputs ignorée en mode --dry-run.\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 676,
      "context": "summary = outputs_polisher(",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 677,
      "context": "self.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 688,
      "context": "self.logger.warning(\"Polish des exports ignoré (%s).\", reason)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 691,
      "context": "\"Polish des exports terminé (%d phrases / %d chunks / %d paragraphes).\",",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 697,
      "context": "self.logger.exception(\"Échec du polish final (--polish-outputs).\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 709,
      "context": "cache_path = self.work_dir / \"04_cleaned.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 730,
      "context": "cache_path = self.work_dir / \"05_polished.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 751,
      "context": "cache_path = self.work_dir / \"structure.json\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 759,
      "context": "structure_data = self.structurer.run(segments, language, doc_id, self.low_conf_threshold)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 760,
      "context": "payload = dict(structure_data)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 767,
      "context": "{\"schema_version\": SCHEMA_VERSION, \"language\": language, \"sections\": structure_data.get(\"sections\", [])},",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 774,
      "context": "cache_path = self.work_dir / \"chunks.json\"",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 869,
      "context": "txt_mode = str(self.outputs_cfg.get(\"clean_txt_mode\", \"human\")).lower()",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 886,
      "context": "export_default = str(self.outputs_cfg.get(\"clean_jsonl_payload\", \"both\")).lower()",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1122,
      "context": "avg = section.get(\"metadata\", {}).get(\"avg_confidence\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1148,
      "context": "self.work_dir / \"02_merged_raw.json\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1149,
      "context": "self.work_dir / \"03_aligned_whisperx.json\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1150,
      "context": "self.work_dir / \"04_cleaned.json\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1151,
      "context": "self.work_dir / \"05_polished.json\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1153,
      "context": "required_dirs = [self.work_dir / \"00_segments\", self.work_dir / \"01_asr_jsonl\"]",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1161,
      "context": "required_exports: List[Path] = []",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1166,
      "context": "required_exports.append(self.out_dir / f\"{stem}.{fmt_key}\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1168,
      "context": "required_exports.append(self.out_dir / f\"{stem}.chapters.json\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1175,
      "context": "required_exports.append(csv_path)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1176,
      "context": "missing_exports = [str(path) for path in required_exports if not path.exists()]",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1177,
      "context": "if missing_exports:",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1178,
      "context": "raise PipelineError(f\"Mode strict: exports requis manquants {missing_exports}\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1184,
      "context": "exports_map = {name: str(path) for name, path in (self.last_artifacts or {}).items()}",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1202,
      "context": "\"work_dir\": str(self.work_dir),",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1204,
      "context": "\"exports\": sorted(exports_map.keys()),",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1205,
      "context": "\"export_paths\": exports_map,",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1208,
      "context": "tmp_manifest_path = run_manifest_path.with_suffix(\".tmp\")",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1209,
      "context": "write_json(tmp_manifest_path, manifest)",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1211,
      "context": "os.replace(tmp_manifest_path, run_manifest_path)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1229,
      "context": "versions[pkg] = metadata.version(pkg)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1312,
      "context": "self.logger.info(\"--dry-run activé: arrêt avant exports finaux.\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1320,
      "context": "self.logger.info(\"Les artefacts work sont conservés par défaut (option --keep-build obsolète).\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1321,
      "context": "self.logger.info(\"Dossier de travail ➜ %s\", self.work_dir)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1329,
      "context": "\"02_merged_raw.json\": (self.work_dir / \"02_merged_raw.json\").exists(),",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1330,
      "context": "\"03_aligned_whisperx.json\": (self.work_dir / \"03_aligned_whisperx.json\").exists(),",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1331,
      "context": "\"04_cleaned.json\": (self.work_dir / \"04_cleaned.json\").exists(),",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1332,
      "context": "\"05_polished.json\": (self.work_dir / \"05_polished.json\").exists(),",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1338,
      "context": "\"Fenêtres: %ss + overlap %ss | workers cibles: %s\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1341,
      "context": "self.asr.estimate_worker_count(),",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\pipeline.py",
      "line": 1343,
      "context": "self.logger.info(\"Exports ➜ %s/%s.*\", self.out_dir, self.media_path.stem)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\preproc.py",
      "line": 12,
      "context": "def run(self, media_path: Path, work_dir: Path, force: bool = False) -> Path:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\preproc.py",
      "line": 24,
      "context": "work_dir.mkdir(parents=True, exist_ok=True)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\preproc.py",
      "line": 25,
      "context": "output = work_dir / \"audio_16k.wav\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\preproc.py",
      "line": 56,
      "context": "\"-map_metadata\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\segmenter.py",
      "line": 22,
      "context": "def run(self, audio_path: Path, work_dir: Path, force: bool = False) -> Dict[str, Path]:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\segmenter.py",
      "line": 25,
      "context": "work_dir.mkdir(parents=True, exist_ok=True)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\segmenter.py",
      "line": 26,
      "context": "segments_dir = work_dir / \"00_segments\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\segmenter.py",
      "line": 28,
      "context": "manifest_path = work_dir / self.manifest_name",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\segmenter.py",
      "line": 29,
      "context": "state_path = work_dir / \"manifest_state.json\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 27,
      "context": "return {\"index\": index, \"start\": None, \"end\": None, \"segments\": [], \"text\": [], \"sentences_data\": []}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 64,
      "context": "section[\"sentences_data\"].extend(self._segment_sentences(seg))",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 91,
      "context": "sentences = sec.pop(\"sentences_data\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 95,
      "context": "sec[\"metadata\"] = self._section_metadata(sentences)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 100,
      "context": "sec[\"metadata\"][\"low_span_ratio\"] = self._section_low_span_ratio(sentences, sec[\"duration\"])",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\structure.py",
      "line": 182,
      "context": "def _section_metadata(self, sentences: List[Dict]) -> Dict[str, Any]:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 2,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 84,
      "context": "normalized = unicodedata.normalize(\"NFC\", word or \"\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 128,
      "context": "normalized = unicodedata.normalize(\"NFC\", text)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 134,
      "context": "normalized = unicodedata.normalize(\"NFKC\", text or \"\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 167,
      "context": "decomposed = unicodedata.normalize(\"NFKD\", text)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\textnorm.py",
      "line": 168,
      "context": "return \"\".join(ch for ch in decomposed if not unicodedata.combining(ch))",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\text_cleaning.py",
      "line": 1,
      "context": "\"\"\"Shared helpers for text normalization/polish across exports.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 11,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 23,
      "context": "LOCAL_DATA_ENV_VAR = \"TS_ALLOW_LOCAL_DATA\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 135,
      "context": "data = yaml.safe_load(f) or {}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 136,
      "context": "return data",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 165,
      "context": "def prepare_paths(root: Path, cfg: Dict[str, Any], *, allow_local_exports: bool = False) -> Dict[str, Path]:",
      "scope": "source"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 168,
      "context": "\"inputs_dir\": root / \"inputs\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 169,
      "context": "\"work_dir\": root / \"work\",",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 170,
      "context": "\"exports_dir\": root / \"exports\",",
      "scope": "source"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 178,
      "context": "if key != \"inputs_dir\":",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 179,
      "context": "_validate_runtime_path(target, label=key, allow_local_exports=allow_local_exports and key == \"exports_dir\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 185,
      "context": "def _validate_runtime_path(path: Path, *, label: str, allow_local_exports: bool = False) -> None:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 186,
      "context": "if os.getenv(LOCAL_DATA_ENV_VAR):",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 194,
      "context": "if label == \"exports_dir\" and allow_local_exports:",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 195,
      "context": "_warn_local_exports(resolved)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 199,
      "context": "\"Configurez DATA_PIPELINE_ROOT / paths.<name> vers un partage NAS ou utilisez \"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 200,
      "context": "f\"{LOCAL_DATA_ENV_VAR}=1 uniquement en dev/test.\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 204,
      "context": "def _warn_local_exports(target: Path) -> None:",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 206,
      "context": "f\"[paths] WARNING: paths.exports_dir pointe vers {target} à l'intérieur du dépôt. \"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 207,
      "context": "\"Utilisez --allow-local-exports uniquement pour du debug ponctuel.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\utils.py",
      "line": 332,
      "context": "text = unicodedata.normalize(\"NFC\", text)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 8,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 13,
      "context": "\"exports_dir\",",
      "scope": "source"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 14,
      "context": "\"inputs_dir\",",
      "scope": "source"
    },
    {
      "pattern": "outputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 15,
      "context": "\"outputs_dir\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 16,
      "context": "\"work_dir\",",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 17,
      "context": "\"inputs\",",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 18,
      "context": "\"outputs\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 19,
      "context": "\"exports\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 20,
      "context": "\"work\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 21,
      "context": "\"data\",",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 22,
      "context": "\"tmp\",",
      "scope": "source"
    },
    {
      "pattern": "runs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 23,
      "context": "\"runs\",",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 25,
      "context": "LEGACY_DIRS: Sequence[str] = (\"inputs\", \"outputs\", \"exports\", \"work\", \"data\", \"tmp\", \"runs\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 39,
      "context": "\"work_in\",",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 40,
      "context": "\"tmp_whisperx\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 44,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 54,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 62,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\cleanup_audit.py",
      "line": 288,
      "context": "\"Merci de ne plus y écrire : utilisez `DATA_PIPELINE_ROOT` ou le partage NAS.\\n\",",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\nas_audit.py",
      "line": 11,
      "context": "(\"01_input\", \"Inputs bruts\"),",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\nas_audit.py",
      "line": 12,
      "context": "(\"02_output_source\", \"Sources ASR + work\"),",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\nas_audit.py",
      "line": 13,
      "context": "(\"03_output_RAG\", \"Exports RAG\"),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\nas_audit.py",
      "line": 20,
      "context": "parser.add_argument(\"--root\", default=os.getenv(\"DATA_PIPELINE_ROOT\"), help=\"Racine du NAS (DATA_PIPELINE_ROOT).\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\nas_audit.py",
      "line": 234,
      "context": "raise SystemExit(\"DATA_PIPELINE_ROOT non défini (utiliser --root).\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\postprocess_transcript.py",
      "line": 2,
      "context": "\"\"\"Orchestre le post-traitement/QA des exports de transcription.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\postprocess_transcript.py",
      "line": 21,
      "context": "parser.add_argument(\"--export-dir\", required=True, type=Path, help=\"Répertoire contenant les exports clean.txt/metrics.json...\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\postprocess_transcript.py",
      "line": 38,
      "context": "outputs = runner.run(args.export_dir, doc_id=args.doc_id)",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\postprocess_transcript.py",
      "line": 39,
      "context": "for key, path in outputs.items():",
      "scope": "source"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\stage_cleanup.py",
      "line": 11,
      "context": "IGNORE_PATTERNS = (\".git\", \".venv\", \"logs\", \"__pycache__\", \"tmp_whisperx\", \"control_room/frontend/node_modules\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\stage_cleanup.py",
      "line": 42,
      "context": "parser.add_argument(\"--timestamp\", default=None, help=\"Horodatage custom (tests).\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 8,
      "context": "- enrich JSONL exports with section titles",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 20,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 33,
      "context": "from validate_outputs import validate_export_bundle",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 44,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 132,
      "context": "metadata = section.get(\"metadata\") or {}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 133,
      "context": "metadata[\"avg_confidence\"] = stats[\"confidence_mean\"]",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 134,
      "context": "metadata[\"confidence_p05\"] = stats[\"confidence_p05\"]",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 135,
      "context": "metadata[\"low_span_ratio\"] = stats[\"low_span_ratio\"]",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 136,
      "context": "section[\"metadata\"] = metadata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 177,
      "context": "data = json.loads(trimmed)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 178,
      "context": "data[\"artifacts\"] = {}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 179,
      "context": "return data",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 263,
      "context": "def refresh_arte_outputs(",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 264,
      "context": "work_dir: Path,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 272,
      "context": "work_dir = Path(work_dir)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 275,
      "context": "aligned_path = work_dir / \"05_polished.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 276,
      "context": "structure_path = work_dir / \"structure.json\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 286,
      "context": "structure_data = json.loads(structure_path.read_text(encoding=\"utf-8\"))",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 287,
      "context": "update_sections_payload(structure_data.get(\"sections\", []), word_index, low_threshold)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 288,
      "context": "structure_path.write_text(json.dumps(structure_data, ensure_ascii=False, indent=2), encoding=\"utf-8\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 290,
      "context": "chapters_data = json.loads(export_paths[\"chapters\"].read_text(encoding=\"utf-8\"))",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 291,
      "context": "update_sections_payload(chapters_data.get(\"sections\", []), word_index, low_threshold)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 292,
      "context": "section_titles = {section[\"section_id\"]: section.get(\"title\") for section in chapters_data.get(\"sections\", [])}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 293,
      "context": "export_paths[\"chapters\"].write_text(json.dumps(chapters_data, ensure_ascii=False, indent=2), encoding=\"utf-8\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 366,
      "context": "for section in chapters_data.get(\"sections\", []):",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 367,
      "context": "metadata = section.get(\"metadata\") or {}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 379,
      "context": "\"lang\": chapters_data.get(\"language\"),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 380,
      "context": "\"confidence_mean\": metadata.get(\"avg_confidence\"),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 381,
      "context": "\"confidence_p05\": metadata.get(\"confidence_p05\"),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 382,
      "context": "\"low_span_ratio\": metadata.get(\"low_span_ratio\"),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 391,
      "context": "metrics_data = try_load_json(export_paths[\"metrics\"])",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 392,
      "context": "metrics_data[\"phrases_total\"] = len(clean_entries)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 393,
      "context": "metrics_data[\"chunks_total\"] = len(chunk_entries)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 395,
      "context": "metrics_data[\"chunk_confidence_mean\"] = round(statistics.mean(mid_conf), 3) if mid_conf else None",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 398,
      "context": "metrics_data[\"low_conf_count\"] = sentence_low_conf_count",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 400,
      "context": "metrics_data[\"confidence\"] = {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 405,
      "context": "artifacts = metrics_data.setdefault(\"artifacts\", {})",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 411,
      "context": "export_paths[\"metrics\"].write_text(json.dumps(metrics_data, ensure_ascii=False, indent=2), encoding=\"utf-8\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 425,
      "context": "f\"- Chunk-level confidence mean: {metrics_data.get('chunk_confidence_mean')} over {len(chunk_entries)} chunks\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 453,
      "context": "parser = argparse.ArgumentParser(description=\"Recalcule les confiances et enrichit les exports ARTE.\")",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 454,
      "context": "parser.add_argument(\"--work-dir\", type=Path, required=True, help=\"Répertoire work/… contenant structure.json + 05_polished.json\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 455,
      "context": "parser.add_argument(\"--export-dir\", type=Path, required=True, help=\"Dossier exports/TRANSCRIPT - …\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 461,
      "context": "refresh_arte_outputs(",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\update_arte_outputs.py",
      "line": 462,
      "context": "work_dir=args.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\validate_outputs.py",
      "line": 2,
      "context": "\"\"\"Validation helpers for polished transcript exports.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\validate_outputs.py",
      "line": 87,
      "context": "raise RuntimeError(f\"Validation des exports échouée:\\n- {formatted}\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\validate_outputs.py",
      "line": 91,
      "context": "parser = argparse.ArgumentParser(description=\"Valide les exports d'un transcript (clean/chunks/low_confidence/metrics).\")",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\validate_outputs.py",
      "line": 92,
      "context": "parser.add_argument(\"--export-dir\", type=Path, required=True, help=\"Répertoire contenant les exports (clean.jsonl, metrics.json, etc.)\")",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tools\\validate_outputs.py",
      "line": 102,
      "context": "print(f\"[validate_outputs] Erreur: {exc}\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_exports\\README.md",
      "line": 4,
      "context": "Merci de ne plus y écrire : utilisez DATA_PIPELINE_ROOT ou le partage NAS.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_inputs\\README.md",
      "line": 4,
      "context": "Merci de ne plus y écrire : utilisez DATA_PIPELINE_ROOT ou le partage NAS.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_inputs_final\\README.md",
      "line": 3,
      "context": "Ce dossier a été renommé dans le cadre du cleanup. N'y écrivez plus : utilisez DATA_PIPELINE_ROOT ou un dossier adjacent au média.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\README.md",
      "line": 4,
      "context": "Merci de ne plus y écrire : utilisez DATA_PIPELINE_ROOT ou le partage NAS.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\models.py",
      "line": 3,
      "context": "from dataclasses import dataclass, field",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\models.py",
      "line": 8,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\models.py",
      "line": 19,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\models.py",
      "line": 45,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\models.py",
      "line": 73,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\postproc\\__init__.py",
      "line": 1,
      "context": "\"\"\"Post-processing helpers for transcript exports.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\cli.py",
      "line": 43,
      "context": "parser.add_argument(\"--input\", required=True, help=\"Chemin vers work/<doc>, TRANSCRIPT - <doc> ou dossier RAG.\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\configuration.py",
      "line": 5,
      "context": "from dataclasses import dataclass, field",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\configuration.py",
      "line": 30,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\configuration.py",
      "line": 32,
      "context": "\"\"\"Carries the effective config plus provenance metadata.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 1,
      "context": "\"\"\"Validation for RAG exports.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 7,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 21,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 275,
      "context": "except sqlite3.DatabaseError as exc:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 296,
      "context": "except sqlite3.DatabaseError as exc:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 302,
      "context": "except sqlite3.DatabaseError:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 308,
      "context": "work_dir = self._resolve_manifest_work_dir(manifest)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 309,
      "context": "if not work_dir:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 311,
      "context": "suggested = work_dir / \"rag.glossary.suggested.yaml\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 312,
      "context": "validated = work_dir / \"rag.glossary.yaml\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doctor.py",
      "line": 316,
      "context": "def _resolve_manifest_work_dir(self, manifest: Dict[str, Any]) -> Optional[Path]:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doc_id.py",
      "line": 7,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\doc_id.py",
      "line": 15,
      "context": "normalized = unicodedata.normalize(\"NFKD\", text)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\generation.py",
      "line": 223,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\generation.py",
      "line": 491,
      "context": "\"CREATE TABLE metadata (key TEXT PRIMARY KEY, value TEXT)\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\generation.py",
      "line": 493,
      "context": "conn.execute(\"INSERT INTO metadata(key, value) VALUES (?, ?)\", (\"schema_version\", RAG_SCHEMA_VERSION))",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\glossary.py",
      "line": 20,
      "context": "data = yaml.safe_load(path.read_text(encoding=\"utf-8\")) or {}",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\glossary.py",
      "line": 23,
      "context": "rules = data.get(\"rules\")",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 9,
      "context": "from dataclasses import dataclass, field",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 72,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 82,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 92,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 96,
      "context": "work_dir: Path",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 102,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 117,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 193,
      "context": "return context.work_dir / \"rag.glossary.suggested.yaml\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 224,
      "context": "source_path = self.options.source_path or (context.work_dir / \"rag.glossary.suggested.yaml\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 225,
      "context": "target_path = self.options.target_path or (context.work_dir / \"rag.glossary.yaml\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 256,
      "context": "self.logger.warning(\"Source introuvable pour .lexicon_ok.json dans %s\", context.work_dir)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 263,
      "context": "context.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 503,
      "context": "work = context.work_dir",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 504,
      "context": "if not work:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 507,
      "context": "work / \"05_polished.json\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 508,
      "context": "work / \"04_cleaned.json\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 509,
      "context": "work / \"02_merged_raw.json\",",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 518,
      "context": "work_dir: Path,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 525,
      "context": "stamp_path = work_dir / STAMP_FILENAME",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 570,
      "context": "str(resolved.media_path or resolved.work_dir),",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 574,
      "context": "texts = collect_texts_from_work(resolved)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 578,
      "context": "work_dir=resolved.work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 599,
      "context": "work_dir = resolve_work_dir_from_manifest(manifest) or rag_dir",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 604,
      "context": "work_dir=work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 611,
      "context": "def collect_texts_from_work(resolved: ResolvedPaths) -> List[str]:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\lexicon_scan.py",
      "line": 679,
      "context": "def resolve_work_dir_from_manifest(manifest: Dict[str, Any]) -> Optional[Path]:",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\pipeline.py",
      "line": 1,
      "context": "\"\"\"Helpers for NAS data-pipeline overrides.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\pipeline.py",
      "line": 9,
      "context": "PIPELINE_ROOT_ENV = \"DATA_PIPELINE_ROOT\"",
      "scope": "source"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\pipeline.py",
      "line": 21,
      "context": "\"\"\"Return the pipeline override for RAG outputs if configured.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\query.py",
      "line": 7,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\query.py",
      "line": 19,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 5,
      "context": "from dataclasses import dataclass, field",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 12,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 16,
      "context": "work_dir: Path",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 35,
      "context": "self.work_root = self.project_root / \"work\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 40,
      "context": "work_dir: Optional[Path] = None",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 47,
      "context": "work_dir = self._guess_work_dir(doc_name, strict=False) or self._search_nearby_work_dir(entry, doc_name)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 50,
      "context": "work_dir = entry",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 55,
      "context": "work_dir = self._guess_work_dir(doc_name, strict=False) or self._search_nearby_work_dir(entry, doc_name)",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 57,
      "context": "# Maybe user pointed directly to doc name under work root",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 60,
      "context": "work_dir = entry",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 63,
      "context": "# try treat as doc name within work",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 65,
      "context": "work_dir = self._guess_work_dir(doc_name, strict=False)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 66,
      "context": "if work_dir is None:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 67,
      "context": "raise PipelineError(f\"Impossible d'inférer le dossier work pour: {entry}\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 69,
      "context": "if not work_dir or not work_dir.exists():",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 70,
      "context": "raise PipelineError(f\"Dossier work introuvable pour: {entry}\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 73,
      "context": "polished_path = work_dir / \"05_polished.json\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 75,
      "context": "raise PipelineError(f\"05_polished.json introuvable dans {work_dir}\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 81,
      "context": "work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 86,
      "context": "[transcript_dir, work_dir],",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 90,
      "context": "[transcript_dir, work_dir],",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 94,
      "context": "[transcript_dir, work_dir],",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 99,
      "context": "[transcript_dir, work_dir],",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 103,
      "context": "[work_dir],",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 117,
      "context": "doc_title = doc_name or work_dir.name",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 130,
      "context": "self.logger.info(\"Sources détectées: work=%s transcript=%s\", work_dir, transcript_dir or \"n/a\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 134,
      "context": "work_dir=work_dir,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 147,
      "context": "def _guess_work_dir(self, doc_name: str, strict: bool = True) -> Optional[Path]:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 148,
      "context": "candidate = (self.work_root / doc_name).resolve()",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 151,
      "context": "for child in self.work_root.glob(\"*\"):",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 155,
      "context": "raise PipelineError(f\"Dossier work introuvable pour '{doc_name}'\")",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 158,
      "context": "def _search_nearby_work_dir(self, entry: Path, doc_name: Optional[str]) -> Optional[Path]:",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\resolver.py",
      "line": 166,
      "context": "parents = [current, current / \"work\"]",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 9,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 41,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 212,
      "context": "validated_rules = self._load_validated_glossary(resolved.work_dir)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 260,
      "context": "source_key = str(resolved.media_path or resolved.work_dir)",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 369,
      "context": "def _load_validated_glossary(self, work_dir: Path) -> List[Dict[str, str]]:",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\runner.py",
      "line": 370,
      "context": "candidate = work_dir / \"rag.glossary.yaml\"",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\targets.py",
      "line": 42,
      "context": "str(resolved.media_path or resolved.work_dir),",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 6,
      "context": "import unicodedata",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 7,
      "context": "from dataclasses import dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 40,
      "context": "@dataclass",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 71,
      "context": "return unicodedata.normalize(\"NFC\", fixed)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 72,
      "context": "return unicodedata.normalize(\"NFC\", raw)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\text_processing.py",
      "line": 109,
      "context": "normalized = unicodedata.normalize(\"NFC\", normalized)",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\src\\rag_export\\__init__.py",
      "line": 1,
      "context": "\"\"\"RAG export package metadata and helpers.\"\"\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_audit.py",
      "line": 25,
      "context": "structure = {\"language\": \"fr\", \"sections\": [{\"metadata\": {\"sentence_count\": 3}}]}",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 9,
      "context": "def test_collect_references_detects_keywords(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 10,
      "context": "project = tmp_path / \"transcribe-suite\"",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 13,
      "context": "sample.write_text(\"exports_dir = 'exports/legacy'\\n\", encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 16,
      "context": "assert any(ref.pattern == \"exports_dir\" for ref in refs)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 19,
      "context": "def test_specific_keyword_precedes_generic(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 20,
      "context": "project = tmp_path / \"transcribe-suite\"",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 23,
      "context": "sample.write_text(\"exports_dir = exports\\n\", encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 26,
      "context": "assert refs[0].pattern == \"exports_dir\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 29,
      "context": "def test_build_report_lists_directories(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 30,
      "context": "project = tmp_path / \"transcribe-suite\"",
      "scope": "tests"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 31,
      "context": "(project / \"inputs\").mkdir(parents=True)",
      "scope": "tests"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 35,
      "context": "assert \"inputs\" in report",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 38,
      "context": "def test_inventory_and_action_plan(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 39,
      "context": "project = tmp_path / \"transcribe-suite\"",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 40,
      "context": "(project / \"exports\").mkdir(parents=True)",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 45,
      "context": "assert actions and actions[0][\"source\"].endswith(\"exports\")",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 46,
      "context": "target = cleanup_audit.next_deprecated_target(project, \"exports\")",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 47,
      "context": "assert target.name == \"_deprecated_exports\"",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 49,
      "context": "target2 = cleanup_audit.next_deprecated_target(project, \"exports\")",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 50,
      "context": "assert target2.name == \"_deprecated_exports_2\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 53,
      "context": "def test_rename_supports_dry_run(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 54,
      "context": "project = tmp_path / \"transcribe-suite\"",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 55,
      "context": "(project / \"work\").mkdir(parents=True)",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 60,
      "context": "assert (project / \"_deprecated_work\").exists() is False",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 62,
      "context": "assert (project / \"_deprecated_work\").exists()",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 63,
      "context": "readme = project / \"_deprecated_work\" / \"README.md\"",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 67,
      "context": "def test_resolve_outputs_logs(tmp_path: Path, monkeypatch) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 68,
      "context": "repo = (tmp_path / \"repo_pkg\")",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 84,
      "context": "def test_resolve_outputs_docs(tmp_path: Path, monkeypatch) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_cleanup_audit_tool.py",
      "line": 85,
      "context": "repo = tmp_path / \"repo\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 6,
      "context": "def test_exporter_writes_utf8(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 12,
      "context": "out_dir=tmp_path,",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 15,
      "context": "aligned_path=tmp_path / \"aligned.json\",",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 19,
      "context": "data = txt_path.read_bytes()",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 20,
      "context": "assert data.startswith(\"A: Salut\".encode(\"utf-8\"))",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 21,
      "context": "assert b\"\\r\\n\" not in data",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 24,
      "context": "def test_low_confidence_markup(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 65,
      "context": "out_dir=tmp_path,",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 68,
      "context": "aligned_path=tmp_path / \"aligned.json\",",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 79,
      "context": "def test_clean_txt_export(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 99,
      "context": "out_dir=tmp_path,",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_export.py",
      "line": 102,
      "context": "aligned_path=tmp_path / \"aligned.json\",",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 10,
      "context": "def test_build_audit_handles_orphans(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 11,
      "context": "root = tmp_path / \"nas\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 21,
      "context": "def test_archive_docs_moves_with_apply(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 22,
      "context": "root = tmp_path / \"nas\"",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 33,
      "context": "def test_nas_audit_outputs(tmp_path: Path, monkeypatch) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 34,
      "context": "root = tmp_path / \"nas\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 50,
      "context": "def test_stage_path_builder(tmp_path: Path) -> None:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_nas_audit.py",
      "line": 51,
      "context": "repo = tmp_path / \"repo\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 18,
      "context": "def _build_runner(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 22,
      "context": "media_parent = tmp_path / \"media\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 27,
      "context": "runner.work_dir = tmp_path / \"work\" / runner.media_path.stem",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 28,
      "context": "runner.work_dir.mkdir(parents=True, exist_ok=True)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 29,
      "context": "runner.audio_path = runner.work_dir / \"audio_16k.wav\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 31,
      "context": "runner.manifest_path = runner.work_dir / \"manifest.csv\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 35,
      "context": "(runner.work_dir / name).write_text(json.dumps({}), encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 37,
      "context": "(runner.work_dir / sub).mkdir(exist_ok=True)",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 39,
      "context": "runner.out_dir = tmp_path / \"exports\" / f\"TRANSCRIPT - {runner.media_path.stem}\"",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 54,
      "context": "def test_verify_artifacts_allows_extra_exports(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 55,
      "context": "runner = _build_runner(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 63,
      "context": "def test_verify_artifacts_missing_export_fails(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_artifacts.py",
      "line": 64,
      "context": "runner = _build_runner(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 15,
      "context": "def _bootstrap_runner(tmp_path: Path) -> PipelineRunner:",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 17,
      "context": "runner.media_path = tmp_path / \"demo.mp4\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 20,
      "context": "runner.config_path = tmp_path / \"config.yaml\"",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 29,
      "context": "runner.out_dir = tmp_path / \"exports\" / \"TRANSCRIPT - demo\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 32,
      "context": "runner.work_dir = tmp_path / \"work\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 33,
      "context": "runner.work_dir.mkdir()",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 34,
      "context": "runner.local_log_dir = runner.work_dir / \"logs\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 41,
      "context": "def test_finalize_run_writes_export_dir(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 42,
      "context": "runner = _bootstrap_runner(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_pipeline_manifest.py",
      "line": 49,
      "context": "assert payload[\"exports\"] == [\"md\"]",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 56,
      "context": "def test_postprocess_runner_end_to_end(tmp_path: Path):",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 57,
      "context": "export_dir = tmp_path / \"exports\"",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 113,
      "context": "outputs = runner.run(export_dir, doc_id=\"demo\")",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 115,
      "context": "normalized = outputs[\"normalized\"].read_text(encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 117,
      "context": "final = outputs[\"final\"].read_text(encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 119,
      "context": "markdown = outputs[\"markdown\"].read_text(encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_postproc.py",
      "line": 121,
      "context": "qa = json.loads(outputs[\"qa\"].read_text(encoding=\"utf-8\"))",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 16,
      "context": "def _build_temp_config(tmp_path: Path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 17,
      "context": "output_root = tmp_path / \"rag-out\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 18,
      "context": "log_root = tmp_path / \"rag-logs\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 19,
      "context": "cfg_path = tmp_path / \"rag.yaml\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 90,
      "context": "def _prepare_export(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 91,
      "context": "cfg_path, output_root = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 92,
      "context": "work_dir = FIXTURE_ROOT / \"work\" / \"sample_doc\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 93,
      "context": "doc_id = compute_doc_id(\"sample_doc\", str(work_dir))",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 95,
      "context": "return cfg_path, output_root, work_dir, doc_id, target_dir",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 102,
      "context": "def test_rag_export_dry_run(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 103,
      "context": "cfg_path, output_root = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 109,
      "context": "def test_rag_export_generates_artifacts(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 110,
      "context": "cfg_path, output_root, work_dir, doc_id, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 111,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 140,
      "context": "def test_rag_export_idempotent(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 141,
      "context": "cfg_path, output_root, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 142,
      "context": "base_args = [\"--input\", str(work_dir), \"--config\", str(cfg_path), \"--force\"]",
      "scope": "tests"
    },
    {
      "pattern": "runs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 148,
      "context": "assert (target_dir / name).read_bytes() == first_run[name], f\"{name} differs between runs\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 151,
      "context": "def test_provenance_manifest(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 152,
      "context": "cfg_path, _, work_dir, doc_id, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 153,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 170,
      "context": "def test_rag_doctor_ok(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 171,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 172,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 176,
      "context": "def test_rag_doctor_missing_file(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 177,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 178,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 184,
      "context": "def test_rag_doctor_detects_mojibake(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 185,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 186,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 202,
      "context": "def test_sqlite_fts_query_smoke(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 203,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 204,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 216,
      "context": "def test_rag_query_cli(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 217,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 218,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 225,
      "context": "def test_rag_query_missing_db(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 226,
      "context": "cfg_path, _, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 227,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 236,
      "context": "def test_rag_export_pipeline_root_override(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 237,
      "context": "cfg_path, _, work_dir, doc_id, _ = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 238,
      "context": "pipeline_root = tmp_path / \"pipeline_root\"",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 240,
      "context": "extra_env = {\"DATA_PIPELINE_ROOT\": str(pipeline_root)}",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 241,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path), \"--force\"], extra_env=extra_env)",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 247,
      "context": "def test_rag_export_without_pipeline_root_keeps_default(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 248,
      "context": "cfg_path, output_root, work_dir, _, target_dir = _prepare_export(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_export_cli.py",
      "line": 249,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 12,
      "context": "def _copy_work_tree(tmp_path, doc_name=\"sample_doc_lexicon\"):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 13,
      "context": "bundle = tmp_path / \"bundle\"",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 14,
      "context": "work_src = FIXTURE_ROOT / \"work\" / doc_name",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 16,
      "context": "work_dst = bundle / \"work\" / doc_name",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 18,
      "context": "shutil.copytree(work_src, work_dst, dirs_exist_ok=True)",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 20,
      "context": "return work_dst, doc_name",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 32,
      "context": "def test_lexicon_scan_produces_yaml(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 33,
      "context": "cfg_path, _ = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 34,
      "context": "work_dir, doc_name = _copy_work_tree(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 40,
      "context": "str(work_dir),",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 49,
      "context": "suggested = work_dir / \"rag.glossary.suggested.yaml\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 52,
      "context": "assert payload[\"doc_id\"] == compute_doc_id(doc_name, str(work_dir))",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 59,
      "context": "def test_lexicon_apply_creates_validated_file(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 60,
      "context": "cfg_path, _ = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 61,
      "context": "work_dir, doc_name = _copy_work_tree(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 67,
      "context": "str(work_dir),",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 79,
      "context": "str(work_dir),",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 84,
      "context": "validated = work_dir / \"rag.glossary.yaml\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 88,
      "context": "stamp_path = work_dir / \".lexicon_ok.json\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 91,
      "context": "assert stamp[\"doc\"] == compute_doc_id(doc_name, str(work_dir))",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 96,
      "context": "def test_rag_export_ignores_suggested_until_validated(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 97,
      "context": "cfg_path, output_root = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 98,
      "context": "work_dir, doc_name = _copy_work_tree(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 99,
      "context": "_run_cli([\"lexicon\", \"scan\", \"--input\", str(work_dir), \"--config\", str(cfg_path), \"--min-count\", \"1\"])",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 100,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path), \"--force\"])",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 101,
      "context": "doc_id = compute_doc_id(doc_name, str(work_dir))",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 111,
      "context": "str(work_dir),",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 116,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path), \"--force\"])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 121,
      "context": "def test_lexicon_stamp_updates_after_source_change(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 122,
      "context": "cfg_path, _ = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 123,
      "context": "work_dir, _ = _copy_work_tree(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 124,
      "context": "_run_cli([\"lexicon\", \"scan\", \"--input\", str(work_dir), \"--config\", str(cfg_path), \"--min-count\", \"1\"])",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 125,
      "context": "_run_cli([\"lexicon\", \"apply\", \"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 126,
      "context": "stamp_path = work_dir / \".lexicon_ok.json\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 128,
      "context": "polished = work_dir / \"05_polished.json\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 130,
      "context": "_run_cli([\"lexicon\", \"apply\", \"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 135,
      "context": "def test_rag_doctor_warns_on_pending_glossary(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 136,
      "context": "cfg_path, output_root = _build_temp_config(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 137,
      "context": "work_dir, doc_name = _copy_work_tree(tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 138,
      "context": "_run_cli([\"--input\", str(work_dir), \"--config\", str(cfg_path)])",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 139,
      "context": "doc_id = compute_doc_id(doc_name, str(work_dir))",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 141,
      "context": "suggested = work_dir / \"rag.glossary.suggested.yaml\"",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 155,
      "context": "cfg_data = yaml.safe_load(Path(cfg_path).read_text(encoding=\"utf-8\"))",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_rag_lexicon.py",
      "line": 156,
      "context": "log_dir_raw = cfg_data[\"rag\"][\"logging\"][\"log_dir\"]",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_refine.py",
      "line": 6,
      "context": "def test_refiner_marks_segments_and_applies_patch(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_refine.py",
      "line": 15,
      "context": "audio_path = tmp_path / \"audio.wav\"",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_refine.py",
      "line": 46,
      "context": "refined = refiner.run(audio_path, segments, \"fr\", tmp_path)",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 11,
      "context": "data = structurer.run(segments, language=\"fr\", source_id=\"media\", confidence_threshold=0.5)",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 12,
      "context": "assert data[\"sections\"]",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 13,
      "context": "assert \"title\" not in data[\"sections\"][0]",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 23,
      "context": "data = structurer.run(segments, language=\"fr\", source_id=\"media\", confidence_threshold=0.5)",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 24,
      "context": "assert \"title\" in data[\"sections\"][0]",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 27,
      "context": "def test_structure_emits_sentences_metadata():",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 34,
      "context": "data = structurer.run(segments, language=\"fr\", source_id=\"media\", confidence_threshold=0.5)",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 35,
      "context": "section = data[\"sections\"][0]",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 38,
      "context": "assert section[\"metadata\"][\"sentence_count\"] == len(section[\"sentences\"])",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_structure.py",
      "line": 39,
      "context": "assert \"S0\" in section[\"metadata\"][\"speaker_histogram\"]",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 4,
      "context": "from tools.update_arte_outputs import refresh_arte_outputs",
      "scope": "tests"
    },
    {
      "pattern": "outputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 7,
      "context": "def test_refresh_arte_outputs_skips_when_word_scores_missing(tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 8,
      "context": "work_dir = tmp_path / \"work\"",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 9,
      "context": "export_dir = tmp_path / \"exports\"",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 10,
      "context": "work_dir.mkdir()",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 13,
      "context": "(work_dir / \"05_polished.json\").write_text(json.dumps({\"segments\": []}), encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 14,
      "context": "(work_dir / \"structure.json\").write_text(json.dumps({\"sections\": []}), encoding=\"utf-8\")",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_update_arte_outputs.py",
      "line": 19,
      "context": "result = refresh_arte_outputs(work_dir, export_dir, doc_id=base_name)",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 12,
      "context": "monkeypatch.delenv(utils.LOCAL_DATA_ENV_VAR, raising=False)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 13,
      "context": "cfg = {\"paths\": {\"work_dir\": \"work\"}}",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 19,
      "context": "def test_prepare_paths_allows_override(monkeypatch, tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 20,
      "context": "monkeypatch.setenv(utils.LOCAL_DATA_ENV_VAR, \"1\")",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 21,
      "context": "cfg = {\"paths\": {\"work_dir\": \"work\"}}",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 22,
      "context": "result = utils.prepare_paths(tmp_path, cfg)",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 23,
      "context": "assert \"work_dir\" in result",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 24,
      "context": "assert result[\"work_dir\"].exists()",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 27,
      "context": "def test_exports_can_be_local_with_flag(monkeypatch, tmp_path):",
      "scope": "tests"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 28,
      "context": "monkeypatch.delenv(utils.LOCAL_DATA_ENV_VAR, raising=False)",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 31,
      "context": "\"exports_dir\": \"exports\",",
      "scope": "tests"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 32,
      "context": "\"work_dir\": str(tmp_path / \"work\"),",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 33,
      "context": "\"logs_dir\": str(tmp_path / \"logs\"),",
      "scope": "tests"
    },
    {
      "pattern": "tmp",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 34,
      "context": "\"cache_dir\": str(tmp_path / \"cache\"),",
      "scope": "tests"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 38,
      "context": "result = utils.prepare_paths(repo_root, cfg, allow_local_exports=True)",
      "scope": "tests"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\tests\\unit\\test_utils_paths.py",
      "line": 39,
      "context": "assert \"exports_dir\" in result",
      "scope": "tests"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\02_merged_raw.json",
      "line": 181,
      "context": "\"text\": \"aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\03_aligned_whisperx.json",
      "line": 2277,
      "context": "\"text\": \"aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\03_aligned_whisperx.json",
      "line": 2328,
      "context": "\"word\": \"workflow\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\03_aligned_whisperx.json",
      "line": 11249,
      "context": "\"word\": \"workflow\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\03_aligned_whisperx.json",
      "line": 17485,
      "context": "\"num_workers\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\04_cleaned.json",
      "line": 2368,
      "context": "\"text\": \"Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\04_cleaned.json",
      "line": 2369,
      "context": "\"text_human\": \"Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\04_cleaned.json",
      "line": 2370,
      "context": "\"text_machine\": \"Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\04_cleaned.json",
      "line": 2422,
      "context": "\"word\": \"workflow\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\05_polished.json",
      "line": 961,
      "context": "\"text\": \"Des éléments. Je vais vous montrer, je vais ajouter une image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher une autre image. J'aurais pu la coller si j'en Chercher une autre image. J'aurais pu La coller si j'en avais copié Une en mémoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importé l'image que j'avais générée. Bon c'est pas le cas ici, je vais à nouveau Cliquer sur add image, je vais Ouvrir cette image là et j'aimerais détourer Le sujet. Pour faire ça je vais cliquer sur Matting et ça va automatiquement Faire un détourage. mon image est détourée, j'ai des poignées de transformation tout autour Qui vont me permettre de faire des transformations de l'échelle. Maintenez Maj enfoncé pour faire Une transformation homothétique sinon vous risquez de faire des écrasements. Et ensuite Ben vous pouvez poser où vous voulez votre élément. Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire un retour en arrière, hop, , avec CTRL Z. Vous pouvez choisir l'épaisseur pour le trait, ici. Vous avez aussi la possibilité de changer, bien sûr, les couleurs. Bien sûr les couleurs et vous avez là des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'épaisseur que vous avez indiqué ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve un petit peu dommage, C'est qu'on n'a pas de calque, Donc les éléments ici, on ne peut pas les déplacer Une fois qu'on les a créés. On peut juste revenir en arrière à CTRL Z Si on s'est trompé et puis parfois ça bug un peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou là c'est un petit peu Gros ça peut pas aller au delà de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer là on va sortir avec une preview et dans la sortie avec preview masque preview Donc là, , on peut convertir ça en masque. Donc c'est soit vous dessinez une image, soit vous dessinez un masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et là, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi un noeud multitexte, vous pourrez aussi faire des textures Qui se répètent, vous avez un noeud qui permet de définir des images avec Des rapports largeur sur hauteur avancés, un noeud pour afficher tout ce que l'on souhaite, Un noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous intéresse surtout c'est ça, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc là vous le trouverez dans le manager, ça s'appelle S. Bundle et vous le trouvez là vous pouvez l'installer relancer confit etc donc le Noeud qui nous intéresse c'est paint pro ça se présente comme ça alors il faut zoomer un petit Peu on a des outils pinceau gomme ça c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des dégradés. On a une pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. Là, je peux choisir... Là, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\05_polished.json",
      "line": 962,
      "context": "\"text_human\": \"Des éléments. Je vais vous montrer, je vais ajouter une image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher une autre image. J'aurais pu la coller si j'en Chercher une autre image. J'aurais pu La coller si j'en avais copié Une en mémoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importé l'image que j'avais générée. Bon c'est pas le cas ici, je vais à nouveau Cliquer sur add image, je vais Ouvrir cette image là et j'aimerais détourer Le sujet. Pour faire ça je vais cliquer sur Matting et ça va automatiquement Faire un détourage. mon image est détourée, j'ai des poignées de transformation tout autour Qui vont me permettre de faire des transformations de l'échelle. Maintenez Maj enfoncé pour faire Une transformation homothétique sinon vous risquez de faire des écrasements. Et ensuite Ben vous pouvez poser où vous voulez votre élément. Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire un retour en arrière, hop, , avec CTRL Z. Vous pouvez choisir l'épaisseur pour le trait, ici. Vous avez aussi la possibilité de changer, bien sûr, les couleurs. Bien sûr les couleurs et vous avez là des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'épaisseur que vous avez indiqué ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve un petit peu dommage, C'est qu'on n'a pas de calque, Donc les éléments ici, on ne peut pas les déplacer Une fois qu'on les a créés. On peut juste revenir en arrière à CTRL Z Si on s'est trompé et puis parfois ça bug un peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou là c'est un petit peu Gros ça peut pas aller au delà de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer là on va sortir avec une preview et dans la sortie avec preview masque preview Donc là, , on peut convertir ça en masque. Donc c'est soit vous dessinez une image, soit vous dessinez un masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et là, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi un noeud multitexte, vous pourrez aussi faire des textures Qui se répètent, vous avez un noeud qui permet de définir des images avec Des rapports largeur sur hauteur avancés, un noeud pour afficher tout ce que l'on souhaite, Un noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous intéresse surtout c'est ça, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc là vous le trouverez dans le manager, ça s'appelle S. Bundle et vous le trouvez là vous pouvez l'installer relancer confit etc donc le Noeud qui nous intéresse c'est paint pro ça se présente comme ça alors il faut zoomer un petit Peu on a des outils pinceau gomme ça c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des dégradés. On a une pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. Là, je peux choisir... Là, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\05_polished.json",
      "line": 963,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\05_polished.json",
      "line": 2071,
      "context": "\"word\": \"workflow\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 24,
      "context": "\"text_human\": \"Aujourd'hui je vais vous montrer dans cette vidéo des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par un custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages très pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire une recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ça se présente, là aussi je vais faire une recherche sur forge plutôt que layer et j'ai Ce nœud ici qui est très intéressant car il va nous permettre d'assembler des images très Facilement. Alors d'abord on vous définit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir évidemment le panneau donc là on a la limite et on va pouvoir. Des éléments. Je vais vous montrer, je vais ajouter une image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher une autre image. J'aurais pu la coller si j'en Chercher une autre image. J'aurais pu La coller si j'en avais copié Une en mémoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importé l'image que j'avais générée. Bon c'est pas le cas ici, je vais à nouveau Cliquer sur add image, je vais Ouvrir cette image là et j'aimerais détourer Le sujet. Pour faire ça je vais cliquer sur Matting et ça va automatiquement Faire un détourage. mon image est détourée, j'ai des poignées de transformation tout autour Qui vont me permettre de faire des transformations de l'échelle. Maintenez Maj enfoncé pour faire Une transformation homothétique sinon vous risquez de faire des écrasements. Et ensuite Ben vous pouvez poser où vous voulez votre élément. Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 25,
      "context": "\"text_machine\": \"Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Aujourd'hui je vais vous montrer dans cette video des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI. On va commencer par 1 custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages tres pratiques. Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire 1 recherche sur forge Et vous avez ici, config. ui, layer forge, vous l'installez etc. Alors comment ca se presente, la aussi je vais faire 1 recherche sur forge plutot que layer et j'ai Ce n ud ici qui est tres interessant car il va nous permettre d'assembler des images tres Facilement. Alors d'abord on vous definit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir evidemment le panneau donc la on a la limite et on va pouvoir. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 212,
      "context": "\"text\": \"Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 247,
      "context": "\"text_human\": \"Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire un retour en arrière, hop, , avec CTRL Z. Vous pouvez choisir l'épaisseur pour le trait, ici. Vous avez aussi la possibilité de changer, bien sûr, les couleurs. Bien sûr les couleurs et vous avez là des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'épaisseur que vous avez indiqué ici Ou alors vous pouvez dessiner des rectangles.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 248,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 255,
      "context": "\"text\": \"Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 339,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\chunks.json",
      "line": 515,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,. , par exemple ca. Ca peut fonctionner aussi avec 1 tablette. Je vais pouvoir modifier l'opacite, la durete. Le flux l'espacement la pression etc et j'ai la tout en bas des presets et ce qui est interessant Aussi c'est qu'on a des presets pour les brosses la par exemple si je veux dessiner Avec 1 effet de peinture aquarelle hop j'obtiens ce de choses Alors on peut charger 1 image par exemple celle ci si je clique La je vais pouvoir sortir 1 preview je vais faire 1 clic droit demande a voir l'image alors la des fois ca deconne 1 peu Vous pouvez faire 1 clic droit dans le ne vous avez Pas mal de choses la vous pouvez faire 1 retour en arriere et c est Vous avez ici fixe node recreate si on fait ca Donc ca a efface nos dessins Il faut relancer pour ensuite pouvoir dessiner Pouvoir dessiner donc c'est encore 1 petit peu bancal mais c'est interessant de pouvoir faire Ca sans sortir de confit donc la par exemple je pourrais dessiner je sais pas 1 couleur dessus Je peux passer en mode masque en cliquant la et la je peux dessiner mon masque etc et si je mets 1 masque preview je peux vous montrer que le masque c'est ce que j'ai dessine ici on A la la possibilite de faire des degrades vous pouvez definir la couleur dans la colonne de Droite a cyclopacite et bien sur avec les formes vous pouvez decider d'avoir 1 contour Ou non et 1 fond de type couleur solide 1 gradient ou meme 1 motif par exemple 1 degrade Ca ferait ce de choses donc c'est tres pratique bon encore 1 fois il n'y a pas De calque et c'est 1 petit peu dommage mais ca nous permet encore 1 fois de pouvoir faire Ce de choses, de dessiner en tout cas Sans devoir sortir De ConfiUI. Donc pour ces 3 custom nodes, tres Interessant pour faire ce De choses. N'hesitez pas a nous dire Dans les commentaires si vous connaissez D'autres types de Commentaires si vous connaissez d'autres types de custom notes dans ce pour pouvoir dessiner ou pour faire du montage directement dans Confiouai. , par exemple ca. Ca peut fonctionner aussi avec 1 tablette. Je vais pouvoir modifier l'opacite, la durete. Le flux l'espacement la pression etc et j'ai la tout en bas des presets et ce qui est interessant Aussi c'est qu'on a des presets pour les brosses la par exemple si je veux dessiner Avec 1 effet de peinture aquarelle hop j'obtiens ce de choses Alors on peut charger 1 image par exemple celle ci si je clique La je vais pouvoir sortir 1 preview je vais faire 1 clic droit demande a voir l'image alors la des fois ca deconne 1 peu Vous pouvez faire 1 clic droit dans le ne vous avez Pas mal de choses la vous pouvez faire 1 retour en arriere et c est Vous avez ici fixe node recreate si on fait ca Donc ca a efface nos dessins Il faut relancer pour ensuite pouvoir dessiner Pouvoir dessiner donc c'est encore 1 petit peu bancal mais c'est interessant de pouvoir faire Ca sans sortir de confit donc la par exemple je pourrais dessiner je sais pas 1 couleur dessus Je peux passer en mode masque en cliquant la et la je peux dessiner mon masque etc et si je mets 1 masque preview je peux vous montrer que le masque c'est ce que j'ai dessine ici on A la la possibilite de faire des degrades vous pouvez definir la couleur dans la colonne de Droite a cyclopacite et bien sur avec les formes vous pouvez decider d'avoir 1 contour Ou non et 1 fond de type couleur solide 1 gradient ou meme 1 motif par exemple 1 degrade Ca ferait ce de choses donc c'est tres pratique bon encore 1 fois il n'y a pas De calque et c'est 1 petit peu dommage mais ca nous permet encore 1 fois de pouvoir faire Ce de choses, de dessiner en tout cas Sans devoir sortir De ConfiUI. Donc pour ces 3 custom nodes, tres Interessant pour faire ce De choses. N'hesitez pas a nous dire Dans les commentaires si vous connaissez D'autres types de Commentaires si vous connaissez d'autres types de custom notes dans ce pour pouvoir dessiner ou pour faire du montage directement dans Confiouai. , par exemple ca. Ca peut fonctionner aussi avec 1 tablette. Je vais pouvoir modifier l'opacite, la durete. Le flux l'espacement la pression etc et j'ai la tout en bas des presets et ce qui est interessant Aussi c'est qu'on a des presets pour les brosses la par exemple si je veux dessiner Avec 1 effet de peinture aquarelle hop j'obtiens ce de choses Alors on peut charger 1 image par exemple celle ci si je clique La je vais pouvoir sortir 1 preview je vais faire 1 clic droit demande a voir l'image alors la des fois ca deconne 1 peu Vous pouvez faire 1 clic droit dans le ne vous avez Pas mal de choses la vous pouvez faire 1 retour en arriere et c est Vous avez ici fixe node recreate si on fait ca Donc ca a efface nos dessins Il faut relancer pour ensuite pouvoir dessiner Pouvoir dessiner donc c'est encore 1 petit peu bancal mais c'est interessant de pouvoir faire Ca sans sortir de confit donc la par exemple je pourrais dessiner je sais pas 1 couleur dessus Je peux passer en mode masque en cliquant la et la je peux dessiner mon masque etc et si je mets 1 masque preview je peux vous montrer que le masque c'est ce que j'ai dessine ici on A la la possibilite de faire des degrades vous pouvez definir la couleur dans la colonne de Droite a cyclopacite et bien sur avec les formes vous pouvez decider d'avoir 1 contour Ou non et 1 fond de type couleur solide 1 gradient ou meme 1 motif par exemple 1 degrade Ca ferait ce de choses donc c'est tres pratique bon encore 1 fois il n'y a pas De calque et c'est 1 petit peu dommage mais ca nous permet encore 1 fois de pouvoir faire Ce de choses, de dessiner en tout cas Sans devoir sortir De ConfiUI. Donc pour ces 3 custom nodes, tres Interessant pour faire ce De choses. N'hesitez pas a nous dire Dans les commentaires si vous connaissez D'autres types de Commentaires si vous connaissez d'autres types de custom notes dans ce pour pouvoir dessiner ou pour faire du montage directement dans Confiouai. , par exemple ca. Ca peut fonctionner aussi avec 1 tablette. Je vais pouvoir modifier l'opacite, la durete. Le flux l'espacement la pression etc et j'ai la tout en bas des presets et ce qui est interessant Aussi c'est qu'on a des presets pour les brosses la par exemple si je veux dessiner Avec 1 effet de peinture aquarelle hop j'obtiens ce de choses Alors on peut charger 1 image par exemple celle ci si je clique La je vais pouvoir sortir 1 preview je vais faire 1 clic droit demande a voir l'image alors la des fois ca deconne 1 peu Vous pouvez faire 1 clic droit dans le ne vous avez Pas mal de choses la vous pouvez faire 1 retour en arriere et c est Vous avez ici fixe node recreate si on fait ca Donc ca a efface nos dessins Il faut relancer pour ensuite pouvoir dessiner Pouvoir dessiner donc c'est encore 1 petit peu bancal mais c'est interessant de pouvoir faire Ca sans sortir de confit donc la par exemple je pourrais dessiner je sais pas 1 couleur dessus Je peux passer en mode masque en cliquant la et la je peux dessiner mon masque etc et si je mets 1 masque preview je peux vous montrer que le masque c'est ce que j'ai dessine ici on A la la possibilite de faire des degrades vous pouvez definir la couleur dans la colonne de Droite a cyclopacite et bien sur avec les formes vous pouvez decider d'avoir 1 contour Ou non et 1 fond de type couleur solide 1 gradient ou meme 1 motif par exemple 1 degrade Ca ferait ce de choses donc c'est tres pratique bon encore 1 fois il n'y a pas De calque et c'est 1 petit peu dommage mais ca nous permet encore 1 fois de pouvoir faire Ce de choses, de dessiner en tout cas Sans devoir sortir De ConfiUI. Donc pour ces 3 custom nodes, tres Interessant pour faire ce De choses. N'hesitez pas a nous dire Dans les commentaires si vous connaissez D'autres types de Commentaires si vous connaissez d'autres types de custom notes dans ce pour pouvoir dessiner ou pour faire du montage directement dans Confiouai.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 7,
      "context": "\"paragraph\": \"Aujourd'hui je vais vous montrer dans cette vidéo des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI.On va commencer par un custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages très pratiques.Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire une recherche sur forge Et vous avez ici, config.ui, layer forge, vous l'installez etc.Alors comment ça se présente, là aussi je vais faire une recherche sur forge plutôt que layer et j'ai Ce nœud ici qui est très intéressant car il va nous permettre d'assembler des images très Facilement.Alors d'abord on vous définit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir évidemment le panneau donc là on a la limite et on va pouvoir.Des éléments.Je vais vous montrer, je vais ajouter une image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher une autre image.J'aurais pu la coller si j'en Chercher une autre image.J'aurais pu La coller si j'en avais copié Une en mémoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importé l'image que j'avais générée.Bon c'est pas le cas ici, je vais à nouveau Cliquer sur add image, je vais Ouvrir cette image là et j'aimerais détourer Le sujet.Pour faire ça je vais cliquer sur Matting et ça va automatiquement Faire un détourage.mon image est détourée, j'ai des poignées de transformation tout autour Qui vont me permettre de faire des transformations de l'échelle.Maintenez Maj enfoncé pour faire Une transformation homothétique sinon vous risquez de faire des écrasements.Et ensuite Ben vous pouvez poser où vous voulez votre élément.Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.Vous pouvez faire un retour en arrière, hop, , avec CTRL Z.Vous pouvez choisir l'épaisseur pour le trait, ici.Vous avez aussi la possibilité de changer, bien sûr, les couleurs.Bien sûr les couleurs et vous avez là des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'épaisseur que vous avez indiqué ici Ou alors vous pouvez dessiner des rectangles.Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond.Ce que je trouve un petit peu dommage, C'est qu'on n'a pas de calque, Donc les éléments ici, on ne peut pas les déplacer Une fois qu'on les a créés.On peut juste revenir en arrière à CTRL Z Si on s'est trompé et puis parfois ça bug un peu.Pour choisir la taille de l'image vous pouvez indiquer ici taille ou là c'est un petit peu Gros ça peut pas aller au delà de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer là on va sortir avec une preview et dans la sortie avec preview masque preview Donc là, , on peut convertir ça en masque.Donc c'est soit vous dessinez une image, soit vous dessinez un masque.Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle.Et là, il y a pas mal de choses.On va pouvoir faire des titres, saisir du texte, Vous avez aussi un noeud multitexte, vous pourrez aussi faire des textures Qui se répètent, vous avez un noeud qui permet de définir des images avec Des rapports largeur sur hauteur avancés, un noeud pour afficher tout ce que l'on souhaite, Un noeud pour faire des switches, etc.Il y a pas mal de choses et ce qui nous intéresse surtout c'est ça, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI.Donc là vous le trouverez dans le manager, ça s'appelle S.Bundle et vous le trouvez là vous pouvez l'installer relancer confit etc donc le Noeud qui nous intéresse c'est paint pro ça se présente comme ça alors il faut zoomer un petit Peu on a des outils pinceau gomme ça c'est pour faire des remplissages peau de peinture on On peut faire des formes.Vous avez le trait, rectangle, ellipse.On peut faire des dégradés.On a une pipette.On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin.Et on a ici les settings.Je vais cliquer sur les settings pour ouvrir ce panneau.Là, je peux choisir.Là, je peux choisir la couleur de mon pinceau, La taille.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 109,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 124,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 139,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 154,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 169,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 184,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 199,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 214,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 229,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 242,
      "context": "\"text\": \"Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 243,
      "context": "\"text_human\": \"Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 244,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 259,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 274,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 289,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 304,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 319,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 334,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 349,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 364,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 379,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 394,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 409,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 424,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 439,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 454,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 469,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 484,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 499,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 514,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 529,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 544,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 559,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 574,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 589,
      "context": "\"text_machine\": \"Des elements. Je vais vous montrer, je vais ajouter 1 image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher 1 autre image. J'aurais pu la coller si j'en Chercher 1 autre image. J'aurais pu La coller si j'en avais copie 1 en memoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importe l'image que j'avais generee. Bon c'est pas le cas ici, je vais a nouveau Cliquer sur add image, je vais Ouvrir cette image la et j'aimerais detourer Le sujet. Pour faire ca je vais cliquer sur Matting et ca va automatiquement Faire 1 detourage. mon image est detouree, j'ai des poignees de transformation tout autour Qui vont me permettre de faire des transformations de l'echelle. Maintenez Maj enfonce pour faire 1 transformation homothetique sinon vous risquez de faire des ecrasements. Et ensuite Ben vous pouvez poser ou vous voulez votre element. Ca vous pouvez le sortir en En tant que image on peut voir ce que ca donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ca c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans 1 workflow de type image to image ou avec Controle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses a voir vous Pourrez jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres Jeter 1 oeil bien sur sur leur github vous avez des raccourcis interessant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est tres simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici 1 fois Que vous etes dans le dossier custom nodes vous allez dans la fenetre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ca va tout installer il ya rien d'autre a faire Vous relancer confie why et vous aurez acces a ce n'est qu'ils s'appellent olm Sketch qui est tres pratique je vais vous montrer ca vous permet de dessiner la vous Allez pouvoir faire des choses comme ca et ce qui est vachement bien c'est C'est que si vous avez 1 tablette, vous allez pouvoir dessiner avec votre tablette. Vous pouvez faire 1 retour en arriere, hop, , avec CTRL Z. Vous pouvez choisir l'epaisseur pour le trait, ici. Vous avez aussi la possibilite de changer, bien sur, les couleurs. Bien sur les couleurs et vous avez la des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'epaisseur que vous avez indique ici Ou alors vous pouvez dessiner des rectangles. Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond. Ce que je trouve 1 petit peu dommage, C'est qu'on n'a pas de calque, Donc les elements ici, on ne peut pas les deplacer 1 fois qu'on les a crees. On peut juste revenir en arriere a CTRL Z Si on s'est trompe et puis parfois ca bug 1 peu. Pour choisir la taille de l'image vous pouvez indiquer ici taille ou la c'est 1 petit peu Gros ca peut pas aller au dela de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer la on va sortir avec 1 preview et dans la sortie avec preview masque preview Donc la, , on peut convertir ca en masque. Donc c'est soit vous dessinez 1 image, soit vous dessinez 1 masque. Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle. Et la, il y a pas mal de choses. On va pouvoir faire des titres, saisir du texte, Vous avez aussi 1 noeud multitexte, vous pourrez aussi faire des textures Qui se repetent, vous avez 1 noeud qui permet de definir des images avec Des rapports largeur sur hauteur avances, 1 noeud pour afficher tout ce que l'on souhaite, 1 noeud pour faire des switches, etc. Il y a pas mal de choses et ce qui nous interesse surtout c'est ca, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI. Donc la vous le trouverez dans le manager, ca s'appelle S. Bundle et vous le trouvez la vous pouvez l'installer relancer confit etc donc le Noeud qui nous interesse c'est paint pro ca se presente comme ca alors il faut zoomer 1 petit Peu on a des outils pinceau gomme ca c'est pour faire des remplissages peau de peinture on On peut faire des formes. Vous avez le trait, rectangle, ellipse. On peut faire des degrades. On a 1 pipette. On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin. Et on a ici les settings. Je vais cliquer sur les settings pour ouvrir ce panneau. La, je peux choisir... La, je peux choisir la couleur de mon pinceau, La taille,.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 607,
      "context": "\"text\": \"Aujourd'hui je vais vous montrer dans cette vidéo des petits utilitaires bien Sympatoches pour dessiner ou pour manipuler des calques sans sortir de Konfi UI.On va commencer par un custom nodes qui nous permet de manipuler des Calques, enfin de faire des assemblages très pratiques.Il s'agit de Konfi UI Layer Forge Vous pouvez l'installer depuis le manager, vous allez dans le manager, custom node manager, vous allez faire une recherche sur forge Et vous avez ici, config.ui, layer forge, vous l'installez etc.Alors comment ça se présente, là aussi je vais faire une recherche sur forge plutôt que layer et j'ai Ce nœud ici qui est très intéressant car il va nous permettre d'assembler des images très Facilement.Alors d'abord on vous définit la taille de l'image si on veut du 1024 on saisit La bonne valeur on peut agrandir évidemment le panneau donc là on a la limite et on va pouvoir.Des éléments.Je vais vous montrer, je vais ajouter une image, par exemple celle-ci qui pourrait me Servir de fond et ensuite je vais aller chercher une autre image.J'aurais pu la coller si j'en Chercher une autre image.J'aurais pu La coller si j'en avais copié Une en mémoire ou j'aurais pu cliquer Sur import input ce qui m'aurait Importé l'image que j'avais générée.Bon c'est pas le cas ici, je vais à nouveau Cliquer sur add image, je vais Ouvrir cette image là et j'aimerais détourer Le sujet.Pour faire ça je vais cliquer sur Matting et ça va automatiquement Faire un détourage.mon image est détourée, j'ai des poignées de transformation tout autour Qui vont me permettre de faire des transformations de l'échelle.Maintenez Maj enfoncé pour faire Une transformation homothétique sinon vous risquez de faire des écrasements.Et ensuite Ben vous pouvez poser où vous voulez votre élément.Ça vous pouvez le sortir en En tant que image on peut voir ce que ça donne clic droit je clique sur cue selected output Nodes et je vais voir mon super photomontage donc c'est ça c'est super pratique lorsqu'on Aura besoin d'utiliser ce type d'image dans un workflow de type image to image ou avec Contrôle net ou avec ip adapter redux et j'en passe donc encore pas mal de choses à voir vous Pourrez jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres Jeter un oeil bien sûr sur leur github vous avez des raccourcis intéressant et d'autres choses Encore bien je vais vous montrer maintenant l'autre qui s'appelle au lm sketch malheureusement Il ne peut pas s'installer depuis le manager donc il vous faudra vous rendre sur cette Page vous irez suivre les recommandations pour l'installation c'est très simple il suffit de Vous rendre dans le dossier custom nodes vous allez cloner ce repos vous cliquez ici une fois Que vous êtes dans le dossier custom nodes vous allez dans la fenêtre de chemin en haut tapez cmd Vous coller ce que vous venez de copier et ça va tout installer il ya rien d'autre à faire Vous relancer confie why et vous aurez accès à ce n'est qu'ils s'appellent olm Sketch qui est très pratique je vais vous montrer ça vous permet de dessiner là vous Allez pouvoir faire des choses comme ça et ce qui est vachement bien c'est C'est que si vous avez une tablette, vous allez pouvoir dessiner avec votre tablette.Vous pouvez faire un retour en arrière, hop, , avec CTRL Z.Vous pouvez choisir l'épaisseur pour le trait, ici.Vous avez aussi la possibilité de changer, bien sûr, les couleurs.Bien sûr les couleurs et vous avez là des modes de fusion et on peut aussi dessiner des formes Donc au lieu de choisir freehand ici vous allez choisir par exemple line vous allez dessiner des lignes Avec l'épaisseur que vous avez indiqué ici Ou alors vous pouvez dessiner des rectangles.Si vous cliquez sur True au niveau de Fill Shapes, Vous allez remplir le fond.Ce que je trouve un petit peu dommage, C'est qu'on n'a pas de calque, Donc les éléments ici, on ne peut pas les déplacer Une fois qu'on les a créés.On peut juste revenir en arrière à CTRL Z Si on s'est trompé et puis parfois ça bug un peu.Pour choisir la taille de l'image vous pouvez indiquer ici taille ou là c'est un petit peu Gros ça peut pas aller au delà de 2,20 48 et vous pouvez aussi dessiner des masques je vais Vous montrer là on va sortir avec une preview et dans la sortie avec preview masque preview Donc là, , on peut convertir ça en masque.Donc c'est soit vous dessinez une image, soit vous dessinez un masque.Alors l'autre que je souhaite vous montrer, c'est celui-ci, ConfiWi SK Bundle.Et là, il y a pas mal de choses.On va pouvoir faire des titres, saisir du texte, Vous avez aussi un noeud multitexte, vous pourrez aussi faire des textures Qui se répètent, vous avez un noeud qui permet de définir des images avec Des rapports largeur sur hauteur avancés, un noeud pour afficher tout ce que l'on souhaite, Un noeud pour faire des switches, etc.Il y a pas mal de choses et ce qui nous intéresse surtout c'est ça, Paint Pro Node qui lui aussi permet de dessiner dans ConfiUI.Donc là vous le trouverez dans le manager, ça s'appelle S.Bundle et vous le trouvez là vous pouvez l'installer relancer confit etc donc le Noeud qui nous intéresse c'est paint pro ça se présente comme ça alors il faut zoomer un petit Peu on a des outils pinceau gomme ça c'est pour faire des remplissages peau de peinture on On peut faire des formes.Vous avez le trait, rectangle, ellipse.On peut faire des dégradés.On a une pipette.On va pouvoir passer en mode masque pour dessiner des masques en plus du dessin.Et on a ici les settings.Je vais cliquer sur les settings pour ouvrir ce panneau.Là, je peux choisir.Là, je peux choisir la couleur de mon pinceau, La taille.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 610,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\structure.json",
      "line": 733,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\03_aligned_whisperx.json",
      "line": 27679,
      "context": "\"num_workers\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 529,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 982,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 1309,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 1944,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 2397,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 2892,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 3639,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 4176,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 4713,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 5180,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 5829,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 6212,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 6875,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 7314,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 8089,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 8696,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 9345,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 9994,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 10377,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 10816,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 11395,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 12016,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 12791,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 13370,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 14075,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 14808,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 15779,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 16442,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 16867,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 17236,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 17759,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 18898,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 19617,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 20014,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 20789,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 21452,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 22003,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 22764,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 23161,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 24034,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 24711,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 25332,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 25897,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 26448,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 27111,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 27872,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 28535,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 29058,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 29679,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 30342,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 31089,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 31584,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 32051,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 32518,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 33951,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 35118,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 35879,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 36584,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\structure.json",
      "line": 36827,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 109,
      "context": "\"text\": \"jour. Vos données sont hébergées en Europe avec le Zero Data Retention, vos promptes ne sont pas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 175,
      "context": "\"text\": \"un immense dataset d'images et tu vas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 445,
      "context": "\"text\": \"Donc c'est typiquement un dataset qui s'appelle Common Crawl,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 529,
      "context": "\"text\": \"Dans les faits, ce qui se passe, c'est qu'on a des datasets où les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 547,
      "context": "\"text\": \"il y a Flickr, c'est un énorme dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 577,
      "context": "\"text\": \"datasets, qui sont des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 619,
      "context": "\"text\": \"et on va le corriger et il va lui faire apprendre sur un dataset. On pourrait s'attendre à\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 643,
      "context": "\"text\": \"Et c'est les premiers modèles qui ont été construits comme ça, les premiers datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2185,
      "context": "\"text\": \"Et là, pour le coup, tu peux être sur un dataset beaucoup plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2215,
      "context": "\"text\": \"Donc là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2635,
      "context": "\"text\": \"intégré à un workflow, c'est la publication de nos podcasts. Peut-être que vous vous\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 3097,
      "context": "\"text\": \"décision, peu de créativité, qui sont très adaptées pour des workflows automatiques entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 1712,
      "context": "\"text\": \"Vos données sont hébergées en Europe avec le Zero Data Retention, vos promptes ne sont pas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 1769,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 2696,
      "context": "\"text\": \"un immense dataset d'images et tu vas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 2711,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 6503,
      "context": "\"text\": \"Donc c'est typiquement un dataset qui s'appelle Common Crawl,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 6530,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7537,
      "context": "\"text\": \"Dans les faits, ce qui se passe, c'est qu'on a des datasets où les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7606,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7758,
      "context": "\"text\": \"il y a Flickr, c'est un énorme dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7803,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8035,
      "context": "\"text\": \"datasets, qui sont des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8038,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8062,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8488,
      "context": "\"text\": \"et on va le corriger et il va lui faire apprendre sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8569,
      "context": "\"word\": \"dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8897,
      "context": "\"text\": \"Et c'est les premiers modèles qui ont été construits comme ça, les premiers datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8978,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 26313,
      "context": "\"text\": \"Et là, pour le coup, tu peux être sur un dataset beaucoup plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 26376,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 26678,
      "context": "\"text\": \"Donc là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 26729,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 31289,
      "context": "\"text\": \"intégré à un workflow, c'est la publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 31310,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 35805,
      "context": "\"text\": \"décision, peu de créativité, qui sont très adaptées pour des workflows automatiques entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 35868,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 37847,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 38663,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 42083,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 43061,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 43223,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 43409,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 43433,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 43877,
      "context": "\"word\": \"dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 44237,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 59423,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 59741,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 63713,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 67655,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 68005,
      "context": "\"num_workers\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 1752,
      "context": "\"text\": \"Vos données sont hébergées en Europe avec le Zero Data Retention, vos promptes ne sont pas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 1753,
      "context": "\"text_human\": \"Vos données sont hébergées en Europe avec le Zero Data Retention, vos promptes ne sont pas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 1754,
      "context": "\"text_machine\": \"Vos donnees sont hebergees en Europe avec le 0 Data Retention, vos promptes ne sont pas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 1812,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2764,
      "context": "\"text\": \"Un immense dataset d'images et tu vas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2765,
      "context": "\"text_human\": \"Un immense dataset d'images et tu vas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2766,
      "context": "\"text_machine\": \"1 immense dataset d'images et tu vas\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2782,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 6700,
      "context": "\"text\": \"C'est typiquement un dataset qui s'appelle Common Crawl,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 6701,
      "context": "\"text_human\": \"C'est typiquement un dataset qui s'appelle Common Crawl,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 6702,
      "context": "\"text_machine\": \"C'est typiquement 1 dataset qui s'appelle Common Crawl,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 6730,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7768,
      "context": "\"text\": \"Dans les faits, ce qui se passe, c'est qu'on a des datasets où les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7769,
      "context": "\"text_human\": \"Dans les faits, ce qui se passe, c'est qu'on a des datasets où les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7770,
      "context": "\"text_machine\": \"Dans les faits, ce qui se passe, c'est qu'on a des datasets ou les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7840,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7976,
      "context": "\"text\": \"Il y a Flickr, c'est un énorme dataset De notes. Alors, soit c'est des\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7977,
      "context": "\"text_human\": \"Il y a Flickr, c'est un énorme dataset De notes. Alors, soit c'est des\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7978,
      "context": "\"text_machine\": \"Il y a Flickr, c'est 1 enorme dataset De notes. Alors, soit c'est des\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8024,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8237,
      "context": "\"text\": \"Datasets, qui sont des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8238,
      "context": "\"text_human\": \"Datasets, qui sont des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8239,
      "context": "\"text_machine\": \"Datasets, qui sont des datasets esthetiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8243,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8267,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8704,
      "context": "\"text\": \"Et on va le corriger et il va lui faire apprendre sur un dataset. On pourrait s'attendre à\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8705,
      "context": "\"text_human\": \"Et on va le corriger et il va lui faire apprendre sur un dataset. On pourrait s'attendre à\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8706,
      "context": "\"text_machine\": \"Et on va le corriger et il va lui faire apprendre sur 1 dataset. On pourrait s'attendre a\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 8788,
      "context": "\"word\": \"dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9119,
      "context": "\"text\": \"Et c'est les premiers modèles qui ont été construits comme ça, les premiers datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9120,
      "context": "\"text_human\": \"Et c'est les premiers modèles qui ont été construits comme ça, les premiers datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9121,
      "context": "\"text_machine\": \"Et c'est les premiers modeles qui ont ete construits comme ca, les premiers datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9203,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 26841,
      "context": "\"text\": \"Et là, pour le coup, tu peux être sur un dataset beaucoup plus petit. J'ai un peu essayé les deux.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 26842,
      "context": "\"text_human\": \"Et là, pour le coup, tu peux être sur un dataset beaucoup plus petit. J'ai un peu essayé les deux.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 26843,
      "context": "\"text_machine\": \"Et la, pour le coup, tu peux etre sur 1 dataset beaucoup plus petit. J'ai 1 peu essaye les 2.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 26907,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 27215,
      "context": "\"text\": \"Là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 27216,
      "context": "\"text_human\": \"Là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 27217,
      "context": "\"text_machine\": \"La, c'est des entrainements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 27269,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31976,
      "context": "\"text\": \"Intégré à un workflow, c'est la publication de nos podcasts. Peut-être que vous\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31977,
      "context": "\"text_human\": \"Intégré à un workflow, c'est la publication de nos podcasts. Peut-être que vous\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31978,
      "context": "\"text_machine\": \"Integre a 1 workflow, c'est la publication de nos podcasts. Peut-etre que vous\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 32000,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36331,
      "context": "\"text\": \"Décision, peu de créativité, qui sont très adaptées pour des workflows automatiques entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36332,
      "context": "\"text_human\": \"Décision, peu de créativité, qui sont très adaptées pour des workflows automatiques entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36333,
      "context": "\"text_machine\": \"Decision, peu de creativite, qui sont tres adaptees pour des workflows automatiques entierement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36397,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36902,
      "context": "\"Datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 37065,
      "context": "\"Zero Data Retention\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8,
      "context": "\"text\": \"Ça fait Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire un outil d'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et Justement, je Vous parle d'expérience, Parce Que ça fait quelques mois Qu'on a développé un système Pour gérer nos podcasts complètement automatiquement. Vais pouvoir Vous montrer Exactement à quoi ça Ressemble de développer un outil IA utile de A À Z. Pas Une vague Interface par-dessus ChatGPT ou Une énième automatisation de triage d'emails, Mais un outil concret Qui tourne en production et Qui résout un vrai problème. Le but, C'est de montrer l'envers du décor de l'IA. En entreprise. Se perdre Dans la jungle Des Modèles et Des promesses alléchantes, le Fine-tuning fastidieux, l'excitation de l'expérimentation et le désespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec un peu de chance, un outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Préféré. Mais Juste Avant, J'ai un message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modèles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, Une boîte française, Notre partenaire Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment à l'écran. Jour. Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers Comme Mistral Small Qui Sont 10 fois moins Énergivores. Tout ça à Partir de 10 euros Par mois. Le lien Est en description et on reprend. Un petit peu Déjà on part d'où Comment marche ces Modèles et Avec quoi on travaille. C'est Pas mal D'avoir Une petite intuition de Comment ça fonctionne. L'image la Plus parlante je Trouve C'est celle du débruitage. C'est concrètement de Comprendre le principe de la diffusion et de ce Qu'on appelle un auto encodeur. En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels. Et le job de ton système d'apprentissage, ça va être de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9,
      "context": "\"text_human\": \"Ça fait Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire un outil d'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et Justement, je Vous parle d'expérience, Parce Que ça fait quelques mois Qu'on a développé un système Pour gérer nos podcasts complètement automatiquement. Vais pouvoir Vous montrer Exactement à quoi ça Ressemble de développer un outil IA utile de A À Z. Pas Une vague Interface par-dessus ChatGPT ou Une énième automatisation de triage d'emails, Mais un outil concret Qui tourne en production et Qui résout un vrai problème. Le but, C'est de montrer l'envers du décor de l'IA. En entreprise. Se perdre Dans la jungle Des Modèles et Des promesses alléchantes, le Fine-tuning fastidieux, l'excitation de l'expérimentation et le désespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec un peu de chance, un outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Préféré. Mais Juste Avant, J'ai un message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modèles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, Une boîte française, Notre partenaire Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment à l'écran. Jour. Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers Comme Mistral Small Qui Sont 10 fois moins Énergivores. Tout ça à Partir de 10 euros Par mois. Le lien Est en description et on reprend. Un petit peu Déjà on part d'où Comment marche ces Modèles et Avec quoi on travaille. C'est Pas mal D'avoir Une petite intuition de Comment ça fonctionne. L'image la Plus parlante je Trouve C'est celle du débruitage. C'est concrètement de Comprendre le principe de la diffusion et de ce Qu'on appelle un auto encodeur. En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels. Et le job de ton système d'apprentissage, ça va être de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 10,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 1592,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 2408,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5284,
      "context": "\"text\": \"Entraîner un modèle Qui va être générique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la sémantique du texte et la représentation Dans L'image. Et C'est Vraiment ça Qui a déclenché la Révolution Qu'on connaît Aujourd'hui. Un autre truc trop Intéressant Dans l'histoire Des Modèles de diffusion, C'est qu'à Partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités de données massives, D'images. Sauf Que le problème, C'est qu'en termes de quantités disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement un dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5285,
      "context": "\"text_human\": \"Entraîner un modèle Qui va être générique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la sémantique du texte et la représentation Dans L'image. Et C'est Vraiment ça Qui a déclenché la Révolution Qu'on connaît Aujourd'hui. Un autre truc trop Intéressant Dans l'histoire Des Modèles de diffusion, C'est qu'à Partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités de données massives, D'images. Sauf Que le problème, C'est qu'en termes de quantités disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement un dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5286,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5872,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 6596,
      "context": "\"text\": \"Même, il y a Peut-être en Grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les... Humains donnent Des notes à Des Images en Très Grande quantité. Il y en a plein. Typiquement, il y a Flickr, C'est un énorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre un modèle Comme Clip Qui sert à avoir Une première représentation d'une Image et tu vas Entraîner par-dessus un modèle de Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit « essaie Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit, essaie de Prédire la note Sur 5 de Cette Image Sur le plan esthétique. Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset. On pourrait s'attendre à Des résultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ça converge. Il semble Que, Spoiler, il y a Quand Même Une Notion. De beauté universelle. Même si il y a Quand Même Pas mal de variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus. Et ça, il Faut se dire Que, Avant Qu'on ait ça, Tout ce Qu'on A connu derrière Comme modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient de Générer Une matrice de pixels directement. , Une Image, ce Qui était Très demandeur en Ressources, en mémoire et en capacité de calcul. Et Révolution qu'amène Stability Fusion, entre autres, la première version, C'est de créer Une représentation intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive de Faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une Image Par message ou Par mail, si tu la télécharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la télécharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. Là, on a un petit exemple Avec un chien. Là, celui Que Vous voyez à gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo… Elle, Elle fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain Est absolument incapable de voir la différence. Alors Qu'il y a 10 fois moins de données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 6597,
      "context": "\"text_human\": \"Même, il y a Peut-être en Grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les... Humains donnent Des notes à Des Images en Très Grande quantité. Il y en a plein. Typiquement, il y a Flickr, C'est un énorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre un modèle Comme Clip Qui sert à avoir Une première représentation d'une Image et tu vas Entraîner par-dessus un modèle de Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit « essaie Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit, essaie de Prédire la note Sur 5 de Cette Image Sur le plan esthétique. Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset. On pourrait s'attendre à Des résultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ça converge. Il semble Que, Spoiler, il y a Quand Même Une Notion. De beauté universelle. Même si il y a Quand Même Pas mal de variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus. Et ça, il Faut se dire Que, Avant Qu'on ait ça, Tout ce Qu'on A connu derrière Comme modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient de Générer Une matrice de pixels directement. , Une Image, ce Qui était Très demandeur en Ressources, en mémoire et en capacité de calcul. Et Révolution qu'amène Stability Fusion, entre autres, la première version, C'est de créer Une représentation intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive de Faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une Image Par message ou Par mail, si tu la télécharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la télécharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. Là, on a un petit exemple Avec un chien. Là, celui Que Vous voyez à gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo… Elle, Elle fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain Est absolument incapable de voir la différence. Alors Qu'il y a 10 fois moins de données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 6598,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 6872,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7034,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7220,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7244,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7688,
      "context": "\"word\": \"dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8048,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 22921,
      "context": "\"text\": \"Combien il en Faut ? Ça dépend du type d'entraînement Que tu fais. Tu peux Faire Des entraînements complets du modèle, un fine tuning Sur l'ensemble Des Poids du modèle, ou tu peux Faire ce Qu'on appelle un Laura, où là, Pour le coup, tu vas dégeler uniquement... Qu'on appelle un LoRa, où là Pour le coup, tu vas dégeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas dégeler Justement, entre 16, 32. En gros, tu vas infléchir la trajectoire Juste Avant qu'ils te fournissent Une sortie. Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit. J'ai un peu essayé Les deux. Justement, tu as Des API Qui te permettent de facilement Entraîner Des Modèles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 22922,
      "context": "\"text_human\": \"Combien il en Faut ? Ça dépend du type d'entraînement Que tu fais. Tu peux Faire Des entraînements complets du modèle, un fine tuning Sur l'ensemble Des Poids du modèle, ou tu peux Faire ce Qu'on appelle un Laura, où là, Pour le coup, tu vas dégeler uniquement... Qu'on appelle un LoRa, où là Pour le coup, tu vas dégeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas dégeler Justement, entre 16, 32. En gros, tu vas infléchir la trajectoire Juste Avant qu'ils te fournissent Une sortie. Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit. J'ai un peu essayé Les deux. Justement, tu as Des API Qui te permettent de facilement Entraîner Des Modèles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 22923,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 23443,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 23598,
      "context": "\"text\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images. Images. Il y a un premier trick à Comprendre Qui donne Des résultats Comme ça, C'est Que Pour Des bons résultats, tu as plein de paramètres Que tu peux Modifier. Un premier Paramètre, C'est Par exemple la vitesse d'entraînement, le learning rate. Là, il Faut le voir Comme un étudiant. C'est-à-dire Que tu peux Soit bachoter, apprendre Très Vite, Mais Avec Des risques Que ta mémoire Soit fucked up. Soit tu peux apprendre lentement et là tu as Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut dire Que C'est la Même Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 23599,
      "context": "\"text_human\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images. Images. Il y a un premier trick à Comprendre Qui donne Des résultats Comme ça, C'est Que Pour Des bons résultats, tu as plein de paramètres Que tu peux Modifier. Un premier Paramètre, C'est Par exemple la vitesse d'entraînement, le learning rate. Là, il Faut le voir Comme un étudiant. C'est-à-dire Que tu peux Soit bachoter, apprendre Très Vite, Mais Avec Des risques Que ta mémoire Soit fucked up. Soit tu peux apprendre lentement et là tu as Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut dire Que C'est la Même Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 23600,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 23772,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27312,
      "context": "\"text\": \"Mais Par contre Ils Sont extrêmement bons Pour adapter et... Répliquer. Ouais, Répliquer, adapter, Prendre, Utiliser Dans Une boîte à outils Que tu leur donnes Des choses un peu prémâchées et Les adapter à la situation Qui correspond. Il Faut aborder un peu Tous Les problèmes Que tu veux résoudre Avec Des LLM. Élèves de Cette manière Pour avoir Des bons résultats. Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts. Peut-être Que Vous Souvenez, Mais on a Toujours été Des Très mauvais Élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne, on se concentre Sur la chaîne. YouTube, on a du mal à Tout gérer en Même temps, on N'est Pas Une Grande équipe. Cet été, J'ai décidé d'y remédier en créant un système quasiment automatisé Thème quasiment automatisé de publication de nos podcasts. L'idée, C'est qu'en podcast, tu es simplement Une version un petit peu Coupée en enlevant ce Qui N'est Pas nécessaire, Typiquement le sponsor, Des choses Comme ça, de la vidéo Qui Est sortie Sur YouTube et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle Est récupérée Par le système automatiquement, on fait Les découpes Qu'il Faut, on Les rajoute Dans Une Base de données, Qui Ressemble À ça Sur Notion. Dès Que nos vidéos sortent, Elles Sont rajoutées. Là Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée toute seule. On choisit la date de publication du podcast. Et C'est Tout Terminé le podcast et il va être publié et le seul travail Qu'il y a eu C'est Qu'il y a eu un monteur en amont Qui a enlevé Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ça se fait Tout seul ah enlever le sponsor Par exemple D'accord Déjà Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette année il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis à peu Près serein de m'y engager, C'est Qu'on N'a rien à Faire Pour Que ça se produise. J'allais Vraiment dire, à l'Amicorp, l'humain N'est Pas fiable. Il y a un truc de... On Est monotâche on va dire. On Est monotâche, en gros on s'occupe d'un truc, Mais si C'est en dehors ça marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs années, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27313,
      "context": "\"text_human\": \"Mais Par contre Ils Sont extrêmement bons Pour adapter et... Répliquer. Ouais, Répliquer, adapter, Prendre, Utiliser Dans Une boîte à outils Que tu leur donnes Des choses un peu prémâchées et Les adapter à la situation Qui correspond. Il Faut aborder un peu Tous Les problèmes Que tu veux résoudre Avec Des LLM. Élèves de Cette manière Pour avoir Des bons résultats. Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts. Peut-être Que Vous Souvenez, Mais on a Toujours été Des Très mauvais Élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne, on se concentre Sur la chaîne. YouTube, on a du mal à Tout gérer en Même temps, on N'est Pas Une Grande équipe. Cet été, J'ai décidé d'y remédier en créant un système quasiment automatisé Thème quasiment automatisé de publication de nos podcasts. L'idée, C'est qu'en podcast, tu es simplement Une version un petit peu Coupée en enlevant ce Qui N'est Pas nécessaire, Typiquement le sponsor, Des choses Comme ça, de la vidéo Qui Est sortie Sur YouTube et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle Est récupérée Par le système automatiquement, on fait Les découpes Qu'il Faut, on Les rajoute Dans Une Base de données, Qui Ressemble À ça Sur Notion. Dès Que nos vidéos sortent, Elles Sont rajoutées. Là Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée toute seule. On choisit la date de publication du podcast. Et C'est Tout Terminé le podcast et il va être publié et le seul travail Qu'il y a eu C'est Qu'il y a eu un monteur en amont Qui a enlevé Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ça se fait Tout seul ah enlever le sponsor Par exemple D'accord Déjà Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette année il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis à peu Près serein de m'y engager, C'est Qu'on N'a rien à Faire Pour Que ça se produise. J'allais Vraiment dire, à l'Amicorp, l'humain N'est Pas fiable. Il y a un truc de... On Est monotâche on va dire. On Est monotâche, en gros on s'occupe d'un truc, Mais si C'est en dehors ça marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs années, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27314,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27810,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 30310,
      "context": "\"text\": \"Au début, on a fait Des tests Assez simples, Comme ça, Avec de l'inpainting, et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à trouver le bon modèle et à trouver le bon système. , on prend la miniature... On la grandit, on la Met derrière, on la floute, ça sert de point de départ à l'inpainting, le masque il a Une opacité faible. Enfin , il y avait Une petite mécanique à trouver, Mais là Comme ça,, il Invente Même Des reflets et Tout ça. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est Comme ça Qu'on règle le problème de la fiabilité, C'est Qu'on Sait Qu'il y en a Toujours Une Sur quatre Qui Est Bonne. Il y a Une miniature différente Pour chaque podcast ? Exactement du coup. Et bien le résultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tirés directement de la chaîne YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier Cette histoire récente de Comment l'IA a créé Une puce de calcul parfaite, Mais Qui échappe complètement À la compréhension Des Humains. C'était Dans Cette vidéo.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 30311,
      "context": "\"text_human\": \"Au début, on a fait Des tests Assez simples, Comme ça, Avec de l'inpainting, et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à trouver le bon modèle et à trouver le bon système. , on prend la miniature... On la grandit, on la Met derrière, on la floute, ça sert de point de départ à l'inpainting, le masque il a Une opacité faible. Enfin , il y avait Une petite mécanique à trouver, Mais là Comme ça,, il Invente Même Des reflets et Tout ça. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est Comme ça Qu'on règle le problème de la fiabilité, C'est Qu'on Sait Qu'il y en a Toujours Une Sur quatre Qui Est Bonne. Il y a Une miniature différente Pour chaque podcast ? Exactement du coup. Et bien le résultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tirés directement de la chaîne YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier Cette histoire récente de Comment l'IA a créé Une puce de calcul parfaite, Mais Qui échappe complètement À la compréhension Des Humains. C'était Dans Cette vidéo.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 30312,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 31690,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 24,
      "context": "\"text_human\": \"Ça fait Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire un outil d'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et Justement, je Vous parle d'expérience, Parce Que ça fait quelques mois Qu'on a développé un système Pour gérer nos podcasts complètement automatiquement. Vais pouvoir Vous montrer Exactement à quoi ça Ressemble de développer un outil IA utile de A À Z. Pas Une vague Interface par-dessus ChatGPT ou Une énième automatisation de triage d'emails, Mais un outil concret Qui tourne en production et Qui résout un vrai problème. Le but, C'est de montrer l'envers du décor de l'IA. En entreprise. Se perdre Dans la jungle Des Modèles et Des promesses alléchantes, le Fine-tuning fastidieux, l'excitation de l'expérimentation et le désespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec un peu de chance, un outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Préféré. Mais Juste Avant, J'ai un message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modèles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, Une boîte française, Notre partenaire Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment à l'écran. Jour. Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers Comme Mistral Small Qui Sont 10 fois moins Énergivores. Tout ça à Partir de 10 euros Par mois. Le lien Est en description et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 25,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 224,
      "context": "\"text\": \"Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 295,
      "context": "\"text_human\": \"Le lien Est en description et on reprend. Un petit peu Déjà on part d'où Comment marche ces Modèles et Avec quoi on travaille. C'est Pas mal D'avoir Une petite intuition de Comment ça fonctionne. L'image la Plus parlante je Trouve C'est celle du débruitage. C'est concrètement de Comprendre le principe de la diffusion et de ce Qu'on appelle un auto encodeur. En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels. Et le job de ton système d'apprentissage, ça va être de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux de bruit Qui Sont Très faibles. C'est relativement facile de reconstruire Les textures, etc. Et petit à petit, tu vas détruire de Plus en Plus ton Image Jusqu'à ce Que ton modèle, à Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entièrement. Et C'est ça la magie du truc, C'est Que entre temps, ton Image a complètement disparu et ton modèle Est capable, Avec du rien, du bruit, de Générer plein de variantes Qui Correspondent à ton texte. C'est un peu ça la magie de la diffusion. Et ce Qui Est Intéressant, C'est Que ce Que tu vises, C'est D'avoir un modèle Qui Est relativement... Créatif. C'est un peu l'autre truc à Comprendre, C'est Que ces modèles-là, Ils Sont constamment en tension entre deux extrêmes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Sauf Que tu vas le relancer 20 fois, ça va être Toujours la Même. Et ça, C'est un modèle Qui Est tombé Dans l'apprentissage Par cœur et Qui N'est Plus capable de généraliser.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 296,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux de bruit Qui Sont Tres faibles. C'est relativement facile de reconstruire Les textures, etc. Au debut, tu commences Avec Des niveaux de bruit Qui Sont Tres faibles. C'est relativement facile de reconstruire Les textures, etc. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Et petit a petit, tu vas detruire de Plus en Plus ton Image Jusqu'a ce Que ton modele, a Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entierement. Et C'est ca la magie du truc, C'est Que entre temps, ton Image a completement disparu et ton modele Est capable, Avec du rien, du bruit, de Generer plein de variantes Qui Correspondent a ton texte. C'est 1 peu ca la magie de la diffusion. Et ce Qui Est Interessant, C'est Que ce Que tu vises, C'est D'avoir 1 modele Qui Est relativement... Creatif. C'est 1 peu l'autre truc a Comprendre, C'est Que ces modeles-la, Ils Sont constamment en tension entre 2 extremes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 363,
      "context": "\"text\": \"En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 567,
      "context": "\"text_machine\": \"Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Sauf Que tu vas le relancer 20 fois, ca va etre Toujours la Meme. Et ca, C'est 1 modele Qui Est tombe Dans l'apprentissage Par c ur et Qui N'est Plus capable de generaliser. On Est Sur du bachotage. Oui, Exactement. Et tu as 1 autre extreme. Des Modeles Qui vont Pas etre capables de Faire du Realisme ou Qui vont avoir Des resultats Toujours 1 peu Tres flou Tres blurry Mais Qui vont etre Tres varies et Tout le L'enjeu Des gens Qui creent Des Modeles de ce type la Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces 2 ecueils la et Ils essayent D'avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modeles Images, Enfin Les Modeles de diffusion, ca te fait depuis bien Avant Que stable diffusion, Que ca existe. Des 2014, tu as Des premiers exemples de Modeles de diffusion, Typiquement Pour Generer Des chiffres. La grosse limite de ces Modeles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais... Generer 1 Image Sur le label pecheur, ca te donnait Des Images de pecheur. Mais si tu voulais 1 pecheur Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. Avec 1 chapeau rouge, ce n'etait Pas entraine Pour. La vraie Revolution, C'est le fait de Combiner 1 modele de diffusion Avec Justement 1 modele Comme Clip. En gros, le principe de Base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du texte et de L'image. Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,. Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,. Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,. Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 825,
      "context": "\"text_human\": \"Sauf Que le problème, C'est qu'en termes de quantités disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement un dataset Qui s'appelle Common Crawl,. Qui constitue Une sorte d'empreinte à un instant T d'Internet. Là-dedans, tu as du texte et de L'image. Tu veux pouvoir Déjà extraire uniquement toutes Les Images Pour servir de Base d'entraînement. Et Pour ça, ce qu'ils ont fait, C'est Très simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associée. On a le alt Qui, en général, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilité, Qui contient Une description de L'image. Le problème de ça, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Même, il y a Peut-être en Grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les... Humains donnent Des notes à Des Images en Très Grande quantité. Il y en a plein. Typiquement, il y a Flickr, C'est un énorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre un modèle Comme Clip Qui sert à avoir Une première représentation d'une Image et tu vas Entraîner par-dessus un modèle de Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit « essaie Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit, essaie de Prédire la note Sur 5 de Cette Image Sur le plan esthétique. Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 826,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,. Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Qui constitue 1 sorte d'empreinte a 1 instant T d'Internet. La-dedans, tu as du texte et de L'image. Tu veux pouvoir Deja extraire uniquement toutes Les Images Pour servir de Base d'entrainement. Et Pour ca, ce qu'ils ont fait, C'est Tres simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les developpeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associee. On a le alt Qui, en general, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilite, Qui contient 1 description de L'image. Le probleme de ca, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 845,
      "context": "\"text\": \"C'est Typiquement un dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 977,
      "context": "\"text\": \"Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1013,
      "context": "\"text\": \"Typiquement, il y a Flickr, C'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1037,
      "context": "\"text\": \"Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1085,
      "context": "\"text\": \"Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1121,
      "context": "\"text_human\": \"Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset. On pourrait s'attendre à Des résultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ça converge. Il semble Que, Spoiler, il y a Quand Même Une Notion. De beauté universelle. Même si il y a Quand Même Pas mal de variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus. Et ça, il Faut se dire Que, Avant Qu'on ait ça, Tout ce Qu'on A connu derrière Comme modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient de Générer Une matrice de pixels directement. , Une Image, ce Qui était Très demandeur en Ressources, en mémoire et en capacité de calcul. Et Révolution qu'amène Stability Fusion, entre autres, la première version, C'est de créer Une représentation intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive de Faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une Image Par message ou Par mail, si tu la télécharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la télécharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. Là, on a un petit exemple Avec un chien. Là, celui Que Vous voyez à gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo… Elle, Elle fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain Est absolument incapable de voir la différence. Alors Qu'il y a 10 fois moins de données. , Une première intuition du fait Que l'œil humain ne se représente Pas la donnée de la Même manière. C'est-à-dire qu'en gros, si la texture du poil du chien N'est Pas parfaite... Et similaire à l'original, Mais Que Tous Les autres détails Sont bons, ton œil humain ne verra jamais la différence.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1122,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees. , 1 premiere intuition du fait Que l' il humain ne se represente Pas la donnee de la Meme maniere. C'est-a-dire qu'en gros, si la texture du poil du chien N'est Pas parfaite... Et similaire a l'original, Mais Que Tous Les autres details Sont bons, ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme Chose. Ca va decrire le contenu de L'image le Plus precisement possible et a Partir de Cet espace latent, tu vas pouvoir Generer ton Image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne. Aussi Les Modeles d'image C'est Que d'1 coup on se retrouve a travailler Avec Des Ressources Beaucoup Plus restreintes C'est ca Qui fait Que tu peux surtout Sur ton ordi gamer tu peux Faire tourner Des Modeles d'image completement hallucinant Meme de D'images completement hallucinants, Meme de videos maintenant. Cette transition Qui a eu lieu Sur la maniere de decrire Les Images, Elle a Aussi ete accompagnee de grosses ameliorations Assez invisibles Pour Les gens Qui ne Sont Pas Passionnes. Passionnes Par la question Sur ce Qu'on appelle L'adherence aux promptes. , C'est 1 terme Qui decrit simplement le fait Que Quand tu demandes quelque Chose, il se Passe quelque Chose. Quand tu rentres Dans du specifique, ton modele Est capable de te suivre et d'etre Fidele a ce Que tu demandes. , Typiquement, ca, C'est Des Images generees a gauche. Par SDXL, Qui Est 1 ancien modele de Stability, et a droite, Fluxpro 1.1, Qui Est 1 Des Tout Derniers Modeles faits Par Black Forest Labs, Qui Sont Des anciens de Stability. , C'est Toujours Les memes gens Dans Tous Les cas. Le prompt, C'est Qu'il y a 1 boule verte Sur 1 Cube bleu, lui-meme Sur 1 pyramide rouge, il y a 1 chien a leur gauche et 1 chat a leur droite. Il Faut dire Que malgre Que Sur le plan purement esthetique, on aurait pu dire SDXL C'etait Deja super bien, L'adherence au prompt, C'est catastrophique. Et a gauche, il N'a rien compris. Et a droite, C'est parfaitement ce Qu'on a demande. Exactement. Les createurs de Modeles vont avoir Des benchmarks Pour mesurer ca precisement. C'est-a-dire Que tu dois pouvoir Modifier l'ordre Dans ton prompt. , 1 premiere intuition du fait Que l' il humain ne se represente Pas la donnee de la Meme maniere. C'est-a-dire qu'en gros, si la texture du poil du chien N'est Pas parfaite... Et similaire a l'original, Mais Que Tous Les autres details Sont bons, ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme Chose. Ca va decrire le contenu de L'image le Plus precisement possible et a Partir de Cet espace latent, tu vas pouvoir Generer ton Image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne. Aussi Les Modeles d'image C'est Que d'1 coup on se retrouve a travailler Avec Des Ressources Beaucoup Plus restreintes C'est ca Qui fait Que tu peux surtout Sur ton ordi gamer tu peux Faire tourner Des Modeles d'image completement hallucinant Meme de D'images completement hallucinants, Meme de videos maintenant. Cette transition Qui a eu lieu Sur la maniere de decrire Les Images, Elle a Aussi ete accompagnee de grosses ameliorations Assez invisibles Pour Les gens Qui ne Sont Pas Passionnes. Passionnes Par la question Sur ce Qu'on appelle L'adherence aux promptes. , C'est 1 terme Qui decrit simplement le fait Que Quand tu demandes quelque Chose, il se Passe quelque Chose. Quand tu rentres Dans du specifique, ton modele Est capable de te suivre et d'etre Fidele a ce Que tu demandes. , Typiquement, ca, C'est Des Images generees a gauche. Par SDXL, Qui Est 1 ancien modele de Stability, et a droite, Fluxpro 1.1, Qui Est 1 Des Tout Derniers Modeles faits Par Black Forest Labs, Qui Sont Des anciens de Stability. , C'est Toujours Les memes gens Dans Tous Les cas. Le prompt, C'est Qu'il y a 1 boule verte Sur 1 Cube bleu, lui-meme Sur 1 pyramide rouge, il y a 1 chien a leur gauche et 1 chat a leur droite. Il Faut dire Que malgre Que Sur le plan purement esthetique, on aurait pu dire SDXL C'etait Deja super bien, L'adherence au prompt, C'est catastrophique. Et a gauche, il N'a rien compris. Et a droite, C'est parfaitement ce Qu'on a demande. Exactement. Les createurs de Modeles vont avoir Des benchmarks Pour mesurer ca precisement. C'est-a-dire Que tu dois pouvoir Modifier l'ordre Dans ton prompt. , 1 premiere intuition du fait Que l' il humain ne se represente Pas la donnee de la Meme maniere. C'est-a-dire qu'en gros, si la texture du poil du chien N'est Pas parfaite... Et similaire a l'original, Mais Que Tous Les autres details Sont bons, ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme Chose. Ca va decrire le contenu de L'image le Plus precisement possible et a Partir de Cet espace latent, tu vas pouvoir Generer ton Image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne. Aussi Les Modeles d'image C'est Que d'1 coup on se retrouve a travailler Avec Des Ressources Beaucoup Plus restreintes C'est ca Qui fait Que tu peux surtout Sur ton ordi gamer tu peux Faire tourner Des Modeles d'image completement hallucinant Meme de D'images completement hallucinants, Meme de videos maintenant. Cette transition Qui a eu lieu Sur la maniere de decrire Les Images, Elle a Aussi ete accompagnee de grosses ameliorations Assez invisibles Pour Les gens Qui ne Sont Pas Passionnes. Passionnes Par la question Sur ce Qu'on appelle L'adherence aux promptes. , C'est 1 terme Qui decrit simplement le fait Que Quand tu demandes quelque Chose, il se Passe quelque Chose. Quand tu rentres Dans du specifique, ton modele Est capable de te suivre et d'etre Fidele a ce Que tu demandes. , Typiquement, ca, C'est Des Images generees a gauche. Par SDXL, Qui Est 1 ancien modele de Stability, et a droite, Fluxpro 1.1, Qui Est 1 Des Tout Derniers Modeles faits Par Black Forest Labs, Qui Sont Des anciens de Stability. , C'est Toujours Les memes gens Dans Tous Les cas. Le prompt, C'est Qu'il y a 1 boule verte Sur 1 Cube bleu, lui-meme Sur 1 pyramide rouge, il y a 1 chien a leur gauche et 1 chat a leur droite. Il Faut dire Que malgre Que Sur le plan purement esthetique, on aurait pu dire SDXL C'etait Deja super bien, L'adherence au prompt, C'est catastrophique. Et a gauche, il N'a rien compris. Et a droite, C'est parfaitement ce Qu'on a demande. Exactement. Les createurs de Modeles vont avoir Des benchmarks Pour mesurer ca precisement. C'est-a-dire Que tu dois pouvoir Modifier l'ordre Dans ton prompt.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1129,
      "context": "\"text\": \"Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1201,
      "context": "\"text\": \"Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3368,
      "context": "\"text_machine\": \"Exactement, ce Qui Est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. L'infiltration, C'est genial. Elle se Ressemble Pas mal. Il y a 1 personne a droite, 1 element d'image a gauche et 1 texte au-dessus. Ce Qui Est Typiquement 1 layout classique de la chaine. Et la, en gros, il a fait 10 miniatures Par version. Par version. C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent entre Elles. Mais ne fut-ce Que Pour se donner Des idees, C'est Deja genial. Eh bien, tu as Tout compris. La realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja aux... Au debut avoir Des resultats Quand Meme bons Comme ca. Et en Meme temps, J'ai Vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible de Faire. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Peut-etre Que C'est possible d'aller encore gratter 1 peu de qualite, de consistance. Mais, Quand, la realite, C'est Que C'est du AI junk Quand Meme. C'est-a-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Tres naturellement, Comme tu l'as devine, C'est devenu 1 outil de brainstorming ou je l'utilisais Pour donner 4 idees de miniatures et avoir instantanement 80 Versions differentes. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Comment on fait quelque Chose Comme ca ? , il y a plein d'astuces et de triches a plein D'endroits. Il y a Des artifices partout Pour Que ca marche et ca donne ce resultat. Quand tu veux creer 1 Image Qui Ressemble a ta chaine, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec 1 fond bleu, 1 degrade vers le noir, et 1 invite a droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ca. La premiere Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modele sous-jacent et Les Poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le premier, C'est d'entrainer 1 identite, de Faire en sorte d'apprendre quelle Est ma tete Pour creer... Le deuxieme usage, C'est le style. C'est Justement d'apprendre 1 style specifique. Ca peut etre du Realisme, du pixel art ou 1 direction artistique Comme Underscore, Par exemple. La, ca veut dire qu'est-ce Que tu lui as donne toutes Les anciennes miniatures d'Underscore ? Je lui AI donne Des miniatures d'Underscore. Mais Justement, Bonne transition. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3734,
      "context": "\"text_human\": \"Combien il en Faut ? Ça dépend du type d'entraînement Que tu fais. Tu peux Faire Des entraînements complets du modèle, un fine tuning Sur l'ensemble Des Poids du modèle, ou tu peux Faire ce Qu'on appelle un Laura, où là, Pour le coup, tu vas dégeler uniquement... Qu'on appelle un LoRa, où là Pour le coup, tu vas dégeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas dégeler Justement, entre 16, 32. En gros, tu vas infléchir la trajectoire Juste Avant qu'ils te fournissent Une sortie. Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit. J'ai un peu essayé Les deux. Justement, tu as Des API Qui te permettent de facilement Entraîner Des Modèles Comme Flux,. Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images. Images. Il y a un premier trick à Comprendre Qui donne Des résultats Comme ça, C'est Que Pour Des bons résultats, tu as plein de paramètres Que tu peux Modifier. Un premier Paramètre, C'est Par exemple la vitesse d'entraînement, le learning rate. Là, il Faut le voir Comme un étudiant. C'est-à-dire Que tu peux Soit bachoter, apprendre Très Vite, Mais Avec Des risques Que ta mémoire Soit fucked up. Soit tu peux apprendre lentement et là tu as Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut dire Que C'est la Même Chose. Tu as d'autres paramètres Comme ça, je Vous AI dit le nombre de layers Que tu vas Vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour avoir Des bons résultats, C'est de Faire littéralement Une matrice. Et de tester Tous Les paramètres, un Par un,. Jusqu'à avoir un modèle Qui marche bien. À la fin, on Est arrivé Avec, je pense, 20, 30 Modèles différents.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3735,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose. Tu as d'autres parametres Comme ca, je Vous AI dit le nombre de layers Que tu vas Vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouve Pour avoir Des bons resultats, C'est de Faire litteralement 1 matrice. Et de tester Tous Les parametres, 1 Par 1,. Tu as d'autres parametres Comme ca, je Vous AI dit le nombre de layers Que tu vas Vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouve Pour avoir Des bons resultats, C'est de Faire litteralement 1 matrice. Et de tester Tous Les parametres, 1 Par 1,. Tu as d'autres parametres Comme ca, je Vous AI dit le nombre de layers Que tu vas Vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouve Pour avoir Des bons resultats, C'est de Faire litteralement 1 matrice. Et de tester Tous Les parametres, 1 Par 1,. Tu as d'autres parametres Comme ca, je Vous AI dit le nombre de layers Que tu vas Vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouve Pour avoir Des bons resultats, C'est de Faire litteralement 1 matrice. Et de tester Tous Les parametres, 1 Par 1,. Jusqu'a avoir 1 modele Qui marche bien. A la fin, on Est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, Comme lequel Est le bon, tu testes. Sur chaque modele, tu donnes 5 entrees differentes. Jusqu'a avoir 1 modele Qui marche bien. A la fin, on Est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, Comme lequel Est le bon, tu testes. Sur chaque modele, tu donnes 5 entrees differentes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3814,
      "context": "\"text\": \"Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3874,
      "context": "\"text\": \"Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4360,
      "context": "\"text_human\": \"Quand Elle fait un style Comme ça de schéma Elle va s'adapter Elle va instruire le modèle Pour Qu'il modifie telle ou telle partie du prompt de manière intelligente C'est Pas Non Plus un formulaire le truc Mais C'est ça Qui va permettre D'avoir Des résultats Aussi bons derrière et il y a un autre exemple de ça Qui Est trop Intéressant C'est Les applis Qui étaient capables de te Générer Des Landing pages, Des sites Web complets Avec un prompt. Tu te dis, waouh, C'est dingue. Tu mets un prompt, ça te sort Une page D'accueil d'un D'accueil d'un site Web ultra léché et parfait. Et, la réalité, C'est Que derrière, t'avais Une Base de données, de segments de sites, de slides Que le modèle pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est Une super intuition Pour Comprendre Comment Utiliser au mieux Les Modèles maintenant. Comprendre qu'ils Sont Pas, Enfin, Ils Sont Pas si intelligents,. Mais Par contre Ils Sont extrêmement bons Pour adapter et... Répliquer. Ouais, Répliquer, adapter, Prendre, Utiliser Dans Une boîte à outils Que tu leur donnes Des choses un peu prémâchées et Les adapter à la situation Qui correspond. Il Faut aborder un peu Tous Les problèmes Que tu veux résoudre Avec Des LLM. Élèves de Cette manière Pour avoir Des bons résultats. Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts. Peut-être Que Vous Souvenez, Mais on a Toujours été Des Très mauvais Élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne, on se concentre Sur la chaîne. YouTube, on a du mal à Tout gérer en Même temps, on N'est Pas Une Grande équipe. Cet été, J'ai décidé d'y remédier en créant un système quasiment automatisé Thème quasiment automatisé de publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4361,
      "context": "\"text_machine\": \"Elle a de decrites, 5 Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Meme. La, Typiquement... Quand Elle fait 1 style Comme ca de schema Elle va s'adapter Elle va instruire le modele Pour Qu'il modifie telle ou telle partie du prompt de maniere intelligente C'est Pas Non Plus 1 formulaire le truc Mais C'est ca Qui va permettre D'avoir Des resultats Aussi bons derriere et il y a 1 autre exemple de ca Qui Est trop Interessant C'est Les applis Qui etaient capables de te Generer Des Landing pages, Des sites Web complets Avec 1 prompt. Tu te dis, waouh, C'est dingue. Tu mets 1 prompt, ca te sort 1 page D'accueil d'1 D'accueil d'1 site Web ultra leche et parfait. Et, la realite, C'est Que derriere, t'avais 1 Base de donnees, de segments de sites, de slides Que le modele pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est 1 super intuition Pour Comprendre Comment Utiliser au mieux Les Modeles maintenant. Elle a de decrites, 5 Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Meme. La, Typiquement... Quand Elle fait 1 style Comme ca de schema Elle va s'adapter Elle va instruire le modele Pour Qu'il modifie telle ou telle partie du prompt de maniere intelligente C'est Pas Non Plus 1 formulaire le truc Mais C'est ca Qui va permettre D'avoir Des resultats Aussi bons derriere et il y a 1 autre exemple de ca Qui Est trop Interessant C'est Les applis Qui etaient capables de te Generer Des Landing pages, Des sites Web complets Avec 1 prompt. Tu te dis, waouh, C'est dingue. Tu mets 1 prompt, ca te sort 1 page D'accueil d'1 D'accueil d'1 site Web ultra leche et parfait. Et, la realite, C'est Que derriere, t'avais 1 Base de donnees, de segments de sites, de slides Que le modele pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est 1 super intuition Pour Comprendre Comment Utiliser au mieux Les Modeles maintenant. Elle a de decrites, 5 Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Meme. La, Typiquement... Quand Elle fait 1 style Comme ca de schema Elle va s'adapter Elle va instruire le modele Pour Qu'il modifie telle ou telle partie du prompt de maniere intelligente C'est Pas Non Plus 1 formulaire le truc Mais C'est ca Qui va permettre D'avoir Des resultats Aussi bons derriere et il y a 1 autre exemple de ca Qui Est trop Interessant C'est Les applis Qui etaient capables de te Generer Des Landing pages, Des sites Web complets Avec 1 prompt. Tu te dis, waouh, C'est dingue. Tu mets 1 prompt, ca te sort 1 page D'accueil d'1 D'accueil d'1 site Web ultra leche et parfait. Et, la realite, C'est Que derriere, t'avais 1 Base de donnees, de segments de sites, de slides Que le modele pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est 1 super intuition Pour Comprendre Comment Utiliser au mieux Les Modeles maintenant. Elle a de decrites, 5 Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Meme. La, Typiquement... Quand Elle fait 1 style Comme ca de schema Elle va s'adapter Elle va instruire le modele Pour Qu'il modifie telle ou telle partie du prompt de maniere intelligente C'est Pas Non Plus 1 formulaire le truc Mais C'est ca Qui va permettre D'avoir Des resultats Aussi bons derriere et il y a 1 autre exemple de ca Qui Est trop Interessant C'est Les applis Qui etaient capables de te Generer Des Landing pages, Des sites Web complets Avec 1 prompt. Tu te dis, waouh, C'est dingue. Tu mets 1 prompt, ca te sort 1 page D'accueil d'1 D'accueil d'1 site Web ultra leche et parfait. Et, la realite, C'est Que derriere, t'avais 1 Base de donnees, de segments de sites, de slides Que le modele pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est 1 super intuition Pour Comprendre Comment Utiliser au mieux Les Modeles maintenant. Elle a de decrites, 5 Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Meme. La, Typiquement... Quand Elle fait 1 style Comme ca de schema Elle va s'adapter Elle va instruire le modele Pour Qu'il modifie telle ou telle partie du prompt de maniere intelligente C'est Pas Non Plus 1 formulaire le truc Mais C'est ca Qui va permettre D'avoir Des resultats Aussi bons derriere et il y a 1 autre exemple de ca Qui Est trop Interessant C'est Les applis Qui etaient capables de te Generer Des Landing pages, Des sites Web complets Avec 1 prompt. Tu te dis, waouh, C'est dingue. Tu mets 1 prompt, ca te sort 1 page D'accueil d'1 D'accueil d'1 site Web ultra leche et parfait. Et, la realite, C'est Que derriere, t'avais 1 Base de donnees, de segments de sites, de slides Que le modele pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est 1 super intuition Pour Comprendre Comment Utiliser au mieux Les Modeles maintenant. Comprendre qu'ils Sont Pas, Enfin, Ils Sont Pas si intelligents,. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4500,
      "context": "\"text\": \"Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4573,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4831,
      "context": "\"text_human\": \"Alors, Comment Faire ? Trois petits points. La solution, C'est super simple, C'est de Faire un système de Dean Painting. Globalement, Notre but, C'est de trouver un système Pour Que… À Partir d'une miniature, on vient combler ce Qu'il y a en haut et en bas. Au début, on a fait Des tests Assez simples, Comme ça, Avec de l'inpainting, et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à trouver le bon modèle et à trouver le bon système. , on prend la miniature... On la grandit, on la Met derrière, on la floute, ça sert de point de départ à l'inpainting, le masque il a Une opacité faible. Enfin , il y avait Une petite mécanique à trouver, Mais là Comme ça,, il Invente Même Des reflets et Tout ça. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est Comme ça Qu'on règle le problème de la fiabilité, C'est Qu'on Sait Qu'il y en a Toujours Une Sur quatre Qui Est Bonne. Il y a Une miniature différente Pour chaque podcast ? Exactement du coup. Et bien le résultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tirés directement de la chaîne YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier Cette histoire récente de Comment l'IA a créé Une puce de calcul parfaite, Mais Qui échappe complètement À la compréhension Des Humains.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4832,
      "context": "\"text_machine\": \"Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles Sont carrees. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? 3 petits points. La solution, C'est super simple, C'est de Faire 1 systeme de Dean Painting. Globalement, Notre but, C'est de trouver 1 systeme Pour Que... A Partir d'1 miniature, on vient combler ce Qu'il y a en haut et en bas. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 5055,
      "context": "\"text\": \"Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\chunks.json",
      "line": 5115,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video. Sous-titrage FR ?\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 7,
      "context": "\"paragraph\": \"Ça fait Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire un outil d'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et Justement, je Vous parle d'expérience, Parce Que ça fait quelques mois Qu'on a développé un système Pour gérer nos podcasts complètement automatiquement. Vais pouvoir Vous montrer Exactement à quoi ça Ressemble de développer un outil IA utile de A À Z. Pas Une vague Interface par-dessus ChatGPT ou Une énième automatisation de triage d'emails, Mais un outil concret Qui tourne en production et Qui résout un vrai problème. Le but, C'est de montrer l'envers du décor de l'IA. En entreprise. Se perdre Dans la jungle Des Modèles et Des promesses alléchantes, le Fine-tuning fastidieux, l'excitation de l'expérimentation et le désespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec un peu de chance, un outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Préféré. Mais Juste Avant, J'ai un message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modèles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, Une boîte française, Notre partenaire Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment à l'écran. Jour. Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers Comme Mistral Small Qui Sont 10 fois moins Énergivores. Tout ça à Partir de 10 euros Par mois. Le lien Est en description et on reprend. Un petit peu Déjà on part d'où Comment marche ces Modèles et Avec quoi on travaille. C'est Pas mal D'avoir Une petite intuition de Comment ça fonctionne. L'image la Plus parlante je Trouve C'est celle du débruitage. C'est concrètement de Comprendre le principe de la diffusion et de ce Qu'on appelle un auto encodeur. En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels. Et le job de ton système d'apprentissage, ça va être de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux de bruit Qui Sont Très faibles. C'est relativement facile de reconstruire Les textures, etc. Et petit à petit, tu vas détruire de Plus en Plus ton Image Jusqu'à ce Que ton modèle, à Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entièrement. Et C'est ça la magie du truc, C'est Que entre temps, ton Image a complètement disparu et ton modèle Est capable, Avec du rien, du bruit, de Générer plein de variantes Qui Correspondent à ton texte. C'est un peu ça la magie de la diffusion. Et ce Qui Est Intéressant, C'est Que ce Que tu vises, C'est D'avoir un modèle Qui Est relativement... Créatif. C'est un peu l'autre truc à Comprendre, C'est Que ces modèles-là, Ils Sont constamment en tension entre deux extrêmes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Sauf Que tu vas le relancer 20 fois, ça va être Toujours la Même. Et ça, C'est un modèle Qui Est tombé Dans l'apprentissage Par cœur et Qui N'est Plus capable de généraliser. On Est Sur du bachotage. Oui, Exactement. Et tu as un autre extrême. Des Modèles Qui vont Pas être capables de Faire du Réalisme ou Qui vont avoir Des résultats Toujours un peu Très flou Très blurry Mais Qui vont être Très variés et Tout le L'enjeu Des gens Qui créent Des Modèles de ce type là Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces deux écueils là et Ils essayent D'avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modèles Images, Enfin Les Modèles de diffusion, ça te fait depuis bien Avant Que stable diffusion, Que ça existe. Dès 2014, tu as Des premiers exemples de Modèles de diffusion, Typiquement Pour Générer Des chiffres. La grosse limite de ces Modèles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais... Générer Une Image Sur le label pêcheur, ça te donnait Des Images de pêcheur. Mais si tu voulais un pêcheur Avec un chapeau rouge, ce n'était Pas entraîné Pour. Avec un chapeau rouge, ce n'était Pas entraîné Pour. La vraie Révolution, C'est le fait de Combiner un modèle de diffusion Avec Justement un modèle Comme Clip. En gros, le principe de Base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du texte et de L'image. Entraîner un modèle Qui va être générique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la sémantique du texte et la représentation Dans L'image. Et C'est Vraiment ça Qui a déclenché la Révolution Qu'on connaît Aujourd'hui. Un autre truc trop Intéressant Dans l'histoire Des Modèles de diffusion, C'est qu'à Partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités de données massives, D'images. Sauf Que le problème, C'est qu'en termes de quantités disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement un dataset Qui s'appelle Common Crawl,. Qui constitue Une sorte d'empreinte à un instant T d'Internet. Là-dedans, tu as du texte et de L'image. Tu veux pouvoir Déjà extraire uniquement toutes Les Images Pour servir de Base d'entraînement. Et Pour ça, ce qu'ils ont fait, C'est Très simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associée. On a le alt Qui, en général, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilité, Qui contient Une description de L'image. Le problème de ça, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Même, il y a Peut-être en Grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les... Humains donnent Des notes à Des Images en Très Grande quantité. Il y en a plein. Typiquement, il y a Flickr, C'est un énorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre un modèle Comme Clip Qui sert à avoir Une première représentation d'une Image et tu vas Entraîner par-dessus un modèle de Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit « essaie Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit, essaie de Prédire la note Sur 5 de Cette Image Sur le plan esthétique. Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset. On pourrait s'attendre à Des résultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ça converge. Il semble Que, Spoiler, il y a Quand Même Une Notion. De beauté universelle. Même si il y a Quand Même Pas mal de variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus. Et ça, il Faut se dire Que, Avant Qu'on ait ça, Tout ce Qu'on A connu derrière Comme modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient de Générer Une matrice de pixels directement. , Une Image, ce Qui était Très demandeur en Ressources, en mémoire et en capacité de calcul. Et Révolution qu'amène Stability Fusion, entre autres, la première version, C'est de créer Une représentation intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive de Faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une Image Par message ou Par mail, si tu la télécharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la télécharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. Là, on a un petit exemple Avec un chien. Là, celui Que Vous voyez à gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo… Elle, Elle fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain Est absolument incapable de voir la différence. Alors Qu'il y a 10 fois moins de données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 18,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 32,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 46,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 60,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 74,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 88,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 102,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 116,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 130,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 144,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 158,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 172,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 186,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 200,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 214,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 228,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 240,
      "context": "\"text\": \"Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 241,
      "context": "\"text_human\": \"Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 242,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 256,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 270,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 284,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 298,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 312,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 326,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 340,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 352,
      "context": "\"text\": \"En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 353,
      "context": "\"text_human\": \"En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 354,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 368,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 382,
      "context": "\"text_machine\": \"Ca fait Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire 1 outil d'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et Justement, je Vous parle d'experience, Parce Que ca fait quelques mois Qu'on a developpe 1 systeme Pour gerer nos podcasts completement automatiquement. Vais pouvoir Vous montrer Exactement a quoi ca Ressemble de developper 1 outil IA utile de A A Z. Pas 1 vague Interface par-dessus ChatGPT ou 1 enieme automatisation de triage d'emails, Mais 1 outil concret Qui tourne en production et Qui resout 1 vrai probleme. Le but, C'est de montrer l'envers du decor de l'IA. En entreprise. Se perdre Dans la jungle Des Modeles et Des promesses allechantes, le Fine-tuning fastidieux, l'excitation de l'experimentation et le desespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec 1 peu de chance, 1 outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Prefere. Mais Juste Avant, J'ai 1 message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modeles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, 1 boite francaise, Notre partenaire Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment a l'ecran. Jour. Vos donnees Sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne Sont Pas Conservees et Les fournisseurs de Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers Comme Mistral Small Qui Sont 10 fois moins Energivores. Tout ca a Partir de 10 euros Par mois. Le lien Est en description et on reprend. 1 petit peu Deja on part d'ou Comment marche ces Modeles et Avec quoi on travaille. C'est Pas mal D'avoir 1 petite intuition de Comment ca fonctionne. L'image la Plus parlante je Trouve C'est celle du debruitage. C'est concretement de Comprendre le principe de la diffusion et de ce Qu'on appelle 1 auto encodeur. En gros le principe C'est Que Pour le modele et lui creer Cette sorte de comprehension du monde et Des objets, tu vas creer 1 immense dataset D'images et tu vas et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation de la matrice de pixels. Et le job de ton systeme d'apprentissage, ca va etre de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 760,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 774,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 788,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 802,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 814,
      "context": "\"text\": \"C'est Typiquement un dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 815,
      "context": "\"text_human\": \"C'est Typiquement un dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 816,
      "context": "\"text_machine\": \"Entrainer 1 modele Qui va etre generique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la semantique du texte et la representation Dans L'image. Et C'est Vraiment ca Qui a declenche la Revolution Qu'on connait Aujourd'hui. 1 autre truc trop Interessant Dans l'histoire Des Modeles de diffusion, C'est qu'a Partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites de donnees massives, D'images. Sauf Que le probleme, C'est qu'en termes de quantites disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 942,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 956,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 968,
      "context": "\"text\": \"Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 969,
      "context": "\"text_human\": \"Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les...\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 970,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 984,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 998,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1010,
      "context": "\"text\": \"Typiquement, il y a Flickr, C'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1011,
      "context": "\"text_human\": \"Typiquement, il y a Flickr, C'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1012,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1026,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1038,
      "context": "\"text\": \"Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1039,
      "context": "\"text_human\": \"Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1040,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1054,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1068,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1082,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1094,
      "context": "\"text\": \"Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1095,
      "context": "\"text_human\": \"Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1096,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1110,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1124,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1138,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1152,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1166,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1178,
      "context": "\"text\": \"Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1179,
      "context": "\"text_human\": \"Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1180,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1194,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1208,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1222,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1236,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1250,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1264,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1278,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1292,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1306,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1320,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1334,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1348,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1362,
      "context": "\"text_machine\": \"Meme, il y a Peut-etre en Grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets ou Les... Humains donnent Des notes a Des Images en Tres Grande quantite. Il y en a plein. Typiquement, il y a Flickr, C'est 1 enorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthetiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre 1 modele Comme Clip Qui sert a avoir 1 premiere representation d'1 Image et tu vas Entrainer par-dessus 1 modele de Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit essaie Scoring esthetique. C'est-a-dire Qu'on lui donne 1 Image, on lui dit, essaie de Predire la note Sur 5 de Cette Image Sur le plan esthetique. Il va Faire 1 tentative et on va le corriger et il va lui Faire apprendre Sur 1 dataset. On pourrait s'attendre a Des resultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ca converge. Il semble Que, Spoiler, il y a Quand Meme 1 Notion. De beaute universelle. Meme si il y a Quand Meme Pas mal de variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits Comme ca, Les premiers Datasets Qui s'appellent Lyon esthetiques, Qui Correspondent a Internet filtre Sur Tout ce Qui Est 5 5 etoiles et Plus. Et ca, il Faut se dire Que, Avant Qu'on ait ca, Tout ce Qu'on A connu derriere Comme modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient de Generer 1 matrice de pixels directement. , 1 Image, ce Qui etait Tres demandeur en Ressources, en memoire et en capacite de calcul. Et Revolution qu'amene Stability Fusion, entre autres, la premiere version, C'est de creer 1 representation intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive de Faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 Image Par message ou Par mail, si tu la telecharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la telecharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. La, on a 1 petit exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo... Elle, Elle fait 1 mega en PNG. L'arrete, C'est Que l' il humain Est absolument incapable de voir la difference. Alors Qu'il y a 10 fois moins de donnees.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1379,
      "context": "\"text\": \"Ça fait Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye de construire un outil d'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et Justement, je Vous parle d'expérience, Parce Que ça fait quelques mois Qu'on a développé un système Pour gérer nos podcasts complètement automatiquement. Vais pouvoir Vous montrer Exactement à quoi ça Ressemble de développer un outil IA utile de A À Z. Pas Une vague Interface par-dessus ChatGPT ou Une énième automatisation de triage d'emails, Mais un outil concret Qui tourne en production et Qui résout un vrai problème. Le but, C'est de montrer l'envers du décor de l'IA. En entreprise. Se perdre Dans la jungle Des Modèles et Des promesses alléchantes, le Fine-tuning fastidieux, l'excitation de l'expérimentation et le désespoir Des impasses. Vous allez voir, Pas de solution miracle, Pas de bouton magique, Juste Beaucoup, Beaucoup D'essais. Et au bout, Avec un peu de chance, un outil Qui fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau jouet Préféré. Mais Juste Avant, J'ai un message Pour Tous ceux Qui veulent Utiliser Les meilleurs Modèles d'IA sans multiplier Les abonnements. Notre partenaire Mammouth AI, Une boîte française, Notre partenaire Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule Interface. On parle de Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout et Ils Les mettent constamment à l'écran. Jour. Vos données Sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne Sont Pas Conservées et Les fournisseurs de Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers Comme Mistral Small Qui Sont 10 fois moins Énergivores. Tout ça à Partir de 10 euros Par mois. Le lien Est en description et on reprend. Un petit peu Déjà on part d'où Comment marche ces Modèles et Avec quoi on travaille. C'est Pas mal D'avoir Une petite intuition de Comment ça fonctionne. L'image la Plus parlante je Trouve C'est celle du débruitage. C'est concrètement de Comprendre le principe de la diffusion et de ce Qu'on appelle un auto encodeur. En gros le principe C'est Que Pour le modèle et lui créer Cette sorte de compréhension du monde et Des objets, tu vas créer un immense dataset D'images et tu vas et tu vas appliquer un léger bruit dessus, Une légère perturbation de la matrice de pixels. Et le job de ton système d'apprentissage, ça va être de reconstruire L'image d'origine. Et en gros, sa fonction d'accompance, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux de bruit Qui Sont Très faibles. C'est relativement facile de reconstruire Les textures, etc. Et petit à petit, tu vas détruire de Plus en Plus ton Image Jusqu'à ce Que ton modèle, à Partir uniquement du bruit et de la description en texte de L'image, Est capable de la reconstruire. Entièrement. Et C'est ça la magie du truc, C'est Que entre temps, ton Image a complètement disparu et ton modèle Est capable, Avec du rien, du bruit, de Générer plein de variantes Qui Correspondent à ton texte. C'est un peu ça la magie de la diffusion. Et ce Qui Est Intéressant, C'est Que ce Que tu vises, C'est D'avoir un modèle Qui Est relativement... Créatif. C'est un peu l'autre truc à Comprendre, C'est Que ces modèles-là, Ils Sont constamment en tension entre deux extrêmes. Il y en a Qui Sont capables de Faire Des super belles de Faire Des super belles femmes brunes en portrait,. Sauf Que tu vas le relancer 20 fois, ça va être Toujours la Même. Et ça, C'est un modèle Qui Est tombé Dans l'apprentissage Par cœur et Qui N'est Plus capable de généraliser. On Est Sur du bachotage. Oui, Exactement. Et tu as un autre extrême. Des Modèles Qui vont Pas être capables de Faire du Réalisme ou Qui vont avoir Des résultats Toujours un peu Très flou Très blurry Mais Qui vont être Très variés et Tout le L'enjeu Des gens Qui créent Des Modèles de ce type là Pour Comprendre il Faut dire qu'ils Sont Tout le temps entre ces deux écueils là et Ils essayent D'avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui Est marrant d'ailleurs C'est Que Les Modèles Images, Enfin Les Modèles de diffusion, ça te fait depuis bien Avant Que stable diffusion, Que ça existe. Dès 2014, tu as Des premiers exemples de Modèles de diffusion, Typiquement Pour Générer Des chiffres. La grosse limite de ces Modèles primitifs, C'est qu'ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais... Générer Une Image Sur le label pêcheur, ça te donnait Des Images de pêcheur. Mais si tu voulais un pêcheur Avec un chapeau rouge, ce n'était Pas entraîné Pour. Avec un chapeau rouge, ce n'était Pas entraîné Pour. La vraie Révolution, C'est le fait de Combiner un modèle de diffusion Avec Justement un modèle Comme Clip. En gros, le principe de Base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du texte et de L'image. Entraîner un modèle Qui va être générique Sur n'importe quel texte et Qui va pouvoir Comprendre Justement le lien entre la sémantique du texte et la représentation Dans L'image. Et C'est Vraiment ça Qui a déclenché la Révolution Qu'on connaît Aujourd'hui. Un autre truc trop Intéressant Dans l'histoire Des Modèles de diffusion, C'est qu'à Partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités de données massives, D'images. Sauf Que le problème, C'est qu'en termes de quantités disponibles en masse, ce Qu'on a Globalement, C'est Internet. C'est Typiquement un dataset Qui s'appelle Common Crawl,. Qui constitue Une sorte d'empreinte à un instant T d'Internet. Là-dedans, tu as du texte et de L'image. Tu veux pouvoir Déjà extraire uniquement toutes Les Images Pour servir de Base d'entraînement. Et Pour ça, ce qu'ils ont fait, C'est Très simple, C'est Que tu scans toutes Les pages Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent. ... Web, tu regardes Les tags Images, Tous Les développeurs Les connaissent, et tu vas extraire Aussi la description Qui Est associée. On a le alt Qui, en général, Est fait Pour Les moteurs de recherche ou Pour Les histoires D'accessibilité, Qui contient Une description de L'image. Le problème de ça, C'est Que Sur Internet, on le Sait bien Qu'il n'y a Pas Que Des belles Images. Même, il y a Peut-être en Grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et, la question, C'est Comment tu filtres ce Qui Est beau de ce Qui N'est Pas beau ? Dans Les faits, ce Qui se Passe, C'est Qu'on a Des Datasets où Les... Humains donnent Des notes à Des Images en Très Grande quantité. Il y en a plein. Typiquement, il y a Flickr, C'est un énorme dataset de notes. Alors, Soit C'est Des Pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. Il y a Ava, Enfin, il y a plusieurs Datasets, Qui Sont Des Datasets esthétiques. Et ce Que tu vas Faire, C'est Que tu vas Prendre un modèle Comme Clip Qui sert à avoir Une première représentation d'une Image et tu vas Entraîner par-dessus un modèle de Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit « essaie Scoring esthétique. C'est-à-dire Qu'on lui donne Une Image, on lui dit, essaie de Prédire la note Sur 5 de Cette Image Sur le plan esthétique. Il va Faire Une tentative et on va le corriger et il va lui Faire apprendre Sur un dataset. On pourrait s'attendre à Des résultats chaotiques, Mais ce N'est Pas ce Qu'on obtient. , ça converge. Il semble Que, Spoiler, il y a Quand Même Une Notion. De beauté universelle. Même si il y a Quand Même Pas mal de variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits Comme ça, Les premiers Datasets Qui s'appellent Lyon esthétiques, Qui Correspondent à Internet filtré Sur Tout ce Qui Est Cinq 5 étoiles et Plus. Et ça, il Faut se dire Que, Avant Qu'on ait ça, Tout ce Qu'on A connu derrière Comme modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient de Générer Une matrice de pixels directement. , Une Image, ce Qui était Très demandeur en Ressources, en mémoire et en capacité de calcul. Et Révolution qu'amène Stability Fusion, entre autres, la première version, C'est de créer Une représentation intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive de Faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une Image Par message ou Par mail, si tu la télécharges, Elle va Faire, je ne sais Pas moi, 100 kilos. Si tu la télécharge, Elle va Faire, je ne sais Pas moi, 100 kilobits Par exemple. Là, on a un petit exemple Avec un chien. Là, celui Que Vous voyez à gauche, il fait 80 kilo-octets, Alors Que la version originale Qui sort de l'appareil photo… Elle, Elle fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain Est absolument incapable de voir la différence. Alors Qu'il y a 10 fois moins de données.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 1382,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 2786,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 2801,
      "context": "\"paragraph\": \"Là on va dire... Bonjour, on va parler Des métaglaceuses. Ce Que tu dis Dans l'intro de la vidéo. Ouais C'est ça. Des métas, Des lunettes révolutionnaires. Hop. La première Chose Qu'on lui demande C'est de Générer... Des nouvelles idées. Des idées de miniature. , il va arriver Avec Une liste d'idées. Et Comme souvent Avec Tout ce Qui Est Tout ce Qui Est modèle de langue, etc. C'est Qu'il Est Très nul Pour en Générer Une Bonne, Mais il peut en Générer 14, dont 2-3 Sont Pas trop mal. Là, il me fait Des lunettes Géantes Qui flottent au-dessus de la ville. Et, je garde Seulement celle Que je veux Générer. Je fais Generate Thumbnails Pour gagner du temps. J'ai fait Une génération Déjà Avec d'autres miniatures. Et en l'occurrence, J'ai proposé de travailler Sur la vidéo Avec L'infiltration d'entreprises, l'osinte, etc. Et voici le résultat. Et toutes ces miniatures-là ont été Entièrement générées. Il n'y a Pas de retouches, il n'y a rien. Et on peut regarder quelques-unes. Déjà on va voir. On reconnaît un style Quand Même. On retrouve le bleu, la Bonne typo. Oh waouh ! Il a changé Des housses. Exactement, ce Qui Est Très drôle, C'est Qu'on reconnaît parfois Certains mélanges d'invités. Mais C'est vachement bien. C'est Pas mal. Là, le truc Avec la hit cam. Ouais, carrément. L'infiltration, C'est génial. Elle se Ressemble Pas mal. Il y a Une personne à droite, un élément d'image à gauche et un texte au-dessus. Ce Qui Est Typiquement un layout classique de la chaîne. Et là, en gros, il a fait 10 miniatures Par version. Par version. C'est Pour ça Qu'il y en a Pas mal Qui se ressemblent entre Elles. Mais ne fût-ce Que Pour se donner Des idées, C'est Déjà génial. Eh bien, tu as Tout compris. La réalité, C'est qu'en le commençant, je n'avais Pas d'attente spécifique. Je ne m'attendais Pas Déjà aux… Au début avoir Des résultats Quand Même bons Comme ça. Et en Même temps, J'ai Vite vu Qu'il y avait un plateau. C'est-à-dire Que là, C'était le mieux Qui était possible de Faire. Peut-être Que C'est possible d'aller encore gratter un peu de qualité, de consistance. Mais, Quand, la réalité, C'est Que C'est du AI junk Quand Même. C'est-à-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Dès Que tu zooms, il n'y a Plus rien Qui marche. Là Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Très naturellement, Comme tu l'as deviné, C'est devenu un outil de brainstorming où je l'utilisais Pour donner quatre idées de miniatures et avoir instantanément 80 Versions différentes. Comment on fait quelque Chose Comme ça ? , il y a plein d'astuces et de triches à plein D'endroits. Il y a Des artifices partout Pour Que ça marche et ça donne ce résultat. Quand tu veux créer Une Image Qui Ressemble à ta chaîne, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec un fond bleu, un dégradé vers le noir, et un invité à droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ça. La première Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modèle sous-jacent et Les Poids Pour obtenir le résultat Que tu veux. Tu as deux usages principaux. Le premier, C'est d'entraîner Une identité, de Faire en sorte d'apprendre quelle Est ma tête Pour créer... Le deuxième usage, C'est le style. C'est Justement d'apprendre un style spécifique. Ça peut être du Réalisme, du pixel art ou Une direction artistique Comme Underscore, Par exemple. Là, ça veut dire qu'est-ce Que tu lui as donné toutes Les anciennes miniatures d'Underscore ? Je lui AI donné Des miniatures d'Underscore. Mais Justement, Bonne transition. Combien il en Faut ? Ça dépend du type d'entraînement Que tu fais. Tu peux Faire Des entraînements complets du modèle, un fine tuning Sur l'ensemble Des Poids du modèle, ou tu peux Faire ce Qu'on appelle un Laura, où là, Pour le coup, tu vas dégeler uniquement... Qu'on appelle un LoRa, où là Pour le coup, tu vas dégeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas dégeler Justement, entre 16, 32. En gros, tu vas infléchir la trajectoire Juste Avant qu'ils te fournissent Une sortie. Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit. J'ai un peu essayé Les deux. Justement, tu as Des API Qui te permettent de facilement Entraîner Des Modèles Comme Flux,. Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images. Images. Il y a un premier trick à Comprendre Qui donne Des résultats Comme ça, C'est Que Pour Des bons résultats, tu as plein de paramètres Que tu peux Modifier. Un premier Paramètre, C'est Par exemple la vitesse d'entraînement, le learning rate. Là, il Faut le voir Comme un étudiant. C'est-à-dire Que tu peux Soit bachoter, apprendre Très Vite, Mais Avec Des risques Que ta mémoire Soit fucked up. Soit tu peux apprendre lentement et là tu as Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut dire Que C'est la Même Chose. Tu as d'autres paramètres Comme ça, je Vous AI dit le nombre de layers Que tu vas Vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour avoir Des bons résultats, C'est de Faire littéralement Une matrice. Et de tester Tous Les paramètres, un Par un,. Jusqu'à avoir un modèle Qui marche bien. À la fin, on Est arrivé Avec, je pense, 20, 30 Modèles différents. Et après, Comme lequel Est le bon, tu testes. Sur chaque modèle, tu donnes Cinq entrées différentes. Tu filtres ce Qui Est bon, ce Qui N'est Pas bon. Vraiment, C'est Assez long et pénible à Faire. Et C'est le seul moyen Qu'on a trouvé, en Tout cas, D'avoir un bon modèle Qui donne Des bons résultats. La deuxième supercherie Qui fait Que là, ça donne Aussi bons résultats, C'est au niveau Des promptes. C'est qu', J'ai fini Par réaliser, en ayant Des Très mauvais résultats pendant longtemps, Que le modèle n'était Pas Non Plus... Assez intelligent Pour Comprendre la structure sous-jacente Des miniatures. Et le fait Qu'on A Des miniatures où il y a un gros texte Sur le côté, Une flèche et quelque Chose, il y a un gros texte Sur le côté, Une flèche et quelque Chose. Ou on a un invité, un texte et Une boîte. Ou on a un truc Qui fait un peu schéma Avec ce style-là. Jusqu'à ce Que je comprenne Qu'il fallait le guider Plus. Et je Trouve Qu'il y a un truc hyper Intéressant derrière à Comprendre Sur ces modèles-là, et Que Même si... Ils ne Sont Pas intelligents. Ils Sont Très bons Pour trouver quel Est le schéma Qui correspond le mieux à telle ou telle situation. Et, la pipeline Qui permet de Générer ces miniatures,. Elle a de décrites, Cinq Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Même. Là, Typiquement... Quand Elle fait un style Comme ça de schéma Elle va s'adapter Elle va instruire le modèle Pour Qu'il modifie telle ou telle partie du prompt de manière intelligente C'est Pas Non Plus un formulaire le truc Mais C'est ça Qui va permettre D'avoir Des résultats Aussi bons derrière et il y a un autre exemple de ça Qui Est trop Intéressant C'est Les applis Qui étaient capables de te Générer Des Landing pages, Des sites Web complets Avec un prompt. Tu te dis, waouh, C'est dingue. Tu mets un prompt, ça te sort Une page D'accueil d'un D'accueil d'un site Web ultra léché et parfait. Et, la réalité, C'est Que derrière, t'avais Une Base de données, de segments de sites, de slides Que le modèle pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est Une super intuition Pour Comprendre Comment Utiliser au mieux Les Modèles maintenant. Comprendre qu'ils Sont Pas, Enfin, Ils Sont Pas si intelligents,. Mais Par contre Ils Sont extrêmement bons Pour adapter et... Répliquer. Ouais, Répliquer, adapter, Prendre, Utiliser Dans Une boîte à outils Que tu leur donnes Des choses un peu prémâchées et Les adapter à la situation Qui correspond. Il Faut aborder un peu Tous Les problèmes Que tu veux résoudre Avec Des LLM. Élèves de Cette manière Pour avoir Des bons résultats. Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts. Peut-être Que Vous Souvenez, Mais on a Toujours été Des Très mauvais Élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne, on se concentre Sur la chaîne. YouTube, on a du mal à Tout gérer en Même temps, on N'est Pas Une Grande équipe. Cet été, J'ai décidé d'y remédier en créant un système quasiment automatisé Thème quasiment automatisé de publication de nos podcasts. L'idée, C'est qu'en podcast, tu es simplement Une version un petit peu Coupée en enlevant ce Qui N'est Pas nécessaire, Typiquement le sponsor, Des choses Comme ça, de la vidéo Qui Est sortie Sur YouTube et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle Est récupérée Par le système automatiquement, on fait Les découpes Qu'il Faut, on Les rajoute Dans Une Base de données, Qui Ressemble À ça Sur Notion. Dès Que nos vidéos sortent, Elles Sont rajoutées. Là Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée toute seule. On choisit la date de publication du podcast. Et C'est Tout Terminé le podcast et il va être publié et le seul travail Qu'il y a eu C'est Qu'il y a eu un monteur en amont Qui a enlevé Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ça se fait Tout seul ah enlever le sponsor Par exemple D'accord Déjà Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette année il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis à peu Près serein de m'y engager, C'est Qu'on N'a rien à Faire Pour Que ça se produise. J'allais Vraiment dire, à l'Amicorp, l'humain N'est Pas fiable. Il y a un truc de... On Est monotâche on va dire. On Est monotâche, en gros on s'occupe d'un truc, Mais si C'est en dehors ça marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs années, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3806,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3820,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3834,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3848,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3862,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3876,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3888,
      "context": "\"text\": \"Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3889,
      "context": "\"text_human\": \"Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3890,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3904,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3918,
      "context": "\"text_machine\": \"Combien il en Faut ? Ca depend du type d'entrainement Que tu fais. Tu peux Faire Des entrainements complets du modele, 1 fine tuning Sur l'ensemble Des Poids du modele, ou tu peux Faire ce Qu'on appelle 1 Laura, ou la, Pour le coup, tu vas degeler uniquement... Qu'on appelle 1 LoRa, ou la Pour le coup, tu vas degeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas degeler Justement, entre 16, 32. En gros, tu vas inflechir la trajectoire Juste Avant qu'ils te fournissent 1 sortie. Et la, Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2. Justement, tu as Des API Qui te permettent de facilement Entrainer Des Modeles Comme Flux,.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3932,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3946,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3958,
      "context": "\"text\": \"Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3959,
      "context": "\"text_human\": \"Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3960,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3974,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 3988,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4002,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4016,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4030,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4044,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4058,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4072,
      "context": "\"text_machine\": \"Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec Seulement Des Datasets de 20 Images. Images. Il y a 1 premier trick a Comprendre Qui donne Des resultats Comme ca, C'est Que Pour Des bons resultats, tu as plein de parametres Que tu peux Modifier. 1 premier Parametre, C'est Par exemple la vitesse d'entrainement, le learning rate. La, il Faut le voir Comme 1 etudiant. C'est-a-dire Que tu peux Soit bachoter, apprendre Tres Vite, Mais Avec Des risques Que ta memoire Soit fucked up. Soit tu peux apprendre lentement et la tu as Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut Beaucoup moins de chances d'oublier et d'etre a cote de la percee. Il Faut dire Que C'est la Meme Chose.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4520,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4534,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4548,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4562,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4576,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4588,
      "context": "\"text\": \"Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4589,
      "context": "\"text_human\": \"Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4590,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4604,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4618,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4632,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4646,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4660,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4674,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4688,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4702,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4716,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4730,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4744,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4758,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4772,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4786,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4800,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4814,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4828,
      "context": "\"text_machine\": \"Mais Par contre Ils Sont extremement bons Pour adapter et... Repliquer. Ouais, Repliquer, adapter, Prendre, Utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu premachees et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les problemes Que tu veux resoudre Avec Des LLM. Eleves de Cette maniere Pour avoir Des bons resultats. Le truc Qu'on s'est mis a Vraiment Utiliser Tout le temps et Qui Est 1 systeme automatique Integre a 1 workflow, C'est la publication de nos podcasts. Peut-etre Que Vous Souvenez, Mais on a Toujours ete Des Tres mauvais Eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine, on se concentre Sur la chaine. YouTube, on a du mal a Tout gerer en Meme temps, on N'est Pas 1 Grande equipe. Cet ete, J'ai decide d'y remedier en creant 1 systeme quasiment automatise Theme quasiment automatise de publication de nos podcasts. L'idee, C'est qu'en podcast, tu es simplement 1 version 1 petit peu Coupee en enlevant ce Qui N'est Pas necessaire, Typiquement le sponsor, Des choses Comme ca, de la video Qui Est sortie Sur YouTube et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle Est recuperee Par le systeme automatiquement, on fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 Base de donnees, Qui Ressemble A ca Sur Notion. Des Que nos videos sortent, Elles Sont rajoutees. La Typiquement, Notre derniere video Micode, Elle a ete rajoutee toute seule. On choisit la date de publication du podcast. Et C'est Tout Termine le podcast et il va etre publie et le seul travail Qu'il y a eu C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ca se fait Tout seul ah enlever le sponsor Par exemple D'accord Deja Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette annee il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis a peu Pres serein de m'y engager, C'est Qu'on N'a rien a Faire Pour Que ca se produise. J'allais Vraiment dire, a l'Amicorp, l'humain N'est Pas fiable. Il y a 1 truc de... On Est monotache on va dire. On Est monotache, en gros on s'occupe d'1 truc, Mais si C'est en dehors ca marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs annees, C'est chiant.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4845,
      "context": "\"text\": \"Là on va dire... Bonjour, on va parler Des métaglaceuses. Ce Que tu dis Dans l'intro de la vidéo. Ouais C'est ça. Des métas, Des lunettes révolutionnaires. Hop. La première Chose Qu'on lui demande C'est de Générer... Des nouvelles idées. Des idées de miniature. , il va arriver Avec Une liste d'idées. Et Comme souvent Avec Tout ce Qui Est Tout ce Qui Est modèle de langue, etc. C'est Qu'il Est Très nul Pour en Générer Une Bonne, Mais il peut en Générer 14, dont 2-3 Sont Pas trop mal. Là, il me fait Des lunettes Géantes Qui flottent au-dessus de la ville. Et, je garde Seulement celle Que je veux Générer. Je fais Generate Thumbnails Pour gagner du temps. J'ai fait Une génération Déjà Avec d'autres miniatures. Et en l'occurrence, J'ai proposé de travailler Sur la vidéo Avec L'infiltration d'entreprises, l'osinte, etc. Et voici le résultat. Et toutes ces miniatures-là ont été Entièrement générées. Il n'y a Pas de retouches, il n'y a rien. Et on peut regarder quelques-unes. Déjà on va voir. On reconnaît un style Quand Même. On retrouve le bleu, la Bonne typo. Oh waouh ! Il a changé Des housses. Exactement, ce Qui Est Très drôle, C'est Qu'on reconnaît parfois Certains mélanges d'invités. Mais C'est vachement bien. C'est Pas mal. Là, le truc Avec la hit cam. Ouais, carrément. L'infiltration, C'est génial. Elle se Ressemble Pas mal. Il y a Une personne à droite, un élément d'image à gauche et un texte au-dessus. Ce Qui Est Typiquement un layout classique de la chaîne. Et là, en gros, il a fait 10 miniatures Par version. Par version. C'est Pour ça Qu'il y en a Pas mal Qui se ressemblent entre Elles. Mais ne fût-ce Que Pour se donner Des idées, C'est Déjà génial. Eh bien, tu as Tout compris. La réalité, C'est qu'en le commençant, je n'avais Pas d'attente spécifique. Je ne m'attendais Pas Déjà aux… Au début avoir Des résultats Quand Même bons Comme ça. Et en Même temps, J'ai Vite vu Qu'il y avait un plateau. C'est-à-dire Que là, C'était le mieux Qui était possible de Faire. Peut-être Que C'est possible d'aller encore gratter un peu de qualité, de consistance. Mais, Quand, la réalité, C'est Que C'est du AI junk Quand Même. C'est-à-dire Que tu as Des fautes. Ah Ouais. T'as ton texte, la gueule du gars Est ignoble. Dès Que tu zooms, il n'y a Plus rien Qui marche. Là Aussi, le fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. Et, Très naturellement, Comme tu l'as deviné, C'est devenu un outil de brainstorming où je l'utilisais Pour donner quatre idées de miniatures et avoir instantanément 80 Versions différentes. Comment on fait quelque Chose Comme ça ? , il y a plein d'astuces et de triches à plein D'endroits. Il y a Des artifices partout Pour Que ça marche et ça donne ce résultat. Quand tu veux créer Une Image Qui Ressemble à ta chaîne, tu peux Essayer. Essayer d'aller Sur Tchad GPT, Midjournals, etc. Et de lui demander quelque Chose Avec un fond bleu, un dégradé vers le noir, et un invité à droite, etc. Tu peux Essayer Autant Que tu veux. N'obtiendra jamais quelque Chose Qui Est proche Comme ça. La première Chose, C'est de Faire du fine tuning. C'est le fait Que d'aller Vraiment Modifier le modèle sous-jacent et Les Poids Pour obtenir le résultat Que tu veux. Tu as deux usages principaux. Le premier, C'est d'entraîner Une identité, de Faire en sorte d'apprendre quelle Est ma tête Pour créer... Le deuxième usage, C'est le style. C'est Justement d'apprendre un style spécifique. Ça peut être du Réalisme, du pixel art ou Une direction artistique Comme Underscore, Par exemple. Là, ça veut dire qu'est-ce Que tu lui as donné toutes Les anciennes miniatures d'Underscore ? Je lui AI donné Des miniatures d'Underscore. Mais Justement, Bonne transition. Combien il en Faut ? Ça dépend du type d'entraînement Que tu fais. Tu peux Faire Des entraînements complets du modèle, un fine tuning Sur l'ensemble Des Poids du modèle, ou tu peux Faire ce Qu'on appelle un Laura, où là, Pour le coup, tu vas dégeler uniquement... Qu'on appelle un LoRa, où là Pour le coup, tu vas dégeler uniquement quelques couches. Tu peux choisir Combien de couches tu vas dégeler Justement, entre 16, 32. En gros, tu vas infléchir la trajectoire Juste Avant qu'ils te fournissent Une sortie. Et là, Pour le coup, tu peux être Sur un dataset Beaucoup Plus petit. J'ai un peu essayé Les deux. Justement, tu as Des API Qui te permettent de facilement Entraîner Des Modèles Comme Flux,. Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec Seulement Des Datasets de 20 Images. Images. Il y a un premier trick à Comprendre Qui donne Des résultats Comme ça, C'est Que Pour Des bons résultats, tu as plein de paramètres Que tu peux Modifier. Un premier Paramètre, C'est Par exemple la vitesse d'entraînement, le learning rate. Là, il Faut le voir Comme un étudiant. C'est-à-dire Que tu peux Soit bachoter, apprendre Très Vite, Mais Avec Des risques Que ta mémoire Soit fucked up. Soit tu peux apprendre lentement et là tu as Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut Beaucoup moins de chances d'oublier et d'être à côté de la percée. Il Faut dire Que C'est la Même Chose. Tu as d'autres paramètres Comme ça, je Vous AI dit le nombre de layers Que tu vas Vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas de recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour avoir Des bons résultats, C'est de Faire littéralement Une matrice. Et de tester Tous Les paramètres, un Par un,. Jusqu'à avoir un modèle Qui marche bien. À la fin, on Est arrivé Avec, je pense, 20, 30 Modèles différents. Et après, Comme lequel Est le bon, tu testes. Sur chaque modèle, tu donnes Cinq entrées différentes. Tu filtres ce Qui Est bon, ce Qui N'est Pas bon. Vraiment, C'est Assez long et pénible à Faire. Et C'est le seul moyen Qu'on a trouvé, en Tout cas, D'avoir un bon modèle Qui donne Des bons résultats. La deuxième supercherie Qui fait Que là, ça donne Aussi bons résultats, C'est au niveau Des promptes. C'est qu', J'ai fini Par réaliser, en ayant Des Très mauvais résultats pendant longtemps, Que le modèle n'était Pas Non Plus... Assez intelligent Pour Comprendre la structure sous-jacente Des miniatures. Et le fait Qu'on A Des miniatures où il y a un gros texte Sur le côté, Une flèche et quelque Chose, il y a un gros texte Sur le côté, Une flèche et quelque Chose. Ou on a un invité, un texte et Une boîte. Ou on a un truc Qui fait un peu schéma Avec ce style-là. Jusqu'à ce Que je comprenne Qu'il fallait le guider Plus. Et je Trouve Qu'il y a un truc hyper Intéressant derrière à Comprendre Sur ces modèles-là, et Que Même si... Ils ne Sont Pas intelligents. Ils Sont Très bons Pour trouver quel Est le schéma Qui correspond le mieux à telle ou telle situation. Et, la pipeline Qui permet de Générer ces miniatures,. Elle a de décrites, Cinq Aussi templates de promptes Qu'elle peut aller Utiliser et remplir. Il y a de l'adaptation Quand Même. Là, Typiquement... Quand Elle fait un style Comme ça de schéma Elle va s'adapter Elle va instruire le modèle Pour Qu'il modifie telle ou telle partie du prompt de manière intelligente C'est Pas Non Plus un formulaire le truc Mais C'est ça Qui va permettre D'avoir Des résultats Aussi bons derrière et il y a un autre exemple de ça Qui Est trop Intéressant C'est Les applis Qui étaient capables de te Générer Des Landing pages, Des sites Web complets Avec un prompt. Tu te dis, waouh, C'est dingue. Tu mets un prompt, ça te sort Une page D'accueil d'un D'accueil d'un site Web ultra léché et parfait. Et, la réalité, C'est Que derrière, t'avais Une Base de données, de segments de sites, de slides Que le modèle pouvait Utiliser, Changer l'ordre, etc. Je Trouve Que C'est Une super intuition Pour Comprendre Comment Utiliser au mieux Les Modèles maintenant. Comprendre qu'ils Sont Pas, Enfin, Ils Sont Pas si intelligents,. Mais Par contre Ils Sont extrêmement bons Pour adapter et... Répliquer. Ouais, Répliquer, adapter, Prendre, Utiliser Dans Une boîte à outils Que tu leur donnes Des choses un peu prémâchées et Les adapter à la situation Qui correspond. Il Faut aborder un peu Tous Les problèmes Que tu veux résoudre Avec Des LLM. Élèves de Cette manière Pour avoir Des bons résultats. Le truc Qu'on s'est mis à Vraiment Utiliser Tout le temps et Qui Est un système automatique Intégré à un workflow, C'est la publication de nos podcasts. Peut-être Que Vous Souvenez, Mais on a Toujours été Des Très mauvais Élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne, on se concentre Sur la chaîne. YouTube, on a du mal à Tout gérer en Même temps, on N'est Pas Une Grande équipe. Cet été, J'ai décidé d'y remédier en créant un système quasiment automatisé Thème quasiment automatisé de publication de nos podcasts. L'idée, C'est qu'en podcast, tu es simplement Une version un petit peu Coupée en enlevant ce Qui N'est Pas nécessaire, Typiquement le sponsor, Des choses Comme ça, de la vidéo Qui Est sortie Sur YouTube et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle Est récupérée Par le système automatiquement, on fait Les découpes Qu'il Faut, on Les rajoute Dans Une Base de données, Qui Ressemble À ça Sur Notion. Dès Que nos vidéos sortent, Elles Sont rajoutées. Là Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée toute seule. On choisit la date de publication du podcast. Et C'est Tout Terminé le podcast et il va être publié et le seul travail Qu'il y a eu C'est Qu'il y a eu un monteur en amont Qui a enlevé Les parties Que tu voulais Pas avoir Dans le podcast Non le montage ça se fait Tout seul ah enlever le sponsor Par exemple D'accord Déjà Pour ceux Qui Sont Amateurs de podcast Sachez Que Cette année il va y en avoir Beaucoup Beaucoup Plus. Tous Les lundis et jeudis matin, il y aura Underscore et Les documentaires Qui seront Sur Les plateformes de podcast. Et la raison Pour laquelle je suis à peu Près serein de m'y engager, C'est Qu'on N'a rien à Faire Pour Que ça se produise. J'allais Vraiment dire, à l'Amicorp, l'humain N'est Pas fiable. Il y a un truc de... On Est monotâche on va dire. On Est monotâche, en gros on s'occupe d'un truc, Mais si C'est en dehors ça marche Pas. Sauf si C'est automatique. Pour l'avoir fait pendant plusieurs années, C'est chiant.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4848,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4863,
      "context": "\"paragraph\": \"Aucune valeur ajoutée. Le problème, C'est qu'en podcast, Les miniatures, Elles Sont carrées. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? Trois petits points. La solution, C'est super simple, C'est de Faire un système de Dean Painting. Globalement, Notre but, C'est de trouver un système Pour Que… À Partir d'une miniature, on vient combler ce Qu'il y a en haut et en bas. Au début, on a fait Des tests Assez simples, Comme ça, Avec de l'inpainting, et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à trouver le bon modèle et à trouver le bon système. , on prend la miniature... On la grandit, on la Met derrière, on la floute, ça sert de point de départ à l'inpainting, le masque il a Une opacité faible. Enfin , il y avait Une petite mécanique à trouver, Mais là Comme ça,, il Invente Même Des reflets et Tout ça. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est Comme ça Qu'on règle le problème de la fiabilité, C'est Qu'on Sait Qu'il y en a Toujours Une Sur quatre Qui Est Bonne. Il y a Une miniature différente Pour chaque podcast ? Exactement du coup. Et bien le résultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tirés directement de la chaîne YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier Cette histoire récente de Comment l'IA a créé Une puce de calcul parfaite, Mais Qui échappe complètement À la compréhension Des Humains. C'était Dans Cette vidéo. Sous-titrage FR ?\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 4986,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5000,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5014,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5028,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5042,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5056,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5070,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5084,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5098,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5112,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5126,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5140,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5154,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5166,
      "context": "\"text\": \"Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5167,
      "context": "\"text_human\": \"Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5168,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5182,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5196,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5210,
      "context": "\"text_machine\": \"Au debut, on a fait Des tests Assez simples, Comme ca, Avec de l'inpainting, et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a trouver le bon modele et a trouver le bon systeme. , on prend la miniature... On la grandit, on la Met derriere, on la floute, ca sert de point de depart a l'inpainting, le masque il a 1 opacite faible. Enfin , il y avait 1 petite mecanique a trouver, Mais la Comme ca,, il Invente Meme Des reflets et Tout ca. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est Comme ca Qu'on regle le probleme de la fiabilite, C'est Qu'on Sait Qu'il y en a Toujours 1 Sur 4 Qui Est Bonne. Il y a 1 miniature differente Pour chaque podcast ? Exactement du coup. Et bien le resultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tires directement de la chaine YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a differentes applications, Des Qu'il y a Tres peu de prise de Decision, peu de creativite, Qui Sont Tres adaptees Pour Des workflows automatiques Entierement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier Cette histoire recente de Comment l'IA a cree 1 puce de calcul parfaite, Mais Qui echappe completement A la comprehension Des Humains. C'etait Dans Cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5241,
      "context": "\"text\": \"Aucune valeur ajoutée. Le problème, C'est qu'en podcast, Les miniatures, Elles Sont carrées. Oui, Elles ne Sont Pas horizontales. Alors, Comment Faire ? Trois petits points. La solution, C'est super simple, C'est de Faire un système de Dean Painting. Globalement, Notre but, C'est de trouver un système Pour Que… À Partir d'une miniature, on vient combler ce Qu'il y a en haut et en bas. Au début, on a fait Des tests Assez simples, Comme ça, Avec de l'inpainting, et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à trouver le bon modèle et à trouver le bon système. , on prend la miniature... On la grandit, on la Met derrière, on la floute, ça sert de point de départ à l'inpainting, le masque il a Une opacité faible. Enfin , il y avait Une petite mécanique à trouver, Mais là Comme ça,, il Invente Même Des reflets et Tout ça. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est Comme ça Qu'on règle le problème de la fiabilité, C'est Qu'on Sait Qu'il y en a Toujours Une Sur quatre Qui Est Bonne. Il y a Une miniature différente Pour chaque podcast ? Exactement du coup. Et bien le résultat, du coup il Est live, C'est Que on a nos miniats Qui Sont propres, Qui Sont tirés directement de la chaîne YouTube. C'est cool ou quoi ? Et, C'est Pour montrer qu'en gros il y a différentes applications, Dès Qu'il y a Très peu de prise de Décision, peu de créativité, Qui Sont Très adaptées Pour Des workflows automatiques Entièrement. Et d'autres, qu'ils le Sont moins, Qui peuvent servir de brainstorming Pour du travail Plus Créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier Cette histoire récente de Comment l'IA a créé Une puce de calcul parfaite, Mais Qui échappe complètement À la compréhension Des Humains. C'était Dans Cette vidéo. Sous-titrage FR ?\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\structure.json",
      "line": 5244,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 163,
      "context": "\"text\": \"Vos données sont hébergées en Europe avec le Zero Data Retention,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 241,
      "context": "\"text\": \"tu vas créer un immense dataset d'images\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 607,
      "context": "\"text\": \"en masse, ce qu'on a globalement c'est internet. Donc c'est typiquement un dataset qui s'appelle\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 685,
      "context": "\"text\": \"Dans les faits, ce qui se passe c'est qu'on a des datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 697,
      "context": "\"text\": \"Il y en a plein, typiquement il y a Flickr, c'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 709,
      "context": "\"text\": \"AVA, il y a plusieurs datasets qui sont des datasets esthétiques. Et ce que tu vas faire,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 751,
      "context": "\"text\": \"sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 793,
      "context": "\"text\": \"les premiers datasets, qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2305,
      "context": "\"text\": \"avant qu'ils te fournissent une sortie en fait. Et là pour le coup, tu peux être sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2329,
      "context": "\"text\": \"Donc là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 2713,
      "context": "\"text\": \"système automatique intégré à un workflow, c'est la publication de nos podcasts. Peut-être\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\02_merged_raw.json",
      "line": 3061,
      "context": "\"text\": \"décision, peu de créativité, qui sont très adaptées pour des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 2035,
      "context": "\"text\": \"Vos données sont hébergées en Europe avec le Zero Data Retention,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 2101,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 3121,
      "context": "\"text\": \"tu vas créer un immense dataset d'images\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 3159,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7750,
      "context": "\"text\": \"Donc c'est typiquement un dataset qui s'appelle\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 7781,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 8988,
      "context": "\"text\": \"Dans les faits, ce qui se passe c'est qu'on a des datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9068,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9179,
      "context": "\"text\": \"Il y en a plein, typiquement il y a Flickr, c'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9273,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9426,
      "context": "\"text\": \"AVA, il y a plusieurs datasets qui sont des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9464,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 9492,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 10099,
      "context": "\"text\": \"sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 10116,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 10540,
      "context": "\"text\": \"les premiers datasets, qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 10557,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 30411,
      "context": "\"text\": \"Et là pour le coup, tu peux être sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 30484,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 30852,
      "context": "\"text\": \"Donc là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 30911,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 36271,
      "context": "\"text\": \"système automatique intégré à un workflow, c'est la publication de nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 36309,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 41690,
      "context": "\"text\": \"décision, peu de créativité, qui sont très adaptées pour des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 41763,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 44021,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 44959,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 49005,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 50132,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 50321,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 50496,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 50524,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 51084,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 51469,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 69060,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 69431,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 74205,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\03_aligned_whisperx.json",
      "line": 79091,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2062,
      "context": "\"text\": \"Vos données sont hébergées en Europe avec le Zero Data Retention,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2063,
      "context": "\"text_human\": \"Vos données sont hébergées en Europe avec le Zero Data Retention,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2064,
      "context": "\"text_machine\": \"Vos donnees sont hebergees en Europe avec le 0 Data Retention,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 2131,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 3182,
      "context": "\"text\": \"Tu vas créer un immense dataset d'images\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 3183,
      "context": "\"text_human\": \"Tu vas créer un immense dataset d'images\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 3184,
      "context": "\"text_machine\": \"Tu vas creer 1 immense dataset d'images\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 3223,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7895,
      "context": "\"text\": \"C'est typiquement un dataset qui s'appelle\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7896,
      "context": "\"text_human\": \"C'est typiquement un dataset qui s'appelle\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7897,
      "context": "\"text_machine\": \"C'est typiquement 1 dataset qui s'appelle\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 7929,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9127,
      "context": "\"text\": \"Dans les faits, ce qui se passe c'est qu'on a des datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9128,
      "context": "\"text_human\": \"Dans les faits, ce qui se passe c'est qu'on a des datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9129,
      "context": "\"text_machine\": \"Dans les faits, ce qui se passe c'est qu'on a des datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9210,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9324,
      "context": "\"text\": \"Il y en a plein, typiquement il y a Flickr, c'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9325,
      "context": "\"text_human\": \"Il y en a plein, typiquement il y a Flickr, c'est un énorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9326,
      "context": "\"text_machine\": \"Il y en a plein, typiquement il y a Flickr, c'est 1 enorme dataset de notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9421,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9577,
      "context": "\"text\": \"AVA, il y a plusieurs datasets qui sont des datasets esthétiques. Et ce que tu vas faire,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9578,
      "context": "\"text_human\": \"AVA, il y a plusieurs datasets qui sont des datasets esthétiques. Et ce que tu vas faire,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9579,
      "context": "\"text_machine\": \"AVA, il y a plusieurs datasets qui sont des datasets esthetiques. Et ce que tu vas faire,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9618,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 9646,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10175,
      "context": "\"text\": \"Et on va le corriger et il va lui faire apprendre Sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10176,
      "context": "\"text_human\": \"Et on va le corriger et il va lui faire apprendre Sur un dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10177,
      "context": "\"text_machine\": \"Et on va le corriger et il va lui faire apprendre Sur 1 dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10272,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10713,
      "context": "\"text\": \"Les premiers datasets, qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10714,
      "context": "\"text_human\": \"Les premiers datasets, qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10715,
      "context": "\"text_machine\": \"Les premiers datasets, qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 10733,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 30729,
      "context": "\"text\": \"Et là pour le coup, tu peux être sur un dataset Beaucoup plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 30730,
      "context": "\"text_human\": \"Et là pour le coup, tu peux être sur un dataset Beaucoup plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 30731,
      "context": "\"text_machine\": \"Et la pour le coup, tu peux etre sur 1 dataset Beaucoup plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 30805,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31169,
      "context": "\"text\": \"Là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31170,
      "context": "\"text_human\": \"Là, c'est des entraînements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31171,
      "context": "\"text_machine\": \"La, c'est des entrainements avec seulement des datasets de 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 31231,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36668,
      "context": "\"text\": \"Système automatique intégré à un workflow, c'est la publication de nos podcasts. Peut-être\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36669,
      "context": "\"text_human\": \"Système automatique intégré à un workflow, c'est la publication de nos podcasts. Peut-être\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36670,
      "context": "\"text_machine\": \"Systeme automatique integre a 1 workflow, c'est la publication de nos podcasts. Peut-etre\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 36709,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 42113,
      "context": "\"text\": \"Décision, peu de créativité, qui sont très adaptées pour des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 42114,
      "context": "\"text_human\": \"Décision, peu de créativité, qui sont très adaptées pour des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 42115,
      "context": "\"text_machine\": \"Decision, peu de creativite, qui sont tres adaptees pour des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 42189,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\04_cleaned.json",
      "line": 42879,
      "context": "\"Zero Data Retention\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8,
      "context": "\"text\": \"Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire Un outil D'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et justement, je Vous parle d'expérience, Parce Que ça Fait Quelques mois Qu'on a développé Un Système Pour gérer nos podcasts Complètement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement à Quoi ça ressemble De développer Un outil IA utile De A à Z. Pas Une vague interface par-dessus ChatGPT ou Une énième automatisation De triage d'emails, Mais Un outil concret Qui tourne en production Et Qui résout Un vrai problème. Le but, C'est De Montrer l'envers du Décor De l'IA en entreprise. Se perdre Dans la jungle Des Modèles Et Des promesses saléchantes, le fine-tuning fastidieux, L'excitation De l'expérimentation Et le désespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec Un peu De chance, Un outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet préféré. Mais Juste Avant, J'ai Un Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modèles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, Une boîte française, rassemble Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment à jour. Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers comme Mistral Small, Qui sont 10 fois moins énergivores. Tout ça à partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9,
      "context": "\"text_human\": \"Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire Un outil D'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et justement, je Vous parle d'expérience, Parce Que ça Fait Quelques mois Qu'on a développé Un Système Pour gérer nos podcasts Complètement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement à Quoi ça ressemble De développer Un outil IA utile De A à Z. Pas Une vague interface par-dessus ChatGPT ou Une énième automatisation De triage d'emails, Mais Un outil concret Qui tourne en production Et Qui résout Un vrai problème. Le but, C'est De Montrer l'envers du Décor De l'IA en entreprise. Se perdre Dans la jungle Des Modèles Et Des promesses saléchantes, le fine-tuning fastidieux, L'excitation De l'expérimentation Et le désespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec Un peu De chance, Un outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet préféré. Mais Juste Avant, J'ai Un Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modèles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, Une boîte française, rassemble Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment à jour. Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers comme Mistral Small, Qui sont 10 fois moins énergivores. Tout ça à partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 10,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 1834,
      "context": "\"word\": \"Data\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 2224,
      "context": "\"text\": \"Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille. C'est Pas mal d'avoir Une petite Intuition De Comment ça Fonctionne. L'image la Plus parlante je trouve C'est celle du débruitage. C'est Concrètement De comprendre le principe De la diffusion Et De ce Qu'on Appelle Un auto-encodeur. En gros le principe C'est Que Pour entraîner le Modèle Et le… Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels. Et le job De Ton Système d'apprentissage, ça va être De Reconstruire… Et le job De Ton Système d'apprentissage, ça va être De Reconstruire L'image d'origine. Et en gros, sa fonction De récompense, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux De… Bruits Qui sont Très faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit à petit tu vas Détruire De Plus en Plus Ton image Jusqu'à ce Que Ton Modèle, à partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entièrement. C'est ça la magie du truc, C'est Que Entre Temps Ton image a Complètement disparu Et Ton Modèle est capable, Avec du rien, du bruit, De Générer plein De variantes Qui correspondent à Ton Texte. C'est Un peu ça la magie De la diffusion. Et ce Qui est intéressant C'est Que ce Que tu vises C'est d'avoir Un Modèle Qui est Relativement créatif. C'est Un peu l'autre truc à comprendre, C'est Que ces Modèles-là, Ils sont constamment… En tension Entre deux extrêmes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ça va être toujours la Même Et ça C'est Un Modèle Qui est tombé Dans la… Qui est tombé Dans l'apprentissage Par cœur Et Qui est Plus capable De Généraliser. On est Sur du bachotage. Oui, Exactement. Et T'as Un autre Extrême, Des Modèles Qui vont Pas être Capables De faire du réalisme ou Qui vont Avoir Des résultats toujours Un peu Très flous. Très blurry, Mais Qui vont être Très variés. Et Tout l'enjeu Des gens Qui créent Des Modèles De ce type-là, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces deux écueils-là Et Ils essayent De Avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modèles De diffusion, ça Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 2225,
      "context": "\"text_human\": \"Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille. C'est Pas mal d'avoir Une petite Intuition De Comment ça Fonctionne. L'image la Plus parlante je trouve C'est celle du débruitage. C'est Concrètement De comprendre le principe De la diffusion Et De ce Qu'on Appelle Un auto-encodeur. En gros le principe C'est Que Pour entraîner le Modèle Et le… Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels. Et le job De Ton Système d'apprentissage, ça va être De Reconstruire… Et le job De Ton Système d'apprentissage, ça va être De Reconstruire L'image d'origine. Et en gros, sa fonction De récompense, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux De… Bruits Qui sont Très faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit à petit tu vas Détruire De Plus en Plus Ton image Jusqu'à ce Que Ton Modèle, à partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entièrement. C'est ça la magie du truc, C'est Que Entre Temps Ton image a Complètement disparu Et Ton Modèle est capable, Avec du rien, du bruit, De Générer plein De variantes Qui correspondent à Ton Texte. C'est Un peu ça la magie De la diffusion. Et ce Qui est intéressant C'est Que ce Que tu vises C'est d'avoir Un Modèle Qui est Relativement créatif. C'est Un peu l'autre truc à comprendre, C'est Que ces Modèles-là, Ils sont constamment… En tension Entre deux extrêmes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ça va être toujours la Même Et ça C'est Un Modèle Qui est tombé Dans la… Qui est tombé Dans l'apprentissage Par cœur Et Qui est Plus capable De Généraliser. On est Sur du bachotage. Oui, Exactement. Et T'as Un autre Extrême, Des Modèles Qui vont Pas être Capables De faire du réalisme ou Qui vont Avoir Des résultats toujours Un peu Très flous. Très blurry, Mais Qui vont être Très variés. Et Tout l'enjeu Des gens Qui créent Des Modèles De ce type-là, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces deux écueils-là Et Ils essayent De Avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modèles De diffusion, ça Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 2226,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 2783,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5266,
      "context": "\"text\": \"2014, tu as Des premiers exemples De Modèles De diffusion, Typiquement Pour Générer Des chiffres. La grosse limite De ces Modèles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais Générer Une image Sur le label pêcheur, ça te donnait Des images De pêcheur. Mais si tu voulais… Un pêcheur Avec Un chapeau rouge, C'était Pas entraîné Pour. La vraie révolution, C'est le Fait De Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, le principe De base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du Texte Et De L'image. Et tu vas De cette manière-là pouvoir entraîner Un Modèle Qui va être générique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la sémantique du Texte Et la représentation Dans L'image. C'est Vraiment ça Qui a déclenché la révolution Qu'on connaît Aujourd'hui. Un autre truc trop intéressant Dans l'histoire Des Modèles De diffusion, C'est qu'à partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités De données massives, Et d'images. Sauf Que le problème, C'est qu'en termes De quantité disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet. Là-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Déjà Extraire Uniquement Toutes Les images Pour Servir De base D'entraînement. Et Pour ça, ce qu'ils ont Fait, C'est Très simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les développeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associée. Qui est associé. Parce Qu'on a le alt Qui en général est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilité, contient Une description De L'image. Le problème De ça, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Même il y a Peut-être en grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et… La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5267,
      "context": "\"text_human\": \"2014, tu as Des premiers exemples De Modèles De diffusion, Typiquement Pour Générer Des chiffres. La grosse limite De ces Modèles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais Générer Une image Sur le label pêcheur, ça te donnait Des images De pêcheur. Mais si tu voulais… Un pêcheur Avec Un chapeau rouge, C'était Pas entraîné Pour. La vraie révolution, C'est le Fait De Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, le principe De base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du Texte Et De L'image. Et tu vas De cette manière-là pouvoir entraîner Un Modèle Qui va être générique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la sémantique du Texte Et la représentation Dans L'image. C'est Vraiment ça Qui a déclenché la révolution Qu'on connaît Aujourd'hui. Un autre truc trop intéressant Dans l'histoire Des Modèles De diffusion, C'est qu'à partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités De données massives, Et d'images. Sauf Que le problème, C'est qu'en termes De quantité disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet. Là-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Déjà Extraire Uniquement Toutes Les images Pour Servir De base D'entraînement. Et Pour ça, ce qu'ils ont Fait, C'est Très simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les développeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associée. Qui est associé. Parce Qu'on a le alt Qui en général est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilité, contient Une description De L'image. Le problème De ça, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Même il y a Peut-être en grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et… La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 5268,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 6840,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7895,
      "context": "\"text\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité. Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques. Et ce Que tu vas faire, C'est Que tu vas prendre Un Modèle comme Clip, Qui sert à Avoir Une première représentation D'une image justement, Et tu vas entraîner par-dessus Un Modèle De scoring esthétique. C'est-à-dire Qu'on Lui donne Une image, on Lui dit « essaie De prédire ». La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7896,
      "context": "\"text_human\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité. Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques. Et ce Que tu vas faire, C'est Que tu vas prendre Un Modèle comme Clip, Qui sert à Avoir Une première représentation D'une image justement, Et tu vas entraîner par-dessus Un Modèle De scoring esthétique. C'est-à-dire Qu'on Lui donne Une image, on Lui dit « essaie De prédire ». La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7897,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 7978,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8167,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8342,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8370,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 8930,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9138,
      "context": "\"text\": \"Même s'il y a Quand Même Pas mal De variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9139,
      "context": "\"text_human\": \"Même s'il y a Quand Même Pas mal De variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9140,
      "context": "\"text_machine\": \"Meme s'il y a Quand Meme Pas mal De variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits comme ca, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 9326,
      "context": "\"word\": \"datasets,\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 26051,
      "context": "\"text\": \"Le deuxième usage, C'est le style. C'est justement d'apprendre Un style spécifique. Ça peut être du réalisme, du pixel art ou Une direction artistique comme Un… Ou Une direction artistique comme Underscore, Par Exemple. Là, ça veut dire qu'est-ce Que tu Lui as donné Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donné Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ça dépend De… Du type D'entraînement Que tu fais. Tu peux faire Des entraînements complets du Modèle, Un fine tuning Sur l'ensemble Des poids du Modèle, ou tu peux faire ce Qu'on Appelle Un LoRa, où là Pour le coup, tu vas dégeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas dégeler justement, Entre 16, 32. En gros, tu vas infléchir la Trajectoire. Avant qu'ils te fournissent Une sortie. Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit. J'ai Un peu essayé Les deux justement. Tu as Des API Qui te permettent De facilement entraîner Des Modèles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 26052,
      "context": "\"text_human\": \"Le deuxième usage, C'est le style. C'est justement d'apprendre Un style spécifique. Ça peut être du réalisme, du pixel art ou Une direction artistique comme Un… Ou Une direction artistique comme Underscore, Par Exemple. Là, ça veut dire qu'est-ce Que tu Lui as donné Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donné Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ça dépend De… Du type D'entraînement Que tu fais. Tu peux faire Des entraînements complets du Modèle, Un fine tuning Sur l'ensemble Des poids du Modèle, ou tu peux faire ce Qu'on Appelle Un LoRa, où là Pour le coup, tu vas dégeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas dégeler justement, Entre 16, 32. En gros, tu vas infléchir la Trajectoire. Avant qu'ils te fournissent Une sortie. Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit. J'ai Un peu essayé Les deux justement. Tu as Des API Qui te permettent De facilement entraîner Des Modèles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 26053,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27079,
      "context": "\"word\": \"dataset\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 27450,
      "context": "\"word\": \"datasets\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 31736,
      "context": "\"text\": \"Adapté, prendre, utiliser Dans Une boîte à outils Que tu leur donnes Des choses Un peu Prémâchées Et Les adapter à la situation Qui correspond. Il Faut aborder Un peu Tous Les Problèmes Que tu veux résoudre Avec Des LLM De cette manière Pour Avoir Des Bons résultats. Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts. Peut-être Vous souvenez, Mais on a toujours été Des Très mauvais élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier Encore Une fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 31737,
      "context": "\"text_human\": \"Adapté, prendre, utiliser Dans Une boîte à outils Que tu leur donnes Des choses Un peu Prémâchées Et Les adapter à la situation Qui correspond. Il Faut aborder Un peu Tous Les Problèmes Que tu veux résoudre Avec Des LLM De cette manière Pour Avoir Des Bons résultats. Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts. Peut-être Vous souvenez, Mais on a toujours été Des Très mauvais élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier Encore Une fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 31738,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 32246,
      "context": "\"word\": \"workflow,\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 35595,
      "context": "\"text\": \"Et au début, on a Fait Des tests Assez simples, comme ça, Avec De l'inpainting, Et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à Trouver le bon Modèle. Et à Trouver le bon Système. , on prend la miniature, on l'agrandit, on la met derrière, on la floute. Ça sert De point De départ à l'inpainting. Le masque a Une opacité faible. Il y avait Une petite mécanique à Trouver, Mais là comme ça, il invente Même Des reflets Et Tout ça. Très bien. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est comme ça Qu'on règle le problème De la fiabilité, C'est Qu'on sait Qu'il y en a toujours Une Sur quatre Qui est bonne. Il y a Une miniature différente Pour chaque pot. Exactement du coup. Et bien le résultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tirés directement De la chaîne YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques. Entièrement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier cette histoire récente De Comment l'IA a créé Une puce De calcul parfaite, Mais Qui échappe Complètement à la compréhension Des humains. C'était Dans cette vidéo.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 35596,
      "context": "\"text_human\": \"Et au début, on a Fait Des tests Assez simples, comme ça, Avec De l'inpainting, Et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à Trouver le bon Modèle. Et à Trouver le bon Système. , on prend la miniature, on l'agrandit, on la met derrière, on la floute. Ça sert De point De départ à l'inpainting. Le masque a Une opacité faible. Il y avait Une petite mécanique à Trouver, Mais là comme ça, il invente Même Des reflets Et Tout ça. Très bien. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est comme ça Qu'on règle le problème De la fiabilité, C'est Qu'on sait Qu'il y en a toujours Une Sur quatre Qui est bonne. Il y a Une miniature différente Pour chaque pot. Exactement du coup. Et bien le résultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tirés directement De la chaîne YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques. Entièrement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier cette histoire récente De Comment l'IA a créé Une puce De calcul parfaite, Mais Qui échappe Complètement à la compréhension Des humains. C'était Dans cette vidéo.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 35597,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\05_polished.json",
      "line": 37176,
      "context": "\"word\": \"workflows\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 24,
      "context": "\"text_human\": \"Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire Un outil D'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et justement, je Vous parle d'expérience, Parce Que ça Fait Quelques mois Qu'on a développé Un Système Pour gérer nos podcasts Complètement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement à Quoi ça ressemble De développer Un outil IA utile De A à Z. Pas Une vague interface par-dessus ChatGPT ou Une énième automatisation De triage d'emails, Mais Un outil concret Qui tourne en production Et Qui résout Un vrai problème. Le but, C'est De Montrer l'envers du Décor De l'IA en entreprise. Se perdre Dans la jungle Des Modèles Et Des promesses saléchantes, le fine-tuning fastidieux, L'excitation De l'expérimentation Et le désespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec Un peu De chance, Un outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet préféré. Mais Juste Avant, J'ai Un Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modèles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, Une boîte française, rassemble Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment à jour. Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers comme Mistral Small, Qui sont 10 fois moins énergivores. Tout ça à partir De 10 euros Par mois. Le lien est en description Et on reprend. Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 25,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 212,
      "context": "\"text\": \"Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 295,
      "context": "\"text_human\": \"Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille. C'est Pas mal d'avoir Une petite Intuition De Comment ça Fonctionne. L'image la Plus parlante je trouve C'est celle du débruitage. C'est Concrètement De comprendre le principe De la diffusion Et De ce Qu'on Appelle Un auto-encodeur. En gros le principe C'est Que Pour entraîner le Modèle Et le… Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels. Et le job De Ton Système d'apprentissage, ça va être De Reconstruire… Et le job De Ton Système d'apprentissage, ça va être De Reconstruire L'image d'origine. Et en gros, sa fonction De récompense, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux De… Bruits Qui sont Très faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit à petit tu vas Détruire De Plus en Plus Ton image Jusqu'à ce Que Ton Modèle, à partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entièrement. C'est ça la magie du truc, C'est Que Entre Temps Ton image a Complètement disparu Et Ton Modèle est capable, Avec du rien, du bruit, De Générer plein De variantes Qui correspondent à Ton Texte. C'est Un peu ça la magie De la diffusion. Et ce Qui est intéressant C'est Que ce Que tu vises C'est d'avoir Un Modèle Qui est Relativement créatif. C'est Un peu l'autre truc à comprendre, C'est Que ces Modèles-là, Ils sont constamment… En tension Entre deux extrêmes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ça va être toujours la Même Et ça C'est Un Modèle Qui est tombé Dans la… Qui est tombé Dans l'apprentissage Par cœur Et Qui est Plus capable De Généraliser.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 296,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 363,
      "context": "\"text\": \"Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 555,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 849,
      "context": "\"text_human\": \"Sauf Que le problème, C'est qu'en termes De quantité disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet. Là-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Déjà Extraire Uniquement Toutes Les images Pour Servir De base D'entraînement. Et Pour ça, ce qu'ils ont Fait, C'est Très simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les développeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associée. Qui est associé. Parce Qu'on a le alt Qui en général est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilité, contient Une description De L'image. Le problème De ça, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Même il y a Peut-être en grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et… La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité. Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques. Et ce Que tu vas faire, C'est Que tu vas prendre Un Modèle comme Clip, Qui sert à Avoir Une première représentation D'une image justement, Et tu vas entraîner par-dessus Un Modèle De scoring esthétique. C'est-à-dire Qu'on Lui donne Une image, on Lui dit « essaie De prédire ». La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 850,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. 2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 869,
      "context": "\"text\": \"C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 989,
      "context": "\"text\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1001,
      "context": "\"text\": \"Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1025,
      "context": "\"text\": \"AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1061,
      "context": "\"text\": \"La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1096,
      "context": "\"text_human\": \"La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle. Même s'il y a Quand Même Pas mal De variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics. Qui correspondent à Internet filtré Sur Tout ce Qui est 5 étoiles Et Plus. Et ça, il Faut se dire qu'avant Qu'on ait ça, Tout ce Qu'on a connu derrière comme Modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient De Générer Une matrice De pixels directement. , Une image. Ce Qui était Très… Demandeur en ressources, en mémoire Et en capacité De calcul. Et la révolution qu'amène Stability Fusion Entre autres, la première version, C'est De créer Une représentation Intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive De faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une image Par Message ou Par mail, si tu la télécharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. Là on a Un petit Exemple Avec Un chien. Là, celui Que Vous voyez à gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 méga en PNG. Fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain est absolument incapable De voir la différence Alors Qu'il y a 10 fois moins De données. , Une première Intuition du Fait Que l'œil humain ne se représente Pas la donnée De la Même manière. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire à l'original, Mais Que Tous Les autres détails sont Bons, Ton œil humain ne verra jamais la différence.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1097,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle. Meme s'il y a Quand Meme Pas mal De variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits comme ca, Les premiers datasets, Qui s'appellent l'Ion Aesthetics. Meme s'il y a Quand Meme Pas mal De variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits comme ca, Les premiers datasets, Qui s'appellent l'Ion Aesthetics. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant. Qui correspondent a Internet filtre Sur Tout ce Qui est 5 etoiles Et Plus. Et ca, il Faut se dire qu'avant Qu'on ait ca, Tout ce Qu'on a connu derriere comme Modele d'image etait impossible. 1 deuxieme avancee majeure Qu'il y a eu, C'est Que la, Dans Les Modeles primitifs Qu'on voit, Ils essaient De Generer 1 matrice De pixels directement. , 1 image. Ce Qui etait Tres... Demandeur en ressources, en memoire Et en capacite De calcul. Et la revolution qu'amene Stability Fusion Entre autres, la premiere version, C'est De creer 1 representation Intermediaire. C'est le fameux espace latent. Il y a 1 maniere intuitive De faire 1 analogie, C'est ce qu'est la compression d'image. Quand je t'envoie 1 image Par Message ou Par mail, si tu la telecharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. La on a 1 petit Exemple Avec 1 chien. La, celui Que Vous voyez a gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 mega en PNG. Fait 1 mega en PNG. L'arrete, C'est Que l' il humain est absolument incapable De voir la difference Alors Qu'il y a 10 fois moins De donnees. , 1 premiere Intuition du Fait Que l' il humain ne se represente Pas la donnee De la Meme maniere. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire a l'original, Mais Que Tous Les autres details sont Bons, Ton il humain ne verra jamais la difference. L'espace latent, C'est 1 analogie, Mais il Faut se dire Que C'est 1 peu la Meme chose. Ca va decrire le contenu De L'image, le Plus Precisement possible, Et a partir De cet espace latent, tu vas pouvoir... Generer Ton image finale Avec le decodeur. C'est ca Qui a Vraiment revolutionne aussi Les Modeles d'image. C'est Que d'1 coup on se retrouve a Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ca Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modeles d'image Completement hallucinant, Meme De videos Maintenant.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1104,
      "context": "\"text\": \"La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 1128,
      "context": "\"text\": \"Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3116,
      "context": "\"text_machine\": \"Exactement, ce Qui est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. Pour l'infiltration C'est genial Elles se ressemblent Pas mal il y a 1 personne a droite 1 element d'image a gauche Et 1 Texte au-dessus ce Qui est Typiquement 1 layout classique De la chaine Et la en gros il a Fait 10 miniatures Par version C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fut-ce Que Pour se donner Des idees C'est Deja genial. T'as Tout Compris. La Realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja au debut A Avoir Des resultats Quand Meme Bons comme ca. Et en Meme Temps, J'ai vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible De faire. Peut-etre Que C'est possible d'aller Encore Gratter 1 peu De qualite. De consistance, Mais la Quand la Realite C'est Que C'est du AI junk Quand Meme, C'est a dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Tres naturellement, comme tu l'as devine, C'est devenu 1 outil De brainstorming ou je l'utilisais Pour donner 4 idees De miniatures Et Avoir instantanement 80 Versions differentes. Exactement, ce Qui est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. Pour l'infiltration C'est genial Elles se ressemblent Pas mal il y a 1 personne a droite 1 element d'image a gauche Et 1 Texte au-dessus ce Qui est Typiquement 1 layout classique De la chaine Et la en gros il a Fait 10 miniatures Par version C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fut-ce Que Pour se donner Des idees C'est Deja genial. T'as Tout Compris. La Realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja au debut A Avoir Des resultats Quand Meme Bons comme ca. Et en Meme Temps, J'ai vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible De faire. Peut-etre Que C'est possible d'aller Encore Gratter 1 peu De qualite. De consistance, Mais la Quand la Realite C'est Que C'est du AI junk Quand Meme, C'est a dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Tres naturellement, comme tu l'as devine, C'est devenu 1 outil De brainstorming ou je l'utilisais Pour donner 4 idees De miniatures Et Avoir instantanement 80 Versions differentes. Exactement, ce Qui est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. Pour l'infiltration C'est genial Elles se ressemblent Pas mal il y a 1 personne a droite 1 element d'image a gauche Et 1 Texte au-dessus ce Qui est Typiquement 1 layout classique De la chaine Et la en gros il a Fait 10 miniatures Par version C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fut-ce Que Pour se donner Des idees C'est Deja genial. T'as Tout Compris. La Realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja au debut A Avoir Des resultats Quand Meme Bons comme ca. Et en Meme Temps, J'ai vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible De faire. Peut-etre Que C'est possible d'aller Encore Gratter 1 peu De qualite. De consistance, Mais la Quand la Realite C'est Que C'est du AI junk Quand Meme, C'est a dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Tres naturellement, comme tu l'as devine, C'est devenu 1 outil De brainstorming ou je l'utilisais Pour donner 4 idees De miniatures Et Avoir instantanement 80 Versions differentes. Exactement, ce Qui est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. Pour l'infiltration C'est genial Elles se ressemblent Pas mal il y a 1 personne a droite 1 element d'image a gauche Et 1 Texte au-dessus ce Qui est Typiquement 1 layout classique De la chaine Et la en gros il a Fait 10 miniatures Par version C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fut-ce Que Pour se donner Des idees C'est Deja genial. T'as Tout Compris. La Realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja au debut A Avoir Des resultats Quand Meme Bons comme ca. Et en Meme Temps, J'ai vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible De faire. Peut-etre Que C'est possible d'aller Encore Gratter 1 peu De qualite. De consistance, Mais la Quand la Realite C'est Que C'est du AI junk Quand Meme, C'est a dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Tres naturellement, comme tu l'as devine, C'est devenu 1 outil De brainstorming ou je l'utilisais Pour donner 4 idees De miniatures Et Avoir instantanement 80 Versions differentes. Exactement, ce Qui est Tres drole, C'est Qu'on reconnait parfois Certains melanges d'invites. Mais C'est vachement bien. C'est Pas mal. La, le truc Avec la hit cam. Ouais, carrement. Pour l'infiltration C'est genial Elles se ressemblent Pas mal il y a 1 personne a droite 1 element d'image a gauche Et 1 Texte au-dessus ce Qui est Typiquement 1 layout classique De la chaine Et la en gros il a Fait 10 miniatures Par version C'est Pour ca Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fut-ce Que Pour se donner Des idees C'est Deja genial. T'as Tout Compris. La Realite, C'est qu'en le commencant, je n'avais Pas d'attente specifique. Je ne m'attendais Pas Deja au debut A Avoir Des resultats Quand Meme Bons comme ca. Et en Meme Temps, J'ai vite vu Qu'il y avait 1 plateau. C'est-a-dire Que la, C'etait le mieux Qui etait possible De faire. Peut-etre Que C'est possible d'aller Encore Gratter 1 peu De qualite. De consistance, Mais la Quand la Realite C'est Que C'est du AI junk Quand Meme, C'est a dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Des Que tu zooms, il n'y a Plus rien Qui marche. La aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Tres naturellement, comme tu l'as devine, C'est devenu 1 outil De brainstorming ou je l'utilisais Pour donner 4 idees De miniatures Et Avoir instantanement 80 Versions differentes. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Comment on Fait Quelque chose comme ca ? , il y a plein d'astuces Et De triches A plein d'endroits. Il y a Des artifices partout Pour Que ca marche Et ca donne ce resultat. Quand tu veux creer 1 image Qui ressemble a ta chaine, tu peux essayer d'aller Sur 1 GPT, mid-journee, Etc. Et De Lui demander Quelque chose Avec 1 fond bleu, 1 degrade Vert. Le noir Et l'invite a droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ca. La premiere chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modele sous-jacent Et Les poids Pour obtenir le resultat Que tu veux. Tu as 2 usages principaux. Le Premier, C'est d'entrainer 1 identite, De faire en sorte d'apprendre quelle est ma tete Pour creer Des miniatures. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3398,
      "context": "\"text_human\": \"Je Lui AI donné Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ça dépend De… Du type D'entraînement Que tu fais. Tu peux faire Des entraînements complets du Modèle, Un fine tuning Sur l'ensemble Des poids du Modèle, ou tu peux faire ce Qu'on Appelle Un LoRa, où là Pour le coup, tu vas dégeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas dégeler justement, Entre 16, 32. En gros, tu vas infléchir la Trajectoire. Avant qu'ils te fournissent Une sortie. Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit. J'ai Un peu essayé Les deux justement. Tu as Des API Qui te permettent De facilement entraîner Des Modèles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec seulement Des datasets De 20 images. Il y a Un Premier trick à comprendre Qui donne Des résultats comme ça, Qui donne Des résultats comme ça, C'est Que Pour Des Bons résultats, T'as plein De paramètres Que tu peux Modifier. Un Premier paramètre, C'est Par Exemple la vitesse D'entraînement, le learning rate. Et là, Faut le voir comme Un étudiant, C'est-à-dire Que tu peux Soit Bachoter, apprendre Très vite, Mais Avec Des risques Que ta mémoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et là … … Tu as Beaucoup moins De chances d'oublier Et d'être à côté De la percée. Il Faut dire Que C'est la Même chose. Tu as d'autres paramètres comme ça, je Vous AI dit le nombre De layers Que tu vas vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour Avoir Des Bons résultats, C'est De faire littéralement Une matrice. Et De tester Tous Les paramètres, Un Par Un, Jusqu'à Avoir Un Modèle Qui marche bien.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3399,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3502,
      "context": "\"text\": \"Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3550,
      "context": "\"text\": \"Là, C'est Des entraînements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3976,
      "context": "\"text_human\": \"C'est Pas Non Plus Un formulaire le truc, Mais C'est ça Qui a permis d'avoir Des résultats aussi Bons derrière. Et il y a Un autre Exemple De ça Qui est trop intéressant, C'est Les applis Qui étaient Capables De te Générer Des landing Pages, Des sites web complets, Avec Un Pages, Des sites web complets Avec Un Prompt. Tu te dis waouh, C'est dingue, tu mets Un Prompt, ça te sort Une page d'accueil d'un site web ultra léché Et parfait. Et, la Réalité, C'est Que derrière, tu avais Une base De données. De segments De sites, De slides Que le Modèle pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est Une super Intuition Pour comprendre Comment utiliser au mieux Les Modèles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extrêmement Bons Pour adapter Et répliquer. Adapté, prendre, utiliser Dans Une boîte à outils Que tu leur donnes Des choses Un peu Prémâchées Et Les adapter à la situation Qui correspond. Il Faut aborder Un peu Tous Les Problèmes Que tu veux résoudre Avec Des LLM De cette manière Pour Avoir Des Bons résultats. Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts. Peut-être Vous souvenez, Mais on a toujours été Des Très mauvais élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier Encore Une fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier en créant Un Système quasiment automatisé De publication De nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 3977,
      "context": "\"text_machine\": \"Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Il y a 1 Premier trick a comprendre Qui donne Des resultats comme ca, Qui donne Des resultats comme ca, C'est Que Pour Des Bons resultats, T'as plein De parametres Que tu peux Modifier. 1 Premier parametre, C'est Par Exemple la vitesse D'entrainement, le learning rate. Et la, Faut le voir comme 1 etudiant, C'est-a-dire Que tu peux Soit Bachoter, apprendre Tres vite, Mais Avec Des risques Que ta memoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et la ... ... Tu as Beaucoup moins De chances d'oublier Et d'etre a cote De la percee. Il Faut dire Que C'est la Meme chose. Tu as d'autres parametres comme ca, je Vous AI dit le nombre De layers Que tu vas vouloir degeler. Et la conclusion Qu'on a realisee, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouve Pour Avoir Des Bons resultats, C'est De faire litteralement 1 matrice. Et De tester Tous Les parametres, 1 Par 1, Jusqu'a Avoir 1 Modele Qui marche bien. A la fin, on est arrive Avec, je pense, 20, 30 Modeles differents. Et apres, comme lequel est le bon, tu testes. Sur chaque Modele, tu donnes 5 entrees differentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et penible a faire Et C'est le seul moyen Qu'on a trouve en Tout cas d'avoir 1 bon Modele Qui donne Des Bons resultats. La deuxieme supercherie Qui Fait Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par realiser en ayant Des Tres mauvais Que la ca donne Des aussi Bons resultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par realiser en ayant Des Tres mauvais resultats pendant longtemps, Que le Modele n'etait Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures ou il y a 1 gros Texte Sur le cote, 1 Fleche Et Quelque chose. Ou on a 1 invite, 1 Texte Et 1 boite. Ou on a 1 truc Qui Fait 1 peu schema Avec ce style-la. Jusqu'a ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a 1 truc hyper interessant derriere a comprendre Sur ces Modeles-la, Et Que Meme s'ils ne sont Pas intelligents, Ils sont Tres Bons Pour... Trouver quel est le schema Qui correspond le mieux a telle ou telle situation. Et la pipeline Qui permet De Generer ces miniatures, Elle a De decrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Meme, la Typiquement, Quand Elle Fait 1 style comme ca De schema, Elle va s'adapter, Elle va... Instruire le Modele Pour Qu'il Modifie telle ou telle partie du Prompt De maniere Intelligente. C'est Pas Non Plus 1 formulaire le truc, Mais C'est ca Qui a permis d'avoir Des resultats aussi Bons derriere. Et il y a 1 autre Exemple De ca Qui est trop interessant, C'est Les applis Qui etaient Capables De te Generer Des landing Pages, Des sites web complets, Avec 1 Pages, Des sites web complets Avec 1 Prompt. Tu te dis waouh, C'est dingue, tu mets 1 Prompt, ca te sort 1 page d'accueil d'1 site web ultra leche Et parfait. Et, la Realite, C'est Que derriere, tu avais 1 base De donnees. De segments De sites, De slides Que le Modele pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est 1 super Intuition Pour comprendre Comment utiliser au mieux Les Modeles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extremement Bons Pour adapter Et repliquer. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier en creant 1 Systeme quasiment automatise De publication De nos podcasts. L'idee, C'est qu'1 podcast, C'est simplement 1 version 1 petit peu coupee en enlevant ce Qui n'est Pas necessaire, Typiquement le son. Qu'on sort, Des choses comme ca, De la video Qui est sortie Sur YouTube Et Que ca se Passe Plus ou moins en autopilote. Quand on a 1 video Sur YouTube, Elle est recuperee Par le Systeme automatiquement. On Fait Les decoupes Qu'il Faut, on Les rajoute Dans 1 base De donnees, 1 base De donnees Qui ressemble a ca, Sur Notion. Des Que nos videos sortent, Elles sont rajoutees. La, Typiquement, Notre derniere video Micode, Elle a ete rajoutee Toute seule. La date De publication De podcast, on met saved Et C'est Tout, termine le podcast. Et il va etre publie. Et le seul travail Qu'il y a eu, C'est Qu'il y a eu 1 monteur en amont Qui a enleve Les parties Que tu voulais Pas Avoir Dans le podcast. Non, le montage se Fait Tout seul. Ah enlever le sponsor Par Exemple ? Ca se Fait Tout seul.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4080,
      "context": "\"text\": \"Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4531,
      "context": "\"text_human\": \"Le problème, C'est qu'en podcast, Les miniatures, Elles sont carrées. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? Trois petits points. Eh bien, la solution, C'est super simple, C'est De faire Un Système De Dean Painting. Globalement, Notre but là, C'est De Trouver Un Système Pour Que, à partir D'une miniature, on vienne combler ce Qu'il y a en haut Et en bas. Et au début, on a Fait Des tests Assez simples, comme ça, Avec De l'inpainting, Et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à Trouver le bon Modèle. Et à Trouver le bon Système. , on prend la miniature, on l'agrandit, on la met derrière, on la floute. Ça sert De point De départ à l'inpainting. Le masque a Une opacité faible. Il y avait Une petite mécanique à Trouver, Mais là comme ça, il invente Même Des reflets Et Tout ça. Très bien. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est comme ça Qu'on règle le problème De la fiabilité, C'est Qu'on sait Qu'il y en a toujours Une Sur quatre Qui est bonne. Il y a Une miniature différente Pour chaque pot. Exactement du coup. Et bien le résultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tirés directement De la chaîne YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques. Entièrement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier cette histoire récente De Comment l'IA a créé Une puce De calcul parfaite, Mais Qui échappe Complètement à la compréhension Des humains.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4532,
      "context": "\"text_machine\": \"Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Il y a 1 truc De... On est monotache, on va dire. On est monotache. En gros, on s'occupe d'1 truc, Mais si C'est en dehors, ca ne marche Pas. Sauf si C'est... Pour l'avoir Fait pendant plusieurs annees, C'est chiant. Elle n'a aucune valeur ajoutee. Le probleme, C'est qu'en podcast, Les miniatures, Elles sont carrees. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? 3 petits points. Eh bien, la solution, C'est super simple, C'est De faire 1 Systeme De Dean Painting. Globalement, Notre but la, C'est De Trouver 1 Systeme Pour Que, a partir D'1 miniature, on vienne combler ce Qu'il y a en haut Et en bas. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4803,
      "context": "\"text\": \"Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\chunks.json",
      "line": 4863,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video. Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 7,
      "context": "\"paragraph\": \"Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire Un outil D'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et justement, je Vous parle d'expérience, Parce Que ça Fait Quelques mois Qu'on a développé Un Système Pour gérer nos podcasts Complètement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement à Quoi ça ressemble De développer Un outil IA utile De A à Z. Pas Une vague interface par-dessus ChatGPT ou Une énième automatisation De triage d'emails, Mais Un outil concret Qui tourne en production Et Qui résout Un vrai problème. Le but, C'est De Montrer l'envers du Décor De l'IA en entreprise. Se perdre Dans la jungle Des Modèles Et Des promesses saléchantes, le fine-tuning fastidieux, L'excitation De l'expérimentation Et le désespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec Un peu De chance, Un outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet préféré. Mais Juste Avant, J'ai Un Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modèles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, Une boîte française, rassemble Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment à jour. Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers comme Mistral Small, Qui sont 10 fois moins énergivores. Tout ça à partir De 10 euros Par mois. Le lien est en description Et on reprend. Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille. C'est Pas mal d'avoir Une petite Intuition De Comment ça Fonctionne. L'image la Plus parlante je trouve C'est celle du débruitage. C'est Concrètement De comprendre le principe De la diffusion Et De ce Qu'on Appelle Un auto-encodeur. En gros le principe C'est Que Pour entraîner le Modèle Et le… Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels. Et le job De Ton Système d'apprentissage, ça va être De Reconstruire… Et le job De Ton Système d'apprentissage, ça va être De Reconstruire L'image d'origine. Et en gros, sa fonction De récompense, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux De… Bruits Qui sont Très faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit à petit tu vas Détruire De Plus en Plus Ton image Jusqu'à ce Que Ton Modèle, à partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entièrement. C'est ça la magie du truc, C'est Que Entre Temps Ton image a Complètement disparu Et Ton Modèle est capable, Avec du rien, du bruit, De Générer plein De variantes Qui correspondent à Ton Texte. C'est Un peu ça la magie De la diffusion. Et ce Qui est intéressant C'est Que ce Que tu vises C'est d'avoir Un Modèle Qui est Relativement créatif. C'est Un peu l'autre truc à comprendre, C'est Que ces Modèles-là, Ils sont constamment… En tension Entre deux extrêmes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ça va être toujours la Même Et ça C'est Un Modèle Qui est tombé Dans la… Qui est tombé Dans l'apprentissage Par cœur Et Qui est Plus capable De Généraliser. On est Sur du bachotage. Oui, Exactement. Et T'as Un autre Extrême, Des Modèles Qui vont Pas être Capables De faire du réalisme ou Qui vont Avoir Des résultats toujours Un peu Très flous. Très blurry, Mais Qui vont être Très variés. Et Tout l'enjeu Des gens Qui créent Des Modèles De ce type-là, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces deux écueils-là Et Ils essayent De Avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modèles De diffusion, ça Fait depuis bien Avant Que StableDiffusion existe. 2014, tu as Des premiers exemples De Modèles De diffusion, Typiquement Pour Générer Des chiffres. La grosse limite De ces Modèles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais Générer Une image Sur le label pêcheur, ça te donnait Des images De pêcheur. Mais si tu voulais… Un pêcheur Avec Un chapeau rouge, C'était Pas entraîné Pour. La vraie révolution, C'est le Fait De Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, le principe De base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du Texte Et De L'image. Et tu vas De cette manière-là pouvoir entraîner Un Modèle Qui va être générique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la sémantique du Texte Et la représentation Dans L'image. C'est Vraiment ça Qui a déclenché la révolution Qu'on connaît Aujourd'hui. Un autre truc trop intéressant Dans l'histoire Des Modèles De diffusion, C'est qu'à partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités De données massives, Et d'images. Sauf Que le problème, C'est qu'en termes De quantité disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet. Là-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Déjà Extraire Uniquement Toutes Les images Pour Servir De base D'entraînement. Et Pour ça, ce qu'ils ont Fait, C'est Très simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les développeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associée. Qui est associé. Parce Qu'on a le alt Qui en général est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilité, contient Une description De L'image. Le problème De ça, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Même il y a Peut-être en grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et… La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité. Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques. Et ce Que tu vas faire, C'est Que tu vas prendre Un Modèle comme Clip, Qui sert à Avoir Une première représentation D'une image justement, Et tu vas entraîner par-dessus Un Modèle De scoring esthétique. C'est-à-dire Qu'on Lui donne Une image, on Lui dit « essaie De prédire ». La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle. Même s'il y a Quand Même Pas mal De variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics. Qui correspondent à Internet filtré Sur Tout ce Qui est 5 étoiles Et Plus. Et ça, il Faut se dire qu'avant Qu'on ait ça, Tout ce Qu'on a connu derrière comme Modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient De Générer Une matrice De pixels directement. , Une image. Ce Qui était Très… Demandeur en ressources, en mémoire Et en capacité De calcul. Et la révolution qu'amène Stability Fusion Entre autres, la première version, C'est De créer Une représentation Intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive De faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une image Par Message ou Par mail, si tu la télécharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. Là on a Un petit Exemple Avec Un chien. Là, celui Que Vous voyez à gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 méga en PNG. Fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain est absolument incapable De voir la différence Alors Qu'il y a 10 fois moins De données. , Une première Intuition du Fait Que l'œil humain ne se représente Pas la donnée De la Même manière. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire à l'original, Mais Que Tous Les autres détails sont Bons, Ton œil humain ne verra jamais la différence. L'espace latent, C'est Une analogie, Mais il Faut se dire Que C'est Un peu la Même chose. Ça va décrire le contenu De L'image, le Plus Précisément possible, Et à partir De cet espace latent, tu vas pouvoir… Générer Ton image finale Avec le décodeur. C'est ça Qui a Vraiment révolutionné aussi Les Modèles d'image. C'est Que d'un coup on se retrouve à Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ça Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modèles d'image Complètement hallucinant, Même De vidéos Maintenant.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 18,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 32,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 46,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 60,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 74,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 88,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 102,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 116,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 130,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 144,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 158,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 172,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 186,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 200,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 214,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 226,
      "context": "\"text\": \"Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 227,
      "context": "\"text_human\": \"Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 228,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 242,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 256,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 270,
      "context": "\"text_machine\": \"Des mois Qu'on nous bassine Avec l'IA Qui va revolutionner Tous Les metiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire 1 outil D'IA Qui marche Vraiment, C'est souvent 1 autre histoire. Et justement, je Vous parle d'experience, Parce Que ca Fait Quelques mois Qu'on a developpe 1 Systeme Pour gerer nos podcasts Completement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement a Quoi ca ressemble De developper 1 outil IA utile De A a Z. Pas 1 vague interface par-dessus ChatGPT ou 1 enieme automatisation De triage d'emails, Mais 1 outil concret Qui tourne en production Et Qui resout 1 vrai probleme. Le but, C'est De Montrer l'envers du Decor De l'IA en entreprise. Se perdre Dans la jungle Des Modeles Et Des promesses salechantes, le fine-tuning fastidieux, L'excitation De l'experimentation Et le desespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec 1 peu De chance, 1 outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet prefere. Mais Juste Avant, J'ai 1 Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modeles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, 1 boite francaise, rassemble Mammut AI, 1 boite francaise, rassemble Tous Les grands Modeles Dans 1 seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Meme Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment a jour. Vos donnees sont hebergees en Europe Avec le 0 Data Retention, Vos promptes ne sont Pas conservees Et Les fournisseurs De Modeles ne s'entrainent Pas Sur Vos donnees. En Plus, Vous pourrez opter Pour Des Modeles Plus legers comme Mistral Small, Qui sont 10 fois moins energivores. Tout ca a partir De 10 euros Par mois. Le lien est en description Et on reprend.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 284,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 298,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 312,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 326,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 340,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 352,
      "context": "\"text\": \"Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 353,
      "context": "\"text_human\": \"Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 354,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 368,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 382,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 396,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 410,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 424,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 438,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 452,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 466,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 480,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 494,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 508,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 522,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 536,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 550,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 564,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 578,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 592,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 606,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 620,
      "context": "\"text_machine\": \"Deja on part d'ou, Comment marchent ces Modeles Et Avec Quoi on travaille. C'est Pas mal d'avoir 1 petite Intuition De Comment ca Fonctionne. L'image la Plus parlante je trouve C'est celle du debruitage. C'est Concretement De comprendre le principe De la diffusion Et De ce Qu'on Appelle 1 auto-encodeur. En gros le principe C'est Que Pour entrainer le Modele Et le... Lui creer cette sorte De comprehension du monde Et Des objets, tu vas creer 1 immense dataset d'images Et tu vas appliquer 1 leger bruit dessus, 1 legere perturbation De la matrice De pixels. Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire... Et le job De Ton Systeme d'apprentissage, ca va etre De Reconstruire L'image d'origine. Et en gros, sa fonction De recompense, son mecanisme d'apprentissage va le recompenser Dans sa capacite a recreer le Plus parfaitement possible L'image d'origine. Au debut, tu commences Avec Des niveaux De... Bruits Qui sont Tres faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit a petit tu vas Detruire De Plus en Plus Ton image Jusqu'a ce Que Ton Modele, a partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entierement. C'est ca la magie du truc, C'est Que Entre Temps Ton image a Completement disparu Et Ton Modele est capable, Avec du rien, du bruit, De Generer plein De variantes Qui correspondent a Ton Texte. C'est 1 peu ca la magie De la diffusion. Et ce Qui est interessant C'est Que ce Que tu vises C'est d'avoir 1 Modele Qui est Relativement creatif. C'est 1 peu l'autre truc a comprendre, C'est Que ces Modeles-la, Ils sont constamment... En tension Entre 2 extremes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ca va etre toujours la Meme Et ca C'est 1 Modele Qui est tombe Dans la... Qui est tombe Dans l'apprentissage Par c ur Et Qui est Plus capable De Generaliser. On est Sur du bachotage. Oui, Exactement. Et T'as 1 autre Extreme, Des Modeles Qui vont Pas etre Capables De faire du realisme ou Qui vont Avoir Des resultats toujours 1 peu Tres flous. Tres blurry, Mais Qui vont etre Tres varies. Et Tout l'enjeu Des gens Qui creent Des Modeles De ce type-la, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces 2 ecueils-la Et Ils essayent De Avoir le meilleur Des 2 mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modeles De diffusion, ca Fait depuis bien Avant Que StableDiffusion existe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 634,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 648,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 662,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 676,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 690,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 704,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 718,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 732,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 746,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 760,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 774,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 788,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 802,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 816,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 830,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 842,
      "context": "\"text\": \"C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 843,
      "context": "\"text_human\": \"C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 844,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 858,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 872,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 886,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 900,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 914,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 928,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 942,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 956,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 970,
      "context": "\"text_machine\": \"2014, tu as Des premiers exemples De Modeles De diffusion, Typiquement Pour Generer Des chiffres. La grosse limite De ces Modeles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'etait discret. Tu pouvais Generer 1 image Sur le label pecheur, ca te donnait Des images De pecheur. Mais si tu voulais... 1 pecheur Avec 1 chapeau rouge, C'etait Pas entraine Pour. La vraie revolution, C'est le Fait De Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, Combiner 1 Modele De diffusion Avec justement 1 Modele comme Clip. En gros, le principe De base, C'est Que tu vas representer au sein d'1 Meme espace vectoriel du Texte Et De L'image. Et tu vas De cette maniere-la pouvoir entrainer 1 Modele Qui va etre generique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la semantique du Texte Et la representation Dans L'image. C'est Vraiment ca Qui a declenche la revolution Qu'on connait Aujourd'hui. 1 autre truc trop interessant Dans l'histoire Des Modeles De diffusion, C'est qu'a partir du moment ou on avait la theorie Pour Les creer, il fallait Des quantites De donnees massives, Et d'images. Sauf Que le probleme, C'est qu'en termes De quantite disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement 1 dataset Qui s'appelle Common Crawl, Qui constitue 1 sorte d'empreinte a 1 instant T d'internet. La-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Deja Extraire Uniquement Toutes Les images Pour Servir De base D'entrainement. Et Pour ca, ce qu'ils ont Fait, C'est Tres simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les developpeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associee. Qui est associe. Parce Qu'on a le alt Qui en general est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilite, contient 1 description De L'image. Le probleme De ca, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Meme il y a Peut-etre en grande majorite Des trucs Pas beaux, ignobles, voire illegaux. Et... La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 982,
      "context": "\"text\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 983,
      "context": "\"text_human\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 984,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 996,
      "context": "\"text\": \"Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 997,
      "context": "\"text_human\": \"Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 998,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1012,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1024,
      "context": "\"text\": \"AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1025,
      "context": "\"text_human\": \"AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1026,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1040,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1054,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1066,
      "context": "\"text\": \"La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1067,
      "context": "\"text_human\": \"La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1068,
      "context": "\"text_machine\": \"Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets ou Les humains donnent Des notes a Des images en Tres grande quantite. Il y en a plein, Typiquement il y a Flickr, C'est 1 enorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthetiques. Et ce Que tu vas faire, C'est Que tu vas prendre 1 Modele comme Clip, Qui sert a Avoir 1 premiere representation D'1 image justement, Et tu vas entrainer par-dessus 1 Modele De scoring esthetique. C'est-a-dire Qu'on Lui donne 1 image, on Lui dit essaie De predire . La note Sur 5 De cette image Sur le plan esthetique il va faire 1 tentative Et on va le corriger Et il va Lui faire apprendre Sur 1 dataset on pourrait s'attendre a Des resultats chaotiques Mais C'est Pas ce Qu'on obtient, ca converge il semble Que, spoiler, il y a Quand Meme 1 Notion il me semble Que, spoiler, il y a Quand Meme 1 Notion De beaute universelle.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1082,
      "context": "\"text_machine\": \"Meme s'il y a Quand Meme Pas mal De variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits comme ca, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1094,
      "context": "\"text\": \"Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1095,
      "context": "\"text_human\": \"Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1096,
      "context": "\"text_machine\": \"Meme s'il y a Quand Meme Pas mal De variances Dans Les resultats. Et C'est Les premiers Modeles Qui ont ete construits comme ca, Les premiers datasets, Qui s'appellent l'Ion Aesthetics.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1421,
      "context": "\"text\": \"Des mois Qu'on nous bassine Avec l'IA Qui va révolutionner Tous Les métiers ou remplacer Tous Les emplois. Sauf Que Dans la vraie vie, Quand on essaye De construire Un outil D'IA Qui marche Vraiment, C'est souvent Une autre histoire. Et justement, je Vous parle d'expérience, Parce Que ça Fait Quelques mois Qu'on a développé Un Système Pour gérer nos podcasts Complètement automatiquement. Et je vais pouvoir Vous Montrer. Montrer Exactement à Quoi ça ressemble De développer Un outil IA utile De A à Z. Pas Une vague interface par-dessus ChatGPT ou Une énième automatisation De triage d'emails, Mais Un outil concret Qui tourne en production Et Qui résout Un vrai problème. Le but, C'est De Montrer l'envers du Décor De l'IA en entreprise. Se perdre Dans la jungle Des Modèles Et Des promesses saléchantes, le fine-tuning fastidieux, L'excitation De l'expérimentation Et le désespoir Des impasses. Vous allez voir, Pas De solution miracle, Pas De bouton magique, Juste Beaucoup d'essais. Et au bout, Avec Un peu De chance, Un outil Qui fera Fonctionne Vraiment. Aujourd'hui, je Vous raconte Comment on a construit mon nouveau Jouet préféré. Mais Juste Avant, J'ai Un Message Pour Tous ceux Qui veulent utiliser Les meilleurs Modèles D'IA sans multiplier Les abonnements. Notre partenaire Mammoth AI, Une boîte française, rassemble Mammut AI, Une boîte française, rassemble Tous Les grands Modèles Dans Une seule interface. On parle De Cloud 4.5, GPT-5, Nano Banana, Même Perplexity Deep Research. , il y a Vraiment Tout Et Ils Les mettent constamment à jour. Vos données sont hébergées en Europe Avec le Zero Data Retention, Vos promptes ne sont Pas conservées Et Les fournisseurs De Modèles ne s'entraînent Pas Sur Vos données. En Plus, Vous pourrez opter Pour Des Modèles Plus légers comme Mistral Small, Qui sont 10 fois moins énergivores. Tout ça à partir De 10 euros Par mois. Le lien est en description Et on reprend. Déjà on part d'où, Comment marchent ces Modèles Et Avec Quoi on travaille. C'est Pas mal d'avoir Une petite Intuition De Comment ça Fonctionne. L'image la Plus parlante je trouve C'est celle du débruitage. C'est Concrètement De comprendre le principe De la diffusion Et De ce Qu'on Appelle Un auto-encodeur. En gros le principe C'est Que Pour entraîner le Modèle Et le… Lui créer cette sorte De compréhension du monde Et Des objets, tu vas créer Un immense dataset d'images Et tu vas appliquer Un léger bruit dessus, Une légère perturbation De la matrice De pixels. Et le job De Ton Système d'apprentissage, ça va être De Reconstruire… Et le job De Ton Système d'apprentissage, ça va être De Reconstruire L'image d'origine. Et en gros, sa fonction De récompense, son mécanisme d'apprentissage va le récompenser Dans sa capacité à recréer le Plus parfaitement possible L'image d'origine. Au début, tu commences Avec Des niveaux De… Bruits Qui sont Très faibles, C'est Relativement facile De Reconstruire Les textures Etc. Et petit à petit tu vas Détruire De Plus en Plus Ton image Jusqu'à ce Que Ton Modèle, à partir Uniquement du bruit Et De la description en Texte De L'image, est capable De la Reconstruire Entièrement. C'est ça la magie du truc, C'est Que Entre Temps Ton image a Complètement disparu Et Ton Modèle est capable, Avec du rien, du bruit, De Générer plein De variantes Qui correspondent à Ton Texte. C'est Un peu ça la magie De la diffusion. Et ce Qui est intéressant C'est Que ce Que tu vises C'est d'avoir Un Modèle Qui est Relativement créatif. C'est Un peu l'autre truc à comprendre, C'est Que ces Modèles-là, Ils sont constamment… En tension Entre deux extrêmes. Il y en a Qui sont Capables De faire Des super belles femmes brunes en portrait Sauf Que tu vas le relancer 20 fois ça va être toujours la Même Et ça C'est Un Modèle Qui est tombé Dans la… Qui est tombé Dans l'apprentissage Par cœur Et Qui est Plus capable De Généraliser. On est Sur du bachotage. Oui, Exactement. Et T'as Un autre Extrême, Des Modèles Qui vont Pas être Capables De faire du réalisme ou Qui vont Avoir Des résultats toujours Un peu Très flous. Très blurry, Mais Qui vont être Très variés. Et Tout l'enjeu Des gens Qui créent Des Modèles De ce type-là, Pour comprendre, il Faut dire qu'ils sont Tout le Temps Entre ces deux écueils-là Et Ils essayent De Avoir le meilleur Des deux mondes en employant Des techniques distinctes. Ce Qui est marrant d'ailleurs, C'est Que Les Modèles De diffusion, ça Fait depuis bien Avant Que StableDiffusion existe. 2014, tu as Des premiers exemples De Modèles De diffusion, Typiquement Pour Générer Des chiffres. La grosse limite De ces Modèles primitifs, C'est qu', Ils marchaient Avec Des labels. En gros, C'était discret. Tu pouvais Générer Une image Sur le label pêcheur, ça te donnait Des images De pêcheur. Mais si tu voulais… Un pêcheur Avec Un chapeau rouge, C'était Pas entraîné Pour. La vraie révolution, C'est le Fait De Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, Combiner Un Modèle De diffusion Avec justement Un Modèle comme Clip. En gros, le principe De base, C'est Que tu vas représenter au sein d'un Même espace vectoriel du Texte Et De L'image. Et tu vas De cette manière-là pouvoir entraîner Un Modèle Qui va être générique Sur n'importe quel Texte. Et Qui va pouvoir comprendre justement le lien. Entre la sémantique du Texte Et la représentation Dans L'image. C'est Vraiment ça Qui a déclenché la révolution Qu'on connaît Aujourd'hui. Un autre truc trop intéressant Dans l'histoire Des Modèles De diffusion, C'est qu'à partir du moment où on avait la théorie Pour Les créer, il fallait Des quantités De données massives, Et d'images. Sauf Que le problème, C'est qu'en termes De quantité disponible, en masse, ce Qu'on a Globalement C'est Internet. C'est Typiquement Un dataset Qui s'appelle Common Crawl, Qui constitue Une sorte d'empreinte à Un instant T d'internet. Là-dedans, tu as du Texte Et De L'image. Tu veux pouvoir Déjà Extraire Uniquement Toutes Les images Pour Servir De base D'entraînement. Et Pour ça, ce qu'ils ont Fait, C'est Très simple, C'est Que tu scans Toutes Les Pages web, tu regardes Les tags images, Tous Les développeurs Les connaissent, Et tu vas Extraire aussi la description Qui est associée. Qui est associé. Parce Qu'on a le alt Qui en général est Fait Pour Les moteurs De recherche ou Pour Les histoires d'accessibilité, contient Une description De L'image. Le problème De ça, C'est Que Sur Internet, on le sait bien Qu'il n'y a Pas Que Des belles images. Même il y a Peut-être en grande majorité Des trucs Pas beaux, ignobles, voire illégaux. Et… La question C'est Comment tu filtres ce Qui est beau De ce Qui n'est Pas beau. Dans Les faits, ce Qui se Passe C'est Qu'on a Des datasets où Les humains donnent Des notes à Des images en Très grande quantité. Il y en a plein, Typiquement il y a Flickr, C'est Un énorme dataset De notes. Soit C'est Des pouces vers le haut, vers le bas, Soit C'est Vraiment Des notes Sur 5. AVA, il y a plusieurs datasets Qui sont Des datasets esthétiques. Et ce Que tu vas faire, C'est Que tu vas prendre Un Modèle comme Clip, Qui sert à Avoir Une première représentation D'une image justement, Et tu vas entraîner par-dessus Un Modèle De scoring esthétique. C'est-à-dire Qu'on Lui donne Une image, on Lui dit « essaie De prédire ». La note Sur 5 De cette image Sur le plan esthétique il va faire Une tentative Et on va le corriger Et il va Lui faire apprendre Sur Un dataset on pourrait s'attendre à Des résultats chaotiques Mais C'est Pas ce Qu'on obtient, ça converge il semble Que, spoiler, il y a Quand Même Une Notion il me semble Que, spoiler, il y a Quand Même Une Notion De beauté universelle. Même s'il y a Quand Même Pas mal De variances Dans Les résultats. Et C'est Les premiers Modèles Qui ont été construits comme ça, Les premiers datasets, Qui s'appellent l'Ion Aesthetics. Qui correspondent à Internet filtré Sur Tout ce Qui est 5 étoiles Et Plus. Et ça, il Faut se dire qu'avant Qu'on ait ça, Tout ce Qu'on a connu derrière comme Modèle d'image était impossible. Une deuxième avancée majeure Qu'il y a eu, C'est Que là, Dans Les Modèles primitifs Qu'on voit, Ils essaient De Générer Une matrice De pixels directement. , Une image. Ce Qui était Très… Demandeur en ressources, en mémoire Et en capacité De calcul. Et la révolution qu'amène Stability Fusion Entre autres, la première version, C'est De créer Une représentation Intermédiaire. C'est le fameux espace latent. Il y a Une manière intuitive De faire Une analogie, C'est ce qu'est la compression d'image. Quand je t'envoie Une image Par Message ou Par mail, si tu la télécharges Elle va faire je sais Pas moi, 100 kilobits Par Exemple. Là on a Un petit Exemple Avec Un chien. Là, celui Que Vous voyez à gauche, il Fait 80 kilo-octets, Alors Que la version originale Qui sort De l'appareil photo, Elle, Elle Fait 1 méga en PNG. Fait 1 méga en PNG. L'arrêté, C'est Que l'œil humain est absolument incapable De voir la différence Alors Qu'il y a 10 fois moins De données. , Une première Intuition du Fait Que l'œil humain ne se représente Pas la donnée De la Même manière. En gros, si la texture du poil du chien n'est Pas parfaite, Et similaire à l'original, Mais Que Tous Les autres détails sont Bons, Ton œil humain ne verra jamais la différence. L'espace latent, C'est Une analogie, Mais il Faut se dire Que C'est Un peu la Même chose. Ça va décrire le contenu De L'image, le Plus Précisément possible, Et à partir De cet espace latent, tu vas pouvoir… Générer Ton image finale Avec le décodeur. C'est ça Qui a Vraiment révolutionné aussi Les Modèles d'image. C'est Que d'un coup on se retrouve à Travailler Avec Des ressources Beaucoup Plus restreintes. C'est ça Qui Fait Que tu peux Sur Ton Sur Ton ordi gamer, tu peux faire tourner Des Modèles d'image Complètement hallucinant, Même De vidéos Maintenant.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 1424,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 2954,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 2969,
      "context": "\"paragraph\": \"Exactement, ce Qui est Très drôle, C'est Qu'on reconnaît parfois Certains mélanges d'invités. Mais C'est vachement bien. C'est Pas mal. Là, le truc Avec la hit cam. Ouais, carrément. Pour l'infiltration C'est génial Elles se ressemblent Pas mal il y a Une personne à droite Un élément d'image à gauche Et Un Texte au-dessus ce Qui est Typiquement Un layout classique De la chaîne Et là en gros il a Fait 10 miniatures Par version C'est Pour ça Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fût-ce Que Pour se donner Des idées C'est Déjà génial. T'as Tout Compris. La Réalité, C'est qu'en le commençant, je n'avais Pas d'attente spécifique. Je ne m'attendais Pas Déjà au début À Avoir Des résultats Quand Même Bons comme ça. Et en Même Temps, J'ai vite vu Qu'il y avait Un plateau. C'est-à-dire Que là, C'était le mieux Qui était possible De faire. Peut-être Que C'est possible d'aller Encore Gratter Un peu De qualité. De consistance, Mais là Quand la Réalité C'est Que C'est du AI junk Quand Même, C'est à dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Dès Que tu zooms, il n'y a Plus rien Qui marche. Là aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Très naturellement, comme tu l'as deviné, C'est devenu Un outil De brainstorming où je l'utilisais Pour donner quatre idées De miniatures Et Avoir instantanément 80 Versions différentes. Comment on Fait Quelque chose comme ça ? , il y a plein d'astuces Et De triches À plein d'endroits. Il y a Des artifices partout Pour Que ça marche Et ça donne ce résultat. Quand tu veux créer Une image Qui ressemble à ta chaîne, tu peux essayer d'aller Sur Un GPT, mid-journée, Etc. Et De Lui demander Quelque chose Avec Un fond bleu, Un dégradé Vert. Le noir Et l'invité à droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ça. La première chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modèle sous-jacent Et Les poids Pour obtenir le résultat Que tu veux. Tu as deux usages principaux. Le Premier, C'est d'entraîner Une identité, De faire en sorte d'apprendre quelle est ma tête Pour créer Des miniatures. Le deuxième usage, C'est le style. C'est justement d'apprendre Un style spécifique. Ça peut être du réalisme, du pixel art ou Une direction artistique comme Un… Ou Une direction artistique comme Underscore, Par Exemple. Là, ça veut dire qu'est-ce Que tu Lui as donné Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donné Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ça dépend De… Du type D'entraînement Que tu fais. Tu peux faire Des entraînements complets du Modèle, Un fine tuning Sur l'ensemble Des poids du Modèle, ou tu peux faire ce Qu'on Appelle Un LoRa, où là Pour le coup, tu vas dégeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas dégeler justement, Entre 16, 32. En gros, tu vas infléchir la Trajectoire. Avant qu'ils te fournissent Une sortie. Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit. J'ai Un peu essayé Les deux justement. Tu as Des API Qui te permettent De facilement entraîner Des Modèles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec seulement Des datasets De 20 images. Il y a Un Premier trick à comprendre Qui donne Des résultats comme ça, Qui donne Des résultats comme ça, C'est Que Pour Des Bons résultats, T'as plein De paramètres Que tu peux Modifier. Un Premier paramètre, C'est Par Exemple la vitesse D'entraînement, le learning rate. Et là, Faut le voir comme Un étudiant, C'est-à-dire Que tu peux Soit Bachoter, apprendre Très vite, Mais Avec Des risques Que ta mémoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et là … … Tu as Beaucoup moins De chances d'oublier Et d'être à côté De la percée. Il Faut dire Que C'est la Même chose. Tu as d'autres paramètres comme ça, je Vous AI dit le nombre De layers Que tu vas vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour Avoir Des Bons résultats, C'est De faire littéralement Une matrice. Et De tester Tous Les paramètres, Un Par Un, Jusqu'à Avoir Un Modèle Qui marche bien. À la fin, on est arrivé Avec, je pense, 20, 30 Modèles différents. Et après, comme lequel est le bon, tu testes. Sur chaque Modèle, tu donnes cinq entrées différentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et pénible à faire Et C'est le seul moyen Qu'on a trouvé en Tout cas d'avoir Un bon Modèle Qui donne Des Bons résultats. La deuxième supercherie Qui Fait Que là ça donne Des aussi Bons résultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par réaliser en ayant Des Très mauvais Que là ça donne Des aussi Bons résultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par réaliser en ayant Des Très mauvais résultats pendant longtemps, Que le Modèle n'était Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures où il y a Un gros Texte Sur le côté, Une Flèche Et Quelque chose. Ou on a Un invité, Un Texte Et Une boîte. Ou on a Un truc Qui Fait Un peu schéma Avec ce style-là. Jusqu'à ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a Un truc hyper intéressant derrière à comprendre Sur ces Modèles-là, Et Que Même s'ils ne sont Pas intelligents, Ils sont Très Bons Pour… Trouver quel est le schéma Qui correspond le mieux à telle ou telle situation. Et la pipeline Qui permet De Générer ces miniatures, Elle a De décrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Même, là Typiquement, Quand Elle Fait Un style comme ça De schéma, Elle va s'adapter, Elle va… Instruire le Modèle Pour Qu'il Modifie telle ou telle partie du Prompt De manière Intelligente. C'est Pas Non Plus Un formulaire le truc, Mais C'est ça Qui a permis d'avoir Des résultats aussi Bons derrière. Et il y a Un autre Exemple De ça Qui est trop intéressant, C'est Les applis Qui étaient Capables De te Générer Des landing Pages, Des sites web complets, Avec Un Pages, Des sites web complets Avec Un Prompt. Tu te dis waouh, C'est dingue, tu mets Un Prompt, ça te sort Une page d'accueil d'un site web ultra léché Et parfait. Et, la Réalité, C'est Que derrière, tu avais Une base De données. De segments De sites, De slides Que le Modèle pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est Une super Intuition Pour comprendre Comment utiliser au mieux Les Modèles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extrêmement Bons Pour adapter Et répliquer. Adapté, prendre, utiliser Dans Une boîte à outils Que tu leur donnes Des choses Un peu Prémâchées Et Les adapter à la situation Qui correspond. Il Faut aborder Un peu Tous Les Problèmes Que tu veux résoudre Avec Des LLM De cette manière Pour Avoir Des Bons résultats. Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts. Peut-être Vous souvenez, Mais on a toujours été Des Très mauvais élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier Encore Une fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier en créant Un Système quasiment automatisé De publication De nos podcasts. L'idée, C'est qu'un podcast, C'est simplement Une version Un petit peu coupée en enlevant ce Qui n'est Pas nécessaire, Typiquement le son. Qu'on sort, Des choses comme ça, De la vidéo Qui est sortie Sur YouTube Et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle est récupérée Par le Système automatiquement. On Fait Les découpes Qu'il Faut, on Les rajoute Dans Une base De données, Une base De données Qui ressemble à ça, Sur Notion. Dès Que nos vidéos sortent, Elles sont rajoutées. Là, Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée Toute seule. La date De publication De podcast, on met saved Et C'est Tout, terminé le podcast. Et il va être publié. Et le seul travail Qu'il y a eu, C'est Qu'il y a eu Un monteur en amont Qui a enlevé Les parties Que tu voulais Pas Avoir Dans le podcast. Non, le montage se Fait Tout seul. Ah enlever le sponsor Par Exemple ? Ça se Fait Tout seul. Déjà Pour ceux Qui sont amateurs De podcast, sachez Que cette année… Il va y en Avoir Beaucoup Plus. , Tous Les lundis Et jeudis matin, il y aura Underscore Et Les documentaires Qui seront Sur Les plateformes De podcast. Et la raison Pour laquelle je suis à peu près serein De m'y engager, C'est Qu'on n'a rien à faire Pour Que ça se produise. J'allais Vraiment dire, T'as l'ami. J'allais Vraiment dire, T'as l'ami Corp, l'humain n'est Pas fiable. C'est vrai. Il y a Un truc De… On est monotâche, on va dire. On est monotâche. En gros, on s'occupe d'un truc, Mais si C'est en dehors, ça ne marche Pas. Sauf si C'est… Pour l'avoir Fait pendant plusieurs années, C'est chiant. Elle n'a aucune valeur ajoutée. Le problème, C'est qu'en podcast, Les miniatures, Elles sont carrées. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? Trois petits points. Eh bien, la solution, C'est super simple, C'est De faire Un Système De Dean Painting. Globalement, Notre but là, C'est De Trouver Un Système Pour Que, à partir D'une miniature, on vienne combler ce Qu'il y a en haut Et en bas.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3344,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3358,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3372,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3386,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3400,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3414,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3428,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3442,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3456,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3470,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3484,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3498,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3512,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3524,
      "context": "\"text\": \"Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3525,
      "context": "\"text_human\": \"Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3526,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3540,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3554,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3568,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3580,
      "context": "\"text\": \"Là, C'est Des entraînements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3581,
      "context": "\"text_human\": \"Là, C'est Des entraînements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 3582,
      "context": "\"text_machine\": \"Le deuxieme usage, C'est le style. C'est justement d'apprendre 1 style specifique. Ca peut etre du realisme, du pixel art ou 1 direction artistique comme 1... Ou 1 direction artistique comme Underscore, Par Exemple. La, ca veut dire qu'est-ce Que tu Lui as donne Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donne Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ca depend De... Du type D'entrainement Que tu fais. Tu peux faire Des entrainements complets du Modele, 1 fine tuning Sur l'ensemble Des poids du Modele, ou tu peux faire ce Qu'on Appelle 1 LoRa, ou la Pour le coup, tu vas degeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas degeler justement, Entre 16, 32. En gros, tu vas inflechir la Trajectoire. Avant qu'ils te fournissent 1 sortie. Et la Pour le coup, tu peux etre Sur 1 dataset Beaucoup Plus petit. J'ai 1 peu essaye Les 2 justement. Tu as Des API Qui te permettent De facilement entrainer Des Modeles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Tres mauvais resultats Sur l'entrainement en entier. La, C'est Des entrainements Avec seulement Des datasets De 20 images.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4072,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4086,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4098,
      "context": "\"text\": \"Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4099,
      "context": "\"text_human\": \"Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4100,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4114,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4128,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4142,
      "context": "\"text_machine\": \"Adapte, prendre, utiliser Dans 1 boite a outils Que tu leur donnes Des choses 1 peu Premachees Et Les adapter a la situation Qui correspond. Il Faut aborder 1 peu Tous Les Problemes Que tu veux resoudre Avec Des LLM De cette maniere Pour Avoir Des Bons resultats. Le truc Pour le coup Qu'on s'est mis a Vraiment utiliser Tout le Temps Et Qui est 1 Systeme Systeme automatique integre a 1 workflow, C'est la publication De nos podcasts. Peut-etre Vous souvenez, Mais on a toujours ete Des Tres mauvais eleves Sur Les podcasts Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe. Et cet ete, J'ai decide d'y remedier Encore 1 fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaine YouTube, on a du mal a Tout gerer en Meme Temps, on n'est Pas 1 grande equipe.\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4621,
      "context": "\"text\": \"Exactement, ce Qui est Très drôle, C'est Qu'on reconnaît parfois Certains mélanges d'invités. Mais C'est vachement bien. C'est Pas mal. Là, le truc Avec la hit cam. Ouais, carrément. Pour l'infiltration C'est génial Elles se ressemblent Pas mal il y a Une personne à droite Un élément d'image à gauche Et Un Texte au-dessus ce Qui est Typiquement Un layout classique De la chaîne Et là en gros il a Fait 10 miniatures Par version C'est Pour ça Qu'il y en a Pas mal Qui se ressemblent Entre Elles Mais ne fût-ce Que Pour se donner Des idées C'est Déjà génial. T'as Tout Compris. La Réalité, C'est qu'en le commençant, je n'avais Pas d'attente spécifique. Je ne m'attendais Pas Déjà au début À Avoir Des résultats Quand Même Bons comme ça. Et en Même Temps, J'ai vite vu Qu'il y avait Un plateau. C'est-à-dire Que là, C'était le mieux Qui était possible De faire. Peut-être Que C'est possible d'aller Encore Gratter Un peu De qualité. De consistance, Mais là Quand la Réalité C'est Que C'est du AI junk Quand Même, C'est à dire Que T'as Des fautes Quand tu zooms, T'as Ton Texte, la gueule du gars ignoble, tu as Ton Texte, la gueule du gars est ignoble. Dès Que tu zooms, il n'y a Plus rien Qui marche. Là aussi, le Fait Que ce Soit impressionnant, C'est Qu'on Les voit en petit. , Très naturellement, comme tu l'as deviné, C'est devenu Un outil De brainstorming où je l'utilisais Pour donner quatre idées De miniatures Et Avoir instantanément 80 Versions différentes. Comment on Fait Quelque chose comme ça ? , il y a plein d'astuces Et De triches À plein d'endroits. Il y a Des artifices partout Pour Que ça marche Et ça donne ce résultat. Quand tu veux créer Une image Qui ressemble à ta chaîne, tu peux essayer d'aller Sur Un GPT, mid-journée, Etc. Et De Lui demander Quelque chose Avec Un fond bleu, Un dégradé Vert. Le noir Et l'invité à droite, tu peux essayer autant Que tu veux, tu n'obtiendras jamais Quelque chose Qui est proche comme ça. La première chose, C'est De faire du fine tuning. C'est le Fait d'aller Vraiment Modifier le Modèle sous-jacent Et Les poids Pour obtenir le résultat Que tu veux. Tu as deux usages principaux. Le Premier, C'est d'entraîner Une identité, De faire en sorte d'apprendre quelle est ma tête Pour créer Des miniatures. Le deuxième usage, C'est le style. C'est justement d'apprendre Un style spécifique. Ça peut être du réalisme, du pixel art ou Une direction artistique comme Un… Ou Une direction artistique comme Underscore, Par Exemple. Là, ça veut dire qu'est-ce Que tu Lui as donné Toutes Les anciennes miniatures d'Underscore ? Je Lui AI donné Des miniatures d'Underscore. Mais justement, bonne transition, Combien il en Faut ? Eh bien, ça dépend De… Du type D'entraînement Que tu fais. Tu peux faire Des entraînements complets du Modèle, Un fine tuning Sur l'ensemble Des poids du Modèle, ou tu peux faire ce Qu'on Appelle Un LoRa, où là Pour le coup, tu vas dégeler Uniquement Quelques couches. Tu peux choisir Combien De couches tu vas dégeler justement, Entre 16, 32. En gros, tu vas infléchir la Trajectoire. Avant qu'ils te fournissent Une sortie. Et là Pour le coup, tu peux être Sur Un dataset Beaucoup Plus petit. J'ai Un peu essayé Les deux justement. Tu as Des API Qui te permettent De facilement entraîner Des Modèles comme Flux, Soit en entier, Soit Avec du LoRa. Et, on a Des Très mauvais résultats Sur l'entraînement en entier. Là, C'est Des entraînements Avec seulement Des datasets De 20 images. Il y a Un Premier trick à comprendre Qui donne Des résultats comme ça, Qui donne Des résultats comme ça, C'est Que Pour Des Bons résultats, T'as plein De paramètres Que tu peux Modifier. Un Premier paramètre, C'est Par Exemple la vitesse D'entraînement, le learning rate. Et là, Faut le voir comme Un étudiant, C'est-à-dire Que tu peux Soit Bachoter, apprendre Très vite, Mais Avec Des risques Que ta mémoire, Elle Soit Fucked up, Soit tu peux apprendre lentement, Et là … … Tu as Beaucoup moins De chances d'oublier Et d'être à côté De la percée. Il Faut dire Que C'est la Même chose. Tu as d'autres paramètres comme ça, je Vous AI dit le nombre De layers Que tu vas vouloir dégeler. Et la conclusion Qu'on a réalisée, C'est Qu'il n'y a Pas De recette magique du Tout. Et le seul moyen Qu'on a trouvé Pour Avoir Des Bons résultats, C'est De faire littéralement Une matrice. Et De tester Tous Les paramètres, Un Par Un, Jusqu'à Avoir Un Modèle Qui marche bien. À la fin, on est arrivé Avec, je pense, 20, 30 Modèles différents. Et après, comme lequel est le bon, tu testes. Sur chaque Modèle, tu donnes cinq entrées différentes. Tu filtres ce Qui est bon, ce Qui n'est Pas bon. Vraiment, C'est Assez long. Et pénible à faire Et C'est le seul moyen Qu'on a trouvé en Tout cas d'avoir Un bon Modèle Qui donne Des Bons résultats. La deuxième supercherie Qui Fait Que là ça donne Des aussi Bons résultats, C'est au niveau Des promptes. C'est qu'j'ai fini Par réaliser en ayant Des Très mauvais Que là ça donne Des aussi Bons résultats, C'est au niveau Des promptes. C'est qu'en Fait, J'ai fini Par réaliser en ayant Des Très mauvais résultats pendant longtemps, Que le Modèle n'était Pas Non Plus Assez intelligent Pour comprendre la structure sous-jacente Des miniatures. Et le Fait Qu'on a Des miniatures où il y a Un gros Texte Sur le côté, Une Flèche Et Quelque chose. Ou on a Un invité, Un Texte Et Une boîte. Ou on a Un truc Qui Fait Un peu schéma Avec ce style-là. Jusqu'à ce Que je comprenne Qu'il fallait le guider Plus. Et je trouve Qu'il y a Un truc hyper intéressant derrière à comprendre Sur ces Modèles-là, Et Que Même s'ils ne sont Pas intelligents, Ils sont Très Bons Pour… Trouver quel est le schéma Qui correspond le mieux à telle ou telle situation. Et la pipeline Qui permet De Générer ces miniatures, Elle a De décrites, 5 ou 6 templates De promptes Qu'elle peut aller utiliser Et remplir. Il y a De l'adaptation Quand Même, là Typiquement, Quand Elle Fait Un style comme ça De schéma, Elle va s'adapter, Elle va… Instruire le Modèle Pour Qu'il Modifie telle ou telle partie du Prompt De manière Intelligente. C'est Pas Non Plus Un formulaire le truc, Mais C'est ça Qui a permis d'avoir Des résultats aussi Bons derrière. Et il y a Un autre Exemple De ça Qui est trop intéressant, C'est Les applis Qui étaient Capables De te Générer Des landing Pages, Des sites web complets, Avec Un Pages, Des sites web complets Avec Un Prompt. Tu te dis waouh, C'est dingue, tu mets Un Prompt, ça te sort Une page d'accueil d'un site web ultra léché Et parfait. Et, la Réalité, C'est Que derrière, tu avais Une base De données. De segments De sites, De slides Que le Modèle pouvait utiliser, changer l'ordre, Etc. Je trouve Que C'est Une super Intuition Pour comprendre Comment utiliser au mieux Les Modèles Maintenant Et comprendre qu'ils ne sont Pas si intelligents, Mais Par contre, Ils sont extrêmement Bons Pour adapter Et répliquer. Adapté, prendre, utiliser Dans Une boîte à outils Que tu leur donnes Des choses Un peu Prémâchées Et Les adapter à la situation Qui correspond. Il Faut aborder Un peu Tous Les Problèmes Que tu veux résoudre Avec Des LLM De cette manière Pour Avoir Des Bons résultats. Le truc Pour le coup Qu'on s'est mis à Vraiment utiliser Tout le Temps Et Qui est Un Système Système automatique intégré à Un workflow, C'est la publication De nos podcasts. Peut-être Vous souvenez, Mais on a toujours été Des Très mauvais élèves Sur Les podcasts Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier Encore Une fois, je Vous remercie. Parce Que Quand on se concentre Sur la chaîne YouTube, on a du mal à Tout gérer en Même Temps, on n'est Pas Une grande équipe. Et cet été, J'ai décidé d'y remédier en créant Un Système quasiment automatisé De publication De nos podcasts. L'idée, C'est qu'un podcast, C'est simplement Une version Un petit peu coupée en enlevant ce Qui n'est Pas nécessaire, Typiquement le son. Qu'on sort, Des choses comme ça, De la vidéo Qui est sortie Sur YouTube Et Que ça se Passe Plus ou moins en autopilote. Quand on a Une vidéo Sur YouTube, Elle est récupérée Par le Système automatiquement. On Fait Les découpes Qu'il Faut, on Les rajoute Dans Une base De données, Une base De données Qui ressemble à ça, Sur Notion. Dès Que nos vidéos sortent, Elles sont rajoutées. Là, Typiquement, Notre dernière vidéo Micode, Elle a été rajoutée Toute seule. La date De publication De podcast, on met saved Et C'est Tout, terminé le podcast. Et il va être publié. Et le seul travail Qu'il y a eu, C'est Qu'il y a eu Un monteur en amont Qui a enlevé Les parties Que tu voulais Pas Avoir Dans le podcast. Non, le montage se Fait Tout seul. Ah enlever le sponsor Par Exemple ? Ça se Fait Tout seul. Déjà Pour ceux Qui sont amateurs De podcast, sachez Que cette année… Il va y en Avoir Beaucoup Plus. , Tous Les lundis Et jeudis matin, il y aura Underscore Et Les documentaires Qui seront Sur Les plateformes De podcast. Et la raison Pour laquelle je suis à peu près serein De m'y engager, C'est Qu'on n'a rien à faire Pour Que ça se produise. J'allais Vraiment dire, T'as l'ami. J'allais Vraiment dire, T'as l'ami Corp, l'humain n'est Pas fiable. C'est vrai. Il y a Un truc De… On est monotâche, on va dire. On est monotâche. En gros, on s'occupe d'un truc, Mais si C'est en dehors, ça ne marche Pas. Sauf si C'est… Pour l'avoir Fait pendant plusieurs années, C'est chiant. Elle n'a aucune valeur ajoutée. Le problème, C'est qu'en podcast, Les miniatures, Elles sont carrées. Oui, Elles ne sont Pas horizontales. Alors, Comment faire ? Trois petits points. Eh bien, la solution, C'est super simple, C'est De faire Un Système De Dean Painting. Globalement, Notre but là, C'est De Trouver Un Système Pour Que, à partir D'une miniature, on vienne combler ce Qu'il y a en haut Et en bas.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4624,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4639,
      "context": "\"paragraph\": \"Et au début, on a Fait Des tests Assez simples, comme ça, Avec De l'inpainting, Et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à Trouver le bon Modèle. Et à Trouver le bon Système. , on prend la miniature, on l'agrandit, on la met derrière, on la floute. Ça sert De point De départ à l'inpainting. Le masque a Une opacité faible. Il y avait Une petite mécanique à Trouver, Mais là comme ça, il invente Même Des reflets Et Tout ça. Très bien. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est comme ça Qu'on règle le problème De la fiabilité, C'est Qu'on sait Qu'il y en a toujours Une Sur quatre Qui est bonne. Il y a Une miniature différente Pour chaque pot. Exactement du coup. Et bien le résultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tirés directement De la chaîne YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques. Entièrement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier cette histoire récente De Comment l'IA a créé Une puce De calcul parfaite, Mais Qui échappe Complètement à la compréhension Des humains. C'était Dans cette vidéo.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4650,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4664,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4678,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4692,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4706,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4720,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4734,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4748,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4762,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4776,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4790,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4804,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4818,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4832,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4846,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4860,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4872,
      "context": "\"text\": \"Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4873,
      "context": "\"text_human\": \"Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4874,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4888,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4902,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4916,
      "context": "\"text_machine\": \"Et au debut, on a Fait Des tests Assez simples, comme ca, Avec De l'inpainting, Et ca donnait Des mauvais resultats. Et Globalement, on commence a arriver a Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ca tenait a Trouver le bon Modele. Et a Trouver le bon Systeme. , on prend la miniature, on l'agrandit, on la met derriere, on la floute. Ca sert De point De depart a l'inpainting. Le masque a 1 opacite faible. Il y avait 1 petite mecanique a Trouver, Mais la comme ca, il invente Meme Des reflets Et Tout ca. Tres bien. Et ce Que ca veut dire, C'est Que Quand 1 video sort, il nous propose 4 Versions. A chaque fois, C'est comme ca Qu'on regle le probleme De la fiabilite, C'est Qu'on sait Qu'il y en a toujours 1 Sur 4 Qui est bonne. Il y a 1 miniature differente Pour chaque pot. Exactement du coup. Et bien le resultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tires directement De la chaine YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a differentes applications, Des Qu'il y a Tres peu De prise De Decision, peu De creativite, Qui sont Tres adaptees Pour Des workflows automatiques. Entierement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus creatif. Si ce sujet Vous a interesse, Vous allez forcement apprecier cette histoire recente De Comment l'IA a cree 1 puce De calcul parfaite, Mais Qui echappe Completement a la comprehension Des humains. C'etait Dans cette video.\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4933,
      "context": "\"text\": \"Et au début, on a Fait Des tests Assez simples, comme ça, Avec De l'inpainting, Et ça donnait Des mauvais résultats. Et Globalement, on commence à arriver à Des Bons trucs. On voit Plus Vraiment Les limites. Et Globalement, ça tenait à Trouver le bon Modèle. Et à Trouver le bon Système. , on prend la miniature, on l'agrandit, on la met derrière, on la floute. Ça sert De point De départ à l'inpainting. Le masque a Une opacité faible. Il y avait Une petite mécanique à Trouver, Mais là comme ça, il invente Même Des reflets Et Tout ça. Très bien. Et ce Que ça veut dire, C'est Que Quand Une vidéo sort, il nous propose quatre Versions. À chaque fois, C'est comme ça Qu'on règle le problème De la fiabilité, C'est Qu'on sait Qu'il y en a toujours Une Sur quatre Qui est bonne. Il y a Une miniature différente Pour chaque pot. Exactement du coup. Et bien le résultat du coup il est live, C'est Que on a nos Miniats Qui sont propres, Qui sont tirés directement De la chaîne YouTube. C'est cool ou Quoi ? Et C'est Pour Montrer Que en gros il y a différentes applications, Dès Qu'il y a Très peu De prise De Décision, peu De créativité, Qui sont Très adaptées Pour Des workflows automatiques. Entièrement Et d'autres Qui le sont moins, Qui peuvent Servir De brainstorming Pour du travail Plus créatif. Si ce sujet Vous a intéressé, Vous allez forcément apprécier cette histoire récente De Comment l'IA a créé Une puce De calcul parfaite, Mais Qui échappe Complètement à la compréhension Des humains. C'était Dans cette vidéo.\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\structure.json",
      "line": 4936,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\03_aligned_whisperx.json",
      "line": 87206,
      "context": "\"num_workers\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 370,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 823,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1231,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1564,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1912,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 2260,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 2713,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 3076,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 3529,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 4012,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 4465,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 4903,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 5341,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 5794,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 6292,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 6670,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 7138,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 7321,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\03_aligned_whisperx.json",
      "line": 75686,
      "context": "\"num_workers\"",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 295,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 838,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 1171,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 1534,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 1897,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 2230,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 2608,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 3031,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 3484,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 3877,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 4270,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 4663,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 5146,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 5509,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 5977,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 6385,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 6823,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 7201,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\structure.json",
      "line": 7247,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\03_aligned_whisperx.json",
      "line": 87206,
      "context": "\"num_workers\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 402,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1022,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1390,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 1730,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 2084,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 2676,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 3254,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 3972,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 4424,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 4848,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 5888,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 6270,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\structure.json",
      "line": 6694,
      "context": "\"metadata\": {",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\logs\\run_manifest.json",
      "line": 47,
      "context": "\"work_dir\": \"D:\\\\02_dev\\\\scripts\\\\transcribe-suite\\\\transcribe-suite\\\\work\\\\dessins dans Comfyui\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\dessins dans Comfyui\\logs\\run_manifest.json",
      "line": 49,
      "context": "\"exports\": [",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\logs\\run_manifest.json",
      "line": 47,
      "context": "\"work_dir\": \"D:\\\\02_dev\\\\scripts\\\\transcribe-suite\\\\transcribe-suite\\\\work\\\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Intelligence artificielle - l'oubli de l_humanité_ choc civilisationnel _ Éric Sadin\\logs\\run_manifest.json",
      "line": 49,
      "context": "\"exports\": [",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 3,",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 2,
      "context": "\"input\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\video\\\\Je vous dévoile loutil IA dont je ne peux plus me passer.mp4\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 3,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 47,
      "context": "\"work_dir\": \"D:\\\\02_dev\\\\scripts\\\\transcribe-suite\\\\transcribe-suite\\\\work\\\\Je vous dévoile loutil IA dont je ne peux plus me passer\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 48,
      "context": "\"export_dir\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\video\\\\TRANSCRIPT - Je vous dévoile loutil IA dont je ne peux plus me passer\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 49,
      "context": "\"exports\": [",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 55,
      "context": "\"json\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\video\\\\TRANSCRIPT - Je vous dévoile loutil IA dont je ne peux plus me passer\\\\Je vous dévoile loutil IA dont je ne peux plus me passer.json\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 56,
      "context": "\"md\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\video\\\\TRANSCRIPT - Je vous dévoile loutil IA dont je ne peux plus me passer\\\\Je vous dévoile loutil IA dont je ne peux plus me passer.md\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile loutil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 57,
      "context": "\"vtt\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\video\\\\TRANSCRIPT - Je vous dévoile loutil IA dont je ne peux plus me passer\\\\Je vous dévoile loutil IA dont je ne peux plus me passer.vtt\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\Je vous dévoile l’outil IA dont je ne peux plus me passer\\logs\\run_manifest.json",
      "line": 45,
      "context": "\"error\": \"Mode strict: exports non attendus Je vous dévoile l’outil IA dont je ne peux plus me passer.audit.md, Je vous dévoile l’outil IA dont je ne peux plus me passer.chunks.jsonl, Je vous dévoile l’outil IA dont je ne peux plus me passer.chunks.meta.json, Je vous dévoile l’outil IA dont je ne peux plus me passer.clean.jsonl, Je vous dévoile l’outil IA dont je ne peux plus me passer.clean.txt, Je vous dévoile l’outil IA dont je ne peux plus me passer.low_confidence.jsonl, Je vous dévoile l’outil IA dont je ne peux plus me passer.metrics.json, Je vous dévoile l’outil IA dont je ne peux plus me passer.quotes.jsonl\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 8,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 47,
      "context": "\"work_dir\": \"D:\\\\02_dev\\\\scripts\\\\transcribe-suite\\\\transcribe-suite\\\\work\\\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 49,
      "context": "\"exports\": [",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 2,
      "context": "\"input\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE.mp4\",",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 47,
      "context": "\"work_dir\": \"D:\\\\02_dev\\\\scripts\\\\transcribe-suite\\\\transcribe-suite\\\\work\\\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 48,
      "context": "\"export_dir\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\TRANSCRIPT - L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\",",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 49,
      "context": "\"exports\": [",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 55,
      "context": "\"md\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\TRANSCRIPT - L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE.md\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 56,
      "context": "\"json\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\TRANSCRIPT - L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE.json\",",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 57,
      "context": "\"vtt\": \"\\\\\\\\bricesodini\\\\Savoirs\\\\03_data_pipeline\\\\01_input\\\\TRANSCRIPT - L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE\\\\L_IA va-t-elle tuer Internet_Documentaire 2025 _ ARTE.vtt\"",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\metrics.json",
      "line": 8,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 27,
      "context": "\"worker_count\": 2,",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\transcribe-suite\\_deprecated_work\\L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE\\logs\\run_manifest.json",
      "line": 45,
      "context": "\"error\": \"Mode strict: exports non attendus L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.audit.md, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.chunks.jsonl, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.chunks.meta.json, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.clean.jsonl, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.clean.txt, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.low_confidence.jsonl, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.metrics.json, L_IA va-t-elle tuer Internet _ _ Documentaire 2025 _ ARTE.quotes.jsonl\"",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.bat",
      "line": 30,
      "context": "for %%D in (inputs exports) do (",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.bat",
      "line": 44,
      "context": "set \"NAS_ROOT=%DATA_PIPELINE_ROOT%\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.bat",
      "line": 47,
      "context": "echo [QA] NAS audit skipped (DATA_PIPELINE_ROOT not set^)",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.bat",
      "line": 48,
      "context": "echo [QA] NAS audit skipped (DATA_PIPELINE_ROOT not set^) >> \"%QA_LOG%\"",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.sh",
      "line": 27,
      "context": "if [[ -n \"${DATA_PIPELINE_ROOT:-}\" ]]; then",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.sh",
      "line": 29,
      "context": "\"$PYTHON\" -m tools.nas_audit --root \"$DATA_PIPELINE_ROOT\" --out-dir logs >>\"$QA_LOG\" 2>&1",
      "scope": "scripts"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\bin\\qa_check.sh",
      "line": 31,
      "context": "echo \"[QA] NAS audit ignoré (DATA_PIPELINE_ROOT non défini)\" | tee -a \"$QA_LOG\"",
      "scope": "scripts"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 3,
      "context": "> **Transcription locale de haute qualité**, compatible Apple Silicon (CPU, sans accélération GPU), avec **diarisation multi-locuteurs**, **alignement mot-à-mot**, **chapitrage intelligent** et **exports prêts pour RAG / montage**.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 45,
      "context": "Les exports « livrables » restent `md/json/vtt` ; tous les autres fichiers appartiennent à la couche QA/RAG et doivent être présents mais ne bloquent plus le mode strict.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 53,
      "context": "Sans relancer l'ASR, `rag-export` transforme un document existant (`work/<doc>` + `TRANSCRIPT - <doc>`) en artefacts RAG versionnés et déterministes :",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 57,
      "context": "bin/run.sh rag --input \"work/Mon Doc\" --dry-run      # inspection",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 58,
      "context": "bin/run.sh rag --input \"work/Mon Doc\" --force        # génération",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 64,
      "context": "Entrées acceptées : dossier `work/<doc>`, dossier `TRANSCRIPT - <doc>` ou fichier média original (le résolveur retrouve `work/<doc>`).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 65,
      "context": "Configuration : `config/rag.yaml` (globale) + override optionnel `work/<doc>/rag.config.yaml`. Chaque flag CLI écrase la config effective (ex. `--no-sqlite`).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 99,
      "context": "bin/run.sh rag doctor --input \"work/Mon Doc\" --version-tag 0.1.0",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 119,
      "context": "- `--real-timestamps` capture l’horodatage UTC réel et positionne `deterministic_mode=false`, `timestamps_policy=\"real\"` ; la reproductibilité byte-égale n’est alors plus garantie.",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 120,
      "context": "- Tous les manifestes incluent également `provenance` (SHA-256 des inputs) et `config_effective.yaml` + son hash pour tracer la config exacte.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 126,
      "context": "- Les exports vidéo existants servent de base : mêmes artefacts (`document.json`, `chunks.jsonl`, `quality.json`, `lexical.sqlite`, etc.).",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 134,
      "context": "## 🗄️ NAS Data Pipeline (`\\\\bricesodini\\Savoirs\\03_data_pipeline`)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 139,
      "context": "> Les batchs NAS **ne déplacent jamais les exports** ; ils déplacent uniquement le média vers `_processed/_failed` après traitement.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 144,
      "context": "03_data_pipeline/",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 151,
      "context": "asr/                  # artefacts work/ + TRANSCRIPT staging pour rag-export",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 153,
      "context": "03_output_RAG/          # sorties rag-export quand DATA_PIPELINE_ROOT est défini",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 156,
      "context": "### Workflow recommandé",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 164,
      "context": "- Copie automatiquement le dossier `TRANSCRIPT - <Nom>` (resté à côté du média) + `work/<Nom>` dans `02_output_source\\asr\\<doc>\\`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 165,
      "context": "- Déplace les médias vers `01_input\\_processed\\...` (ou `_failed`) sans toucher aux exports adjacents.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 167,
      "context": "- Scanne `02_output_source\\asr\\<doc>\\work\\<doc>` avec `bin\\run.bat rag lexicon scan --input \"<work>\"`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 169,
      "context": "- Par défaut, un document validé + stamp aligné est **SKIP** ; `--force` rescanne malgré tout. Voir `docs/RAG_LEXICON_WORKFLOW.md` pour la boucle complète de validation.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 171,
      "context": "- Parcourt `02_output_source\\asr\\*`, exécute `bin\\run.bat rag --input \"<doc>\\work\\<Nom>\" --force`.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 172,
      "context": "- `DATA_PIPELINE_ROOT` est automatiquement défini pour écrire dans `03_output_RAG`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 173,
      "context": "- Résultat : exports dans `\\\\bricesodini\\Savoirs\\03_data_pipeline\\03_output_RAG\\RAG-<doc_id>\\...`.",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 175,
      "context": "4. **Consommer les artefacts** : `02_output_source\\asr\\*` contient les inputs sources (work + transcripts), tandis que `03_output_RAG\\RAG-<doc_id>` héberge les artefacts RAG versionnés prêts à indexer.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 189,
      "context": "- `DATA_PIPELINE_ROOT` peut aussi être défini manuellement dans votre shell pour rediriger n’importe quel `rag-export` vers `\\\\bricesodini\\Savoirs\\03_data_pipeline\\03_output_RAG` (lorsqu’il est absent, la sortie reste dans `RAG/` à la racine du dépôt).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 191,
      "context": "- Détails et conventions du workflow lexicon : `docs/RAG_LEXICON_WORKFLOW.md`.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 193,
      "context": "**DATA_PIPELINE_ROOT**",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 194,
      "context": "- Valeur recommandée (UNC) : `\\\\bricesodini\\Savoirs\\03_data_pipeline`",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 195,
      "context": "- Si défini : les exports `rag` écrivent dans `03_output_RAG` (pipeline NAS).",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 196,
      "context": "- Si absent : les exports `rag` restent dans `RAG/` à la racine du dépôt (comportement par défaut).",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 214,
      "context": "--export-dir \"exports/TRANSCRIPT - Mon Talk\" \\",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 239,
      "context": "| **Exports RAG-ready** (JSON structuré)    | ✅               | ❌          | ❌            | partiel                    |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 253,
      "context": "- **asr-parallel** : Faster-Whisper large-v3 (mode auto CPU, sans GPU Metal) sur N workers (≤10) via queue, JSONL par segment",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 277,
      "context": "| `--dry-run` | Exécute toutes les étapes nécessaires (incluant audit/metrics) mais saute les exports finaux. |",
      "scope": "source"
    },
    {
      "pattern": "runs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 278,
      "context": "| `--no-audit` | Désactive l'écriture de `*.audit.md` (utile pour les runs batch). |",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 286,
      "context": "- `bin/run.sh dry-run --input \"...mp4\"` pour vérifier l’arborescence cible, les exports et l’état des artefacts existants.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 292,
      "context": "Artefacts : `work/<media>/audio_16k.wav`, `00_segments/*.wav`, `manifest.csv`, `manifest_state.json`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 297,
      "context": "Artefacts : `01_asr_jsonl/seg_*.jsonl`, `logs/asr_worker_*.log`, métriques dans `logs/metrics.json`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 313,
      "context": "Contrôle : ajuster `--align-workers`, `--align-batch`, `--speech-only` en fonction du temps d’exécution et des warnings WhisperX.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 320,
      "context": "7. **Exports finaux (`export`)**",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 323,
      "context": "Contrôle : en mode strict, `_verify_artifacts` n'exige plus que les formats demandés + `chapters.json` (si le chapitrage tourne) + `low_confidence.csv` (si `csv_enabled=true`). Les autres artefacts QA sont tolérés. Le pointer `work/<media>/logs/run_manifest.json` expose `export_dir`, hash, durées, versions et la liste des exports.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 353,
      "context": "| `export` | Génération des formats finaux depuis les artefacts post. | Recréer des exports (formats supplémentaires, patch). |",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 355,
      "context": "| `dry-run` | Aucun traitement : affiche l’arborescence cible + paramètres résolus. | Vérifier les chemins/exports avant un run lourd. |",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 362,
      "context": "| `--input` (obligatoire) | Média audio/vidéo à transcrire. | Accepte `~/`, chemins relatifs ou un fichier déjà déposé dans `inputs/`. |",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 364,
      "context": "| `--profile` | Charge un profil YAML (`default`, `talkshow`, `conference`, custom). | Permet d’appliquer des presets exports/chapitrage. |",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 378,
      "context": "| `--no-partial-export` / `--allow-partial-export` | Empêche (défaut) ou autorise les exports si une étape échoue. | Autorisez ponctuellement pour du debug rapide. |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 379,
      "context": "| `--keep-build` | Conserve `work/<media>` après succès. | Analyse post-mortem ou réutilisation d’artefacts. |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 400,
      "context": "| `--asr-workers` / `--asr-parallelism` | Force le parallélisme ASR (>=1). Sans override, `asr.workers:auto` choisit sagement 1–3 workers sur GPU et ≈50 % des cœurs sur CPU. | `--asr-workers 2` sur une 3090 si besoin spécifique. |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 405,
      "context": "| `--align-workers` | `num_workers` WhisperX. | `--align-workers 4` si beaucoup de cœurs. |",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 409,
      "context": "| `--export-parallel` / `--export-serial` | Détermine si les exports tournent en multi-thread (défaut config). | `--export-serial` si disque lent / collisions I/O. |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 413,
      "context": "> Par défaut `asr.workers: auto` évite les déboires sur GPU unique : 2 workers sur CUDA (3 si VRAM ≥ 20 GB comme une RTX 3090), sinon `min(len(segments), cpu_count/2)` sur CPU/Metal. Toute demande explicite (`--asr-workers` ou `asr.workers: 4`) est clampée et logguée si elle dépasse les limites (segments, threads env, cœurs physiques).",
      "scope": "source"
    },
    {
      "pattern": "inputs",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 419,
      "context": "├─ inputs/VIDEO.ext                      # optionnel, équivalent --input",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 420,
      "context": "├─ work/VIDEO/",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 430,
      "context": "│  ├─ logs/ (run.log, asr_worker_*.log, merge.log, align.log, metrics.json)",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 443,
      "context": "- La règle historique reste valable : les exports ASR (`TRANSCRIPT - <Nom>`) vivent **à côté du média** et les artefacts RAG vont dans `DATA_PIPELINE_ROOT\\03_output_RAG`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 444,
      "context": "- Le dépôt `transcribe-suite/` ne sert plus de zone de stockage (`inputs/`, `exports/`, `work/` et consorts sont automatiquement renommés `_deprecated_*`). Toute redirection implicite vers le dépôt lève désormais une erreur, sauf opt-in ponctuel (`--allow-local-exports` ou `TS_ALLOW_LOCAL_DATA=1` pour les tests).",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 460,
      "context": "python -m tools.nas_audit --root \\\\bricesodini\\Savoirs\\03_data_pipeline --report docs/NAS_AUDIT.md",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 465,
      "context": "Toutes les sorties finales restent donc adjacentes au média traité ou sur le partage NAS, ce qui évite les duplications dans `transcribe-suite/exports`.",
      "scope": "source"
    },
    {
      "pattern": "data",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 469,
      "context": "- `bin\\qa_check.bat` / `./bin/qa_check.sh` doivent passer (tests unitaires Transcribe Suite + Control Room, smoke `/api/v1/*`, audit dépôt dry-run, NAS audit si `DATA_PIPELINE_ROOT` est défini). Les logs sont stockés dans `logs/qa_check_<timestamp>.log`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 472,
      "context": "- Les writes autorisés vivent soit **à côté du média** (`TRANSCRIPT - <Nom>`), soit sur le NAS (`DATA_PIPELINE_ROOT`). Toute écriture dans le dépôt est bloquée, sauf opt-in ponctuel `TS_ALLOW_LOCAL_DATA=1` / `--allow-local-exports` (debug).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 483,
      "context": "La **reprise** est automatique : si un fichier JSONL existe ou qu'un segment est marqué `DONE` dans `manifest_state.json`, il est sauté. Chaque worker écrit ses logs (avec PID) pour faciliter le debug.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 570,
      "context": "> Les scripts batch Windows (`bin\\transcribe_mono.bat`, `bin\\transcribe_multi.bat`, `bin\\transcribe_share.bat`) gardent l’ASR en mode auto par défaut, à l’exception de `transcribe_mono.bat` qui force `--asr-workers 2` pour garantir la stabilité et éviter une saturation GPU sur RTX 3090. Les exécutions via CLI directe ou scripts Unix restent sur la logique auto intelligente décrite plus haut.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 577,
      "context": "- Ce flux reste 100 % pip : pas besoin d’installer un CUDA Toolkit système ni de jouer avec `nvcc`. Les wheels pin (torch 2.6.0+cu124, whisperx 3.4.0, ctranslate2 4.4.0, etc.) sont alignées avec ces DLL et loguées dans `work/<media>/logs/run_manifest.json`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 587,
      "context": "- Après succès : `\\\\bricesodini\\Savoirs\\Transcriptions\\output\\<Nom>\\TRANSCRIPT - <Nom>` contient les exports, `...\\logs` reprend `work/<Nom>/logs`. Le batch lit désormais `work/<Nom>/logs/run_manifest.json` (`export_dir`) plutôt qu’un pattern `__tmp_*`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 703,
      "context": "| `num_workers`                   | `min(8, ASR_THREADS)`                                   |",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 719,
      "context": "Le runner utilisera alors `ASR_THREADS` pour `CTRANSLATE2_NUM_THREADS` et les bindings Faster-Whisper respectent `num_workers`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 747,
      "context": "--align-workers 4 \\",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 752,
      "context": "- `--align-workers` ajuste `num_workers` transmis à WhisperX (auto-fallback si non supporté).",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 772,
      "context": "**4. EXPORTS en parallèle**",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 784,
      "context": "1. ASR ➜ `source bin/asr_env.sh`, `--compute-type int8`, `--chunk-length 20` (optionnellement `--asr-workers N` si vous ne voulez pas du mode auto).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 785,
      "context": "2. ALIGN ➜ `source bin/post_env.sh`, `--align-workers 4`, `--align-batch 16`, `--speech-only`.",
      "scope": "source"
    },
    {
      "pattern": "inputs_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 797,
      "context": "inputs_dir: inputs",
      "scope": "source"
    },
    {
      "pattern": "work_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 798,
      "context": "work_dir: work",
      "scope": "source"
    },
    {
      "pattern": "exports_dir",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 799,
      "context": "exports_dir: exports",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 831,
      "context": "workers: auto          # auto | entier >=1",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 913,
      "context": "- `logs/metrics.json` conserve les stats de la passe ASR (durée, workers utilisés, segments traités/ignorés/échoués).",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 914,
      "context": "- Chaque worker Faster-Whisper écrit un log dédié (`logs/asr_worker_<pid>.log`) pour les analyses de stabilité.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 934,
      "context": "## 📤 Exports",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 969,
      "context": "- `bin/audit_before_commit.sh` scanne l’arbre + l’index Git avec masquage automatique (`***REDACTED***`) et rappelle d’ajouter `work/`, `exports/`, `models/`, `.venv/`, `.cache/` dans `.gitignore`.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 998,
      "context": "→ Encodage erroné (UTF-16). Tous les exports sont forcés en UTF-8.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 1007,
      "context": "→ Les paramètres `num_workers` / `batch_size` sont filtrés dynamiquement pour correspondre à la version installée. En cas de crash (TypeError / IndexError), la pipeline continue avec les segments non alignés mot-à-mot. Vous pouvez aussi bypasser complètement l’align en lançant `bin\\run.bat run --only prepare,asr,merge,post,export --input ...`.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 1013,
      "context": "- **Où sont les logs ?** Chaque exécution crée `\\\\bricesodini\\Savoirs\\Transcriptions\\output\\<Nom>\\run_YYYYMMDD_HHMMSS.log` (copie du `share_stage\\logs\\*.log`) et le dossier `work` associé (`...\\<Nom>\\work\\logs\\...`). C’est la première source à consulter.",
      "scope": "source"
    },
    {
      "pattern": "work",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 1016,
      "context": "- **Run en échec** : la fenêtre reste ouverte, le log cite le code retour. Ouvrez le `run_*.log` du dossier output puis (si besoin) `work\\logs\\run.log` pour l’erreur détaillée. Corrigez (token, CUDA, fichier corrompu…), laissez `\\\\...\\input` vide (le .bat a déplacé le média en `_processed` seulement en cas de succès) puis relancez.",
      "scope": "source"
    },
    {
      "pattern": "exports",
      "file": "D:\\02_dev\\scripts\\transcribe-suite\\README.md",
      "line": 1022,
      "context": "- Verrouillage du profil `stable` (exports `md/json/vtt`, `detect_language=false`, `requirements.lock` imposé).",
      "scope": "source"
    }
  ],
  "actions": []
}
